{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f4ae844694', 'id': 'chatcmpl-D7i6bv1bzn9CWmmCyFmMNqaEI43TZ', 'finish_reason': 'stop', 'logprobs': None}, id='run-f812090c-1ef4-4abd-86c6-d72116205f48-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm.invoke(\"HI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I am based on OpenAI's GPT-3 model. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 14, 'total_tokens': 33, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_842ff35899', 'id': 'chatcmpl-D7i6buvFmQAsanSnLYTGL59qh4Qsm', 'finish_reason': 'stop', 'logprobs': None}, id='run-9b8fca74-0ac8-4ca7-a383-e058c6a1503a-0', usage_metadata={'input_tokens': 14, 'output_tokens': 19, 'total_tokens': 33, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o-mini\", \n",
    "    model_provider=\"openai\")\n",
    "\n",
    "model.invoke(\"Hi what is your model name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm Claude, made by Anthropic. The specific model you're talking to is Claude 3.5 Sonnet (version 2).\", additional_kwargs={}, response_metadata={'id': 'msg_012NVohA2H9Xzw1mP4cWyKw2', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 18, 'output_tokens': 35, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'service_tier': 'standard', 'inference_geo': 'not_available'}, 'model_name': 'claude-sonnet-4-5-20250929'}, id='run-99515dde-c990-49f5-a46a-a41741f05d46-0', usage_metadata={'input_tokens': 18, 'output_tokens': 35, 'total_tokens': 53, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_chat_model(\"claude-sonnet-4-5-20250929\", model_provider=\"anthropic\")\n",
    "\n",
    "model.invoke(\"Hi what is your name? Like the model name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full LLM App in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your OpenAI API key (required if using OpenAI): \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi ‚Äî how can I help you today? \\n\\nHere are a few things I can do if you want suggestions:\\n- Answer questions or explain something\\n- Help with writing (emails, essays, code, etc.)\\n- Generate ideas (projects, meal plans, travel)\\n- Troubleshoot tech problems\\n- Summarize or translate text\\n\\nOr just tell me what you need.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 7, 'total_tokens': 92, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7iCIapavgrDmuyaIy7qSj9mhIgkz', 'finish_reason': 'stop', 'logprobs': None}, id='run-c5ada134-2b14-48ac-a2df-91a8c355a3a6-0', usage_metadata={'input_tokens': 7, 'output_tokens': 85, 'total_tokens': 92, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"gpt-5-mini\",\n",
    "    model_provider=\"openai\"\n",
    ")\n",
    "\n",
    "model.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! Impariamo a conoscere i grandi modelli di linguaggio!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 26, 'total_tokens': 179, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7i7mMFHHnUxB9XalGCLgJ0Nm4P1h', 'finish_reason': 'stop', 'logprobs': None}, id='run-67878eb7-df5d-4013-a97b-731676f3091d-0', usage_metadata={'input_tokens': 26, 'output_tokens': 153, 'total_tokens': 179, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"Hi! Let's learn about large language models!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm good ‚Äî thanks for asking! How are you? Anything I can help you with today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 10, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7i7pC5DS2cm6A6qyXbfzuvxPIKsJ', 'finish_reason': 'stop', 'logprobs': None}, id='run-5789fa39-804c-4286-a6f4-83fd034844e8-0', usage_metadata={'input_tokens': 10, 'output_tokens': 28, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([{\"role\": \"user\", \"content\": \"How are ya?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Here| are| three| funny| ones|:\n",
      "\n",
      "|1|)| I| told| my| wife| she| was| drawing| her| eyebrows| too| high|.| She| looked| surprised|.\n",
      "\n",
      "|2|)| Two| antennas| met| on| a| roof|,| fell| in| love| and| got| married|.| The| ceremony| wasn|‚Äôt| much|,| but| the| reception| was| excellent|.\n",
      "\n",
      "|3|)| Why| don|‚Äôt| scientists| trust| atoms|?| Because| they| make| up| everything|.||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(\"Tell me the 3 funniest jokes you know\"):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: Translate the following from English into French\\nHuman: I love programming in Python'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from {language_source} into {language_target}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"human\", \"{input_sentence}\")]\n",
    ")\n",
    "\n",
    "prompt_template.format(language_source=\"English\", language_target=\"French\", input_sentence=\"I love programming in Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer en Python.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 22, 'total_tokens': 101, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7i83ZXAwKZSwWjT0D0nNs5pQHHCq', 'finish_reason': 'stop', 'logprobs': None}, id='run-7c8e0a9a-8bb7-4ffa-8824-e95205de461e-0', usage_metadata={'input_tokens': 22, 'output_tokens': 79, 'total_tokens': 101, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language_source\": \"English\", \"language_target\": \"French\", \"input_sentence\": \"I love programming in Python\"})\n",
    "response = model.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime programmer en Python.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model\n",
    "\n",
    "response = chain.invoke({\"language_source\": \"English\", \"language_target\": \"Italian\", \"input_sentence\": \"Lucas is a gorgeous bald teacher.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucas √® un insegnante calvo e bellissimo.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedChatCompletion[ElementsOfLiveCourse](id='chatcmpl-D7iBbeKZrWhNGfTsJDNLydsSwddRB', choices=[ParsedChoice[ElementsOfLiveCourse](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[ElementsOfLiveCourse](content='{\"title\":\"Introduction to AI and Large Language Models\",\"topic\":\"Understanding fundamental concepts behind Artificial Intelligence and the use of large language models\",\"example_lesson\":\"1 - Creating Simple Prompts with Python: In this lesson, you\\'ll learn how to interact with a language model by writing prompts in Python.\"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=ElementsOfLiveCourse(title='Introduction to AI and Large Language Models', topic='Understanding fundamental concepts behind Artificial Intelligence and the use of large language models', example_lesson=\"1 - Creating Simple Prompts with Python: In this lesson, you'll learn how to interact with a language model by writing prompts in Python.\")))], created=1770730519, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_f4ae844694', usage=CompletionUsage(completion_tokens=60, prompt_tokens=297, total_tokens=357, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "class ElementsOfLiveCourse(BaseModel):\n",
    "    title: str = Field(description=\"The title of the live course\")\n",
    "    topic: str = Field(description=\"The core topic of the live course\")\n",
    "    example_lesson: str = Field(description=\"An example lesson from the live course\")\n",
    "\n",
    "with open(\"./course_example.md\", \"r\") as f:\n",
    "    prompt_raw_course = f.read()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You take in raw information for a course and\\\n",
    "            you output the structured objects with information about that course\"},\n",
    "        {\"role\": \"user\", \"content\": prompt_raw_course}\n",
    "    ],\n",
    "    response_format=ElementsOfLiveCourse\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElementsOfLiveCourse(title='Introduction to AI and Large Language Models', topic='Understanding fundamental concepts behind Artificial Intelligence and the use of large language models', example_lesson=\"1 - Creating Simple Prompts with Python: In this lesson, you'll learn how to interact with a language model by writing prompts in Python.\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Introduction to AI and Large Language Models\n",
       "\n",
       "- *Topic*: Understanding fundamental concepts behind Artificial Intelligence and the use of large language models\n",
       "- *Example Lesson*: 1 - Creating Simple Prompts with Python: In this lesson, you'll learn how to interact with a language model by writing prompts in Python.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "str_output = f\"\"\"\n",
    "# {response.choices[0].message.parsed.title}\n",
    "\n",
    "- *Topic*: {response.choices[0].message.parsed.topic}\n",
    "- *Example Lesson*: {response.choices[0].message.parsed.example_lesson}\n",
    "\"\"\"\n",
    "Markdown(str_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A screenplay has two kinds of elements: the technical/formatting elements that make it readable and industry-standard, and the dramatic/structural elements that make it a good story. Below is a concise guide to both.\\n\\nTechnical / Format elements\\n- Slugline (Scene Heading): INT./EXT. LOCATION ‚Äî DAY/NIGHT. Marks new scenes, location and time.\\n  Example: INT. DINER ‚Äî DAY\\n- Action / Description: Present-tense, visual description of what can be seen and heard. Keep it short, cinematic.\\n  Example: A waitress pours coffee. The bell above the door jingles.\\n- Character Name: Centered, capitalized, above dialogue to indicate who speaks.\\n- Dialogue: The spoken lines beneath the character name.\\n- Parenthetical (Wrylie): Brief direction for how a line is delivered (use sparingly).\\n  Example: (whispering)\\n- Dialogue Extensions: V.O. (voice-over), O.S. (off-screen) placed next to character name to show source of dialogue.\\n  Example: NARRATOR (V.O.)\\n- Transitions: CUT TO:, DISSOLVE TO: ‚Äî used in shooting scripts; minimal in specs.\\n- Shot/Camera Directions: ANGLE ON, CLOSE ON, etc. Generally avoided in spec scripts unless essential.\\n- Subheaders: Minor scene changes within the same slugline (e.g., LATER; BACKSTAGE).\\n- Montage / SERIES OF SHOTS: Special formatting for rapid sequences.\\n- Intercut: Used when cutting between two locations or characters frequently.\\n- Flashback / SUPER: Indicated clearly so reader knows time shifts.\\n- Title Page & Scene/page numbering: Title page with author contact; scene numbers typically added in shooting scripts.\\n\\nDramatic / Story elements\\n- Scene: A unit of action that advances story or character. Every scene should have a purpose.\\n- Beat: Smallest unit of dramatic action ‚Äî a change in objective, emotion or tactic.\\n- Sequence: Several scenes connected by a single dramatic event or objective.\\n- Acts: Major divisions (feature films commonly use 3 acts: setup, confrontation, resolution).\\n- Inciting Incident: Event that sets the story in motion.\\n- Plot Points: Major turning points that push the story into the next act.\\n- Midpoint: A pivotal turning point that raises the stakes or changes direction.\\n- Climax & Resolution: The high point and the wrap-up of dramatic conflict.\\n- Character Arc: How a character changes over the story (internal goals, growth/decline).\\n- Goals, Obstacles & Stakes: What a character wants, what blocks them, and what‚Äôs at risk.\\n- Conflict: External and internal opposition that drives drama.\\n- Theme / Motifs: Underlying ideas and visual or verbal motifs that give the story coherence.\\n- Subplots: Secondary storylines that support or contrast the main plot.\\n- Pacing & Rhythm: Scene length, beats, and sequencing to control tempo and tension.\\n- Visual Writing: Screenplays are primarily visual ‚Äî show, don‚Äôt tell. Subtext in dialogue.\\n\\nPractical details & conventions\\n- Page format: Courier 12; industry rule of thumb ~1 page = ~1 minute screen time.\\n- Feature length: commonly ~90‚Äì120 pages. TV and shorts vary.\\n- Spec vs. Shooting Script: Spec focuses on story and marketability; shooting scripts include technical directions, scene numbers and more transitions.\\n- Keep it tight: Short, cinematic sentences; avoid novelist exposition.\\n- Voice & Tone: Maintain consistent voice/tonal choices that fit genre and audience.\\n\\nQuick writing tips\\n- Make every scene do at least one of: reveal character, advance plot, increase stakes, or deepen theme.\\n- Avoid excessive camera directions and stage direction unless necessary.\\n- Use strong concrete verbs and sensory detail that can be filmed.\\n- Trim exposition; let actors and images carry emotion and subtext.\\n\\nIf you want, I can show a short sample page illustrating sluglines, action, character and dialogue, or walk through how these elements look in a 3-act outline of a sample story. Which would help most?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1423, 'prompt_tokens': 15, 'total_tokens': 1438, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7iCTRj3ausMZMWqFl50qO68WgFay', 'finish_reason': 'stop', 'logprobs': None}, id='run-96c8074e-dfe4-4405-a91f-bb58cb3b562b-0', usage_metadata={'input_tokens': 15, 'output_tokens': 1423, 'total_tokens': 1438, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")\n",
    "\n",
    "llm.invoke(\"What are the elements of a Screenplay?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class ElementsOfScreenplay(BaseModel):\n",
    "    \"\"\"Elements of a Screenplay.\"\"\"\n",
    "    \n",
    "    title: str = Field(description=\"The title of the screenplay\")\n",
    "    genre: str = Field(description=\"The genre of the screenplay\")\n",
    "    protagonist: str = Field(description=\"The protagonist of the screenplay\")\n",
    "    antagonist: str = Field(description=\"The antagonist of the screenplay\")\n",
    "    setting: str = Field(description=\"The setting of the screenplay\")\n",
    "    plot: str = Field(description=\"The plot of the screenplay\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(ElementsOfScreenplay)\n",
    "\n",
    "screenplay_structured = structured_llm.invoke(\"Structure a Screenplay about characters afraid of becoming outdated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Update Pending\n",
       "\n",
       "- *Genre*: Dramedy (near-future, character-driven)\n",
       "- *Protagonist*: Maya Alvarez ‚Äî 45, creative director of a once-trendsetting lifestyle design studio, resourceful but terrified of being irrelevant\n",
       "- *Antagonist*\n",
       "- *Setting*: A near-future metropolis where cultural attention is governed by an omnipresent recommendation algorithm; scenes alternate between the fading, sunlit offices of Maya's design studio, the electric public spaces where trends are birthed, and intimate domestic spaces showing the personal cost of professional fear\n",
       "\n",
       "### Plot\n",
       "\n",
       "Act I ‚Äî Setup: Maya Alvarez runs Lumen Atelier, a boutique design studio that defined a decade's aesthetic. A platform update ‚Äî an algorithmic recommender ‚Äî buries their content in favor of hyper-niche 'microtrends' seeded by young influencers. Clients demand instant pivots; staff morale drops. Inciting incident: a flagship client cancels a major campaign, citing platform metrics. Maya's panic about becoming \"outdated\" intensifies; she begins compulsively chasing the algorithm's signals. She meets Nova Chen, an exuberant influencer who embodies everything Maya fears: speed, disposability, and viral mastery. Nova is the public face of the Algorithm's tastes, friendly but ruthless. Act II ‚Äî Confrontation: Maya attempts to retrofit Lumen's work to chase trends ‚Äî reactionary color shifts, contrived hashtags, staged authenticity. The team fractures: younger designers embrace the pivot, older craftsmen resist. Maya's personal life frays; she lies to her partner about their dwindling savings and misses her teenage son's recital. A mid-point failure: Maya greenlights a stunt meant to force viral attention; it backfires, producing a shallow hit that alienates long-time collaborators and draws public backlash for selling out. Humiliated, she retreats and encounters a small, intergenerational group called the Archive Collective ‚Äî makers, librarians, and slow-content creators who deliberately curate durability over virality. Through them, Maya rediscovers principles: craft, context, and audience trust. She also recognizes that fear, not age, drove her decisions. Meanwhile, Nova and the Algorithm tighten their hold: the platform downgrades Lumen further unless Maya produces algorithm-friendly content. Act III ‚Äî Resolution: At a pitch that will decide the studio's future, Maya must choose between a formulaic, data-chasing campaign backed by Nova's platform clout or a risky, human-centered project that honors the studio's voice while using new tools with restraint. Maya devises a hybrid plan ‚Äî a layered campaign that uses the platform's mechanics honestly (targeting niche communities, transparent process films, collaborations with older makers) rather than pandering. Nova initially opposes it, but the campaign's authenticity resonates with a cross-generational audience and sparks a slower, steadier wave of engagement that the algorithm can't easily quantify or replicate. Climax: a live-streamed reveal where Maya speaks candidly about craft, obsolescence, and care; some metrics lag, but community support leads to baseline stability and a new client committed to genuine storytelling. Denouement: Lumen Atelier survives in a reshaped form ‚Äî smaller, steadier, and more principled. Maya accepts that trends will pass but that obsolescence is not a moral failing; she mentors younger creators, including Nova in a tentative collaboration, and builds systems that let her studio iterate without losing identity. The antagonist (the Algorithm/Nova) remains part of the ecosystem ‚Äî neither villain nor ally ‚Äî forcing continuous adaptation. Themes: fear of irrelevance, the ethics of attention economies, intergenerational exchange, the creative value of slowness and authenticity versus the seductive safety of chasing metrics.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "str_output = f\"\"\"\n",
    "# {screenplay_structured.title}\n",
    "\n",
    "- *Genre*: {screenplay_structured.genre}\n",
    "- *Protagonist*: {screenplay_structured.protagonist}\n",
    "- *Antagonist*\n",
    "- *Setting*: {screenplay_structured.setting}\n",
    "\n",
    "### Plot\n",
    "\n",
    "{screenplay_structured.plot}\n",
    "\"\"\"\n",
    "Markdown(str_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model + Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "model = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "output_model_tools = model_with_tools.invoke(\"What is the latest model released by Anthropic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': \"Anthropic latest model released 2026 'Anthropic' 'release' 'model' 'latest'\"},\n",
       "  'id': 'call_WBMsSvqahMmreUVtZhbn6Gn4',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search_results_json',\n",
       "  'args': {'query': \"Anthropic releases 'Claude' 2025 2026 'Claude 3' 'Claude 4' 'latest model'\"},\n",
       "  'id': 'call_tVZyS7X7xWvarLazU878tKb8',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search_results_json',\n",
       "  'args': {'query': \"What is the newest Anthropic model released 'Claude 2026' 'Anthropic Claude' 'latest release'\"},\n",
       "  'id': 'call_RrChnhULMfGmaxcC3CiY93rf',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model_tools.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output we get here is something called a \"tool call\" which means, prepared arguments for a pre-defined function (in this case\n",
    "web search with the tavily API) to gather the required information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a full agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11cad8150>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Executor is a graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the capital of Brazil?', additional_kwargs={}, response_metadata={}, id='760f18c2-8c3f-4a20-be2e-3192318fad11'),\n",
       "  AIMessage(content='The capital of Brazil is Bras√≠lia.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 86, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f4ae844694', 'id': 'chatcmpl-D7iEef37n2T07qMYiCX8NH6Tlrie9', 'finish_reason': 'stop', 'logprobs': None}, id='run-21494394-c096-4526-951c-ceb91661857c-0', usage_metadata={'input_tokens': 86, 'output_tokens': 8, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We pass config because this agent has memory so we need to pass a thread_id\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "# Below we can't just invoke on \"input\" we use \"messages\" because the agent expects a list of messages (this info is hidden in the create_react_agent function)\n",
    "agent_executor.invoke({\"messages\": [HumanMessage(\"What is the capital of Brazil?\")]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the best LLM models right now according to artificialanalysis.ai\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_pyaedO1RtAyLKQfnY0rxBYd8)\n",
      " Call ID: call_pyaedO1RtAyLKQfnY0rxBYd8\n",
      "  Args:\n",
      "    query: best LLM models site:artificialanalysis.ai\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Multilingual AI Model Benchmark - Compare Leading LLMs by ...\", \"url\": \"https://artificialanalysis.ai/models/multilingual\", \"content\": \"Stay connected with us on X, Discord, and LinkedIn to stay up to date with future analysis\\n\\nArtificial Analysis\\n\\nFor EnterpriseInsights\\n\\n# Multilingual AI Model BenchmarkCompare Leading LLMs by Language\\n\\nLast updated:February 10, 2026\\n\\n## Top models üåêAll (average)\\n\\nGemini 3 Pro Preview (high)\\n\\nClaude Opus 4.6 (Adaptive)\\n\\n92\\n\\nGemini 3 Flash\\n\\n#4\\n\\nClaude Opus 4.5\\n\\n91\\n\\n#5\\n\\nGPT-5 (high)\\n\\n91\\n\\n## Top models üá¨üáßEnglish\\n\\n#1\\n\\nClaude Opus 4.6 (Adaptive)\\n\\n95\\n\\n#2\\n\\nGemini 3 Flash\\n\\n95\\n\\n#3\\n\\nClaude Opus 4.5\\n\\n94\\n\\n#4\\n\\nGPT-5.1 (high)\\n\\n94\\n\\n#5\\n\\nClaude Opus 4.6\\n\\n94## Top models üá®üá≥Chinese\\n\\n#1\\n\\nClaude Opus 4.6 (Adaptive)\\n\\n94\\n\\n#2\\n\\nGemini 3 Pro Preview (high)\\n\\n94\\n\\n#3\\n\\nGemini 3 Flash\\n\\n93\\n\\n#4\\n\\nClaude Opus 4.5\\n\\n92\\n\\n#5\\n\\nClaude Opus 4.6\\n\\n92## Top models üáÆüá≥Hindi\\n\\n#1\\n\\nClaude Opus 4.6 (Adaptive)\\n\\n92\\n\\n#2 [...] Pro 2,[object Object],/models/solar-pro-2/providers\\\\ngpt-oss-20B (high),[object Object],/models/gpt-oss-20b/providers\\\\nGLM-4.6V,[object Object],/models/glm-4-6v/providers\\\\nMi:dm K 2.5 Pro,[object Object],/models/mi-dm-k-2-5-pro-dec28/providers\\\\nLlama 4 Scout,[object Object],/models/llama-4-scout/providers\\\\nKimi K2 Thinking,[object Object],/models/kimi-k2-thinking/providers\\\\nEXAONE 4.0 32B,[object Object],/models/exaone-4-0-32b-reasoning/providers\\\\ngpt-oss-20B (low),[object Object],/models/gpt-oss-20b-low/providers\\\\nNova 2.0 Omni,[object Object],/models/nova-2-0-omni/providers\\\\nMistral Small 3.2,[object Object],/models/mistral-small-3-2/providers\\\\nQwen3 30B A3B 2507,[object Object],/models/qwen3-30b-a3b-2507/providers\\\\nOlmo 3.1 32B Think,[object [...] 3.1 32B Think,[object Object],/models/olmo-3-1-32b-think/providers\\\\nK2-V2 (low),[object Object],/models/k2-v2-low/providers\\\\nK-EXAONE,[object Object],/models/k-exaone-non-reasoning/providers\\\\nGemma 3 12B,[object Object],/models/gemma-3-12b/providers\\\\nApriel-v1.5-15B-Thinker,[object Object],/models/apriel-v1-5-15b-thinker/providers\\\\nDevstral Small 2,[object Object],/models/devstral-small-2/providers\\\\nMinistral 3 14B,[object Object],/models/ministral-3-14b/providers\\\\nMinistral 3 8B,[object Object],/models/ministral-3-8b/providers\\\\nMiMo-V2-Flash,[object Object],/models/mimo-v2-flash/providers\\\\nNVIDIA Nemotron 3 Nano,[object Object],/models/nvidia-nemotron-3-nano-30b-a3b/providers\\\\nMinistral 3 3B,[object Object],/models/ministral-3-3b/providers\\\\nGemma 3 4B,[object\", \"score\": 0.99271095}, {\"title\": \"Comparison of AI Models across Intelligence, Performance, Price\", \"url\": \"https://artificialanalysis.ai/models\", \"content\": \"Intelligence: Claude Opus 4.6 (Adaptive) and  GPT-5.2 (xhigh) are the highest intelligence models, followed by  Claude Opus 4.5 & GPT-5.2 Codex (xhigh).Output Speed (tokens/s): Gemini 2.5 Flash-Lite (Sep) (645 t/s) and  Granite 3.3 8B (540 t/s) are the fastest models, followed by  Nova Micro & Gemini 2.5 Flash-Lite.Latency (seconds): Apriel-v1.5-15B-Thinker (0.16s) and   NVIDIA Nemotron Nano 12B v2 VL (0.18s) are the lowest latency models, followed by  NVIDIA Nemotron Nano 9B V2 & DeepSeek-OCR.Price ($ per M tokens): Gemma 3n E4B ($0.03) and  DeepSeek-OCR ($0.05) are the cheapest models, followed by  Llama 3.2 1B & Nova Micro.Context Window: Llama 4 Scout (10m) and  Grok 4.1 Fast (2m) are the largest context window models, followed by  Grok 4.1 Fast & Gemini 2.0 Pro Experimental. [...] 2.5 Flash-Lite (Sep),-54.633,/models/gemini-2-5-flash-lite-preview-09-2025-reasoning/providers,false\\\\nQwen3 4B 2507,-54.667,/models/qwen3-4b-2507-instruct-reasoning/providers,false\\\\nNova 2.0 Lite (low),-54.95,/models/nova-2-0-lite-reasoning-low/providers,false\\\\nLFM2 2.6B,-54.95,/models/lfm2-2-6b/providers,false\\\\nLlama 3 70B,-54.95,/models/llama-3-instruct-70b/providers,false\\\\nMi:dm K 2.5 Pro,-55.217,/models/mi-dm-k-2-5-pro-dec28/providers,false\\\\nLlama 3.2 1B,-55.433,/models/llama-3-2-instruct-1b/providers,false\\\\nLlama 3.3 70B,-55.467,/models/llama-3-3-instruct-70b/providers,false\\\\nGPT-5 mini (minimal),-55.6,/models/gpt-5-mini-minimal/providers,false\\\\nGrok 4 Fast,-55.683,/models/grok-4-fast/providers,false\\\\nGPT-4.1 [...] 2.5 Flash-Lite (Sep),-43.717,/models/gemini-2-5-flash-lite-preview-09-2025/providers,false\\\\nGemini 2.5 Flash,-43.75,/models/gemini-2-5-flash/providers,false\\\\nGLM-4.6,-43.883,/models/glm-4-6-reasoning/providers,false\\\\no3-mini (high),-44.283,/models/o3-mini-high/providers,false\\\\nGemini 2.0 Flash,-44.333,/models/gemini-2-0-flash/providers,false\\\\nLlama 3.1 70B,-44.417,/models/llama-3-1-instruct-70b/providers,false\\\\nDeepSeek V3.1 Terminus,-44.583,/models/deepseek-v3-1-terminus/providers,false\\\\nMiMo-V2-Flash,-44.6,/models/mimo-v2-flash/providers,false\\\\nQwen3 Max,-44.9,/models/qwen3-max/providers,false\\\\nMagistral Small 1,-45.2,/models/magistral-small/providers,false\\\\nQwen3 235B 2507,-45.383,/models/qwen3-235b-a22b-instruct-2507/providers,false\\\\nQwen3\", \"score\": 0.9839708}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "According to Artificial Analysis, the best LLM models right now include:\n",
      "\n",
      "### Overall Top Models\n",
      "1. **Claude Opus 4.6 (Adaptive)** - Score: 92\n",
      "2. **Gemini 3 Pro Preview (high)** - Score: 91\n",
      "3. **Claude Opus 4.5** - Score: 91\n",
      "4. **Gemini 3 Flash** - Score: 90\n",
      "5. **GPT-5 (high)** - Score: 91\n",
      "\n",
      "### English Language Top Models\n",
      "1. **Claude Opus 4.6 (Adaptive)** - Score: 95\n",
      "2. **Gemini 3 Flash** - Score: 95\n",
      "3. **Claude Opus 4.5** - Score: 94\n",
      "4. **GPT-5.1 (high)** - Score: 94\n",
      "5. **Claude Opus 4.6** - Score: 94\n",
      "\n",
      "For more details and comparisons, you can visit the full benchmark [here](https://artificialanalysis.ai/models/multilingual).\n"
     ]
    }
   ],
   "source": [
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"What are the best LLM models right now according to artificialanalysis.ai\")]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Predicting the exact advancements in AI by 2026 involves some speculation, but based on current trends and ongoing research, here are some plausible predictions:\\n\\n1. **Advanced Natural Language Understanding**: AI models will likely achieve a deeper understanding of context, nuances, and even sarcasm in human language, making interactions more natural and human-like.\\n\\n2. **Multimodal AI**: AI systems will become proficient in processing and integrating information from multiple sources, such as text, images, audio, and video, simultaneously. This could lead to more comprehensive and context-aware applications.\\n\\n3. **Autonomous AI Systems**: AI will likely become more autonomous, capable of making complex decisions with minimal human intervention. This could revolutionize industries like healthcare, finance, and transportation.\\n\\n4. **Explainable AI (XAI)**: There will be a greater emphasis on making AI decisions understandable to humans. This is crucial for fields like healthcare and law, where transparency is essential.\\n\\n5. **AI in Creative Fields**: AI will make significant strides in creative domains like art, music, and writing. We might see AI-generated content that is indistinguishable from human-created works.\\n\\n6. **Personalized AI Assistants**: AI assistants will become more personalized, learning from individual user behaviors and preferences to provide highly tailored services.\\n\\n7. **Ethical AI**: There will be a stronger focus on ethical considerations in AI development, including fairness, accountability, and privacy. This could lead to more robust regulations and guidelines.\\n\\n8. **AI in Edge Computing**: AI will become more prevalent in edge computing, enabling real-time processing and decision-making on devices like smartphones and IoT gadgets.\\n\\n9. **AI-Driven Scientific Discoveries**: AI will play a significant role in accelerating scientific research, from drug discovery to materials science, by analyzing vast amounts of data and suggesting hypotheses.\\n\\n10. **AI in Education**: Personalized learning experiences powered by AI will become more common, adapting to individual student needs and learning styles.\\n\\nThese predictions are based on current trends and may evolve as new technologies and breakthroughs emerge.', additional_kwargs={}, response_metadata={'model': 'mistral-small3.2', 'created_at': '2026-02-10T13:40:46.961564Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18303092709, 'load_duration': 99039250, 'prompt_eval_count': 520, 'prompt_eval_duration': 495704334, 'eval_count': 424, 'eval_duration': 17630882028, 'model_name': 'mistral-small3.2'}, id='run-9a7c91cf-51e0-4880-8297-8d475af0662d-0', usage_metadata={'input_tokens': 520, 'output_tokens': 424, 'total_tokens': 944})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install langchain-ollama\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "local_llm = init_chat_model(\"mistral-small3.2\", model_provider=\"ollama\")\n",
    "\n",
    "local_llm.invoke(\"What are some predictions for AI in 2026?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "agent_executor = create_react_agent(local_llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What are some predictions for AI in 2026?', additional_kwargs={}, response_metadata={}, id='28c66ffd-81c6-4410-88ba-eb80c36e6c43'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'mistral-small3.2', 'created_at': '2026-02-10T13:40:56.942107Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1637365417, 'load_duration': 93025459, 'prompt_eval_count': 605, 'prompt_eval_duration': 605318792, 'eval_count': 24, 'eval_duration': 931826791, 'model_name': 'mistral-small3.2'}, id='run-ba4b9150-de63-4c21-875c-a62abb6829c5-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'predictions for AI in 2026'}, 'id': 'f5cd13a0-f69c-45b8-91c7-ace3414eaae1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 605, 'output_tokens': 24, 'total_tokens': 629}),\n",
       "  ToolMessage(content='[{\"title\": \"18 Predictions for 2026 - UX Tigers\", \"url\": \"https://www.uxtigers.com/post/2026-predictions\", \"content\": \"What unites these eighteen predictions is not optimism or pessimism about AI but a recognition that 2026 marks the end of spectating. The window for treating AI as an interesting phenomenon to observe from a safe distance has closed. This is the year when individuals, companies, and entire professions must commit to a position: adapt deliberately, or be adapted to. [...] By the close of 2026, the dominant metric for enterprise AI success will shift from ‚Äútokens generated‚Äù to ‚Äútasks completed autonomously.‚Äù We will see widespread deployment of Multi-Agent Systems (MAS), where specialized AI agents collaborate to achieve shared goals without human intervention. These are not merely productivity tools but ‚Äúdigital employees‚Äù capable of negotiating with other agents, managing operational workflows, and executing complex sequences like supply chain reordering or full-stack code deployment. [...] Instead of single-purpose bots (e.g., a lone email-writing assistant), we‚Äôll have coordinated ‚Äúsuper agents‚Äù that can plan and execute multi-step tasks across apps and environments. You might kick off a research task, and an AI agent will autonomously gather data from the web, draft a report, generate slides, and even schedule a meeting, all while another agent handles your inbox.\\\\n\\\\nMicrosoft and other hyperscalers view this as moving AI from reasoning to collaboration, where AI agents act as teammates that punch above their weight, allowing small three-person teams to execute work previously requiring dozens of staff.\", \"score\": 0.99978346}, {\"title\": \"What to Expect From AI in 2026: Personal Agents, Mega Alliances ...\", \"url\": \"https://www.goldmansachs.com/insights/articles/what-to-expect-from-ai-in-2026-personal-agents-mega-alliances\", \"content\": \"AI has emerged as a critical driver for financial markets and potentially for the broader economy. Wall Street analysts, who have consistently underestimated the amount of investment going into AI, expect the largest hyperscale cloud computing companies to pour more than half a trillion dollars into capital expenditures in 2026. The seven biggest tech companies now account for more than 30% of the S&P 500‚Äôs market capitalization and roughly one quarter of the index‚Äôs earnings, according to Goldman Sachs Research.\\\\n\\\\nArgenti, the former vice president of technology of Amazon Web Services, says AI is rewiring everything from the traditional workforce to the traditional software stack. He makes seven predictions about how AI could evolve in the near future:\", \"score\": 0.99971753}]', name='tavily_search_results_json', id='0287c729-a46d-46b6-bfd9-c26d43abd52f', tool_call_id='f5cd13a0-f69c-45b8-91c7-ace3414eaae1', artifact={'query': 'predictions for AI in 2026', 'response_time': 1.65, 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.uxtigers.com/post/2026-predictions', 'title': '18 Predictions for 2026 - UX Tigers', 'content': 'What unites these eighteen predictions is not optimism or pessimism about AI but a recognition that 2026 marks the end of spectating. The window for treating AI as an interesting phenomenon to observe from a safe distance has closed. This is the year when individuals, companies, and entire professions must commit to a position: adapt deliberately, or be adapted to. [...] By the close of 2026, the dominant metric for enterprise AI success will shift from ‚Äútokens generated‚Äù to ‚Äútasks completed autonomously.‚Äù We will see widespread deployment of Multi-Agent Systems (MAS), where specialized AI agents collaborate to achieve shared goals without human intervention. These are not merely productivity tools but ‚Äúdigital employees‚Äù capable of negotiating with other agents, managing operational workflows, and executing complex sequences like supply chain reordering or full-stack code deployment. [...] Instead of single-purpose bots (e.g., a lone email-writing assistant), we‚Äôll have coordinated ‚Äúsuper agents‚Äù that can plan and execute multi-step tasks across apps and environments. You might kick off a research task, and an AI agent will autonomously gather data from the web, draft a report, generate slides, and even schedule a meeting, all while another agent handles your inbox.\\n\\nMicrosoft and other hyperscalers view this as moving AI from reasoning to collaboration, where AI agents act as teammates that punch above their weight, allowing small three-person teams to execute work previously requiring dozens of staff.', 'score': 0.99978346, 'raw_content': None}, {'url': 'https://www.goldmansachs.com/insights/articles/what-to-expect-from-ai-in-2026-personal-agents-mega-alliances', 'title': 'What to Expect From AI in 2026: Personal Agents, Mega Alliances ...', 'content': 'AI has emerged as a critical driver for financial markets and potentially for the broader economy. Wall Street analysts, who have consistently underestimated the amount of investment going into AI, expect the largest hyperscale cloud computing companies to pour more than half a trillion dollars into capital expenditures in 2026. The seven biggest tech companies now account for more than 30% of the S&P 500‚Äôs market capitalization and roughly one quarter of the index‚Äôs earnings, according to Goldman Sachs Research.\\n\\nArgenti, the former vice president of technology of Amazon Web Services, says AI is rewiring everything from the traditional workforce to the traditional software stack. He makes seven predictions about how AI could evolve in the near future:', 'score': 0.99971753, 'raw_content': None}], 'request_id': 'aa23add0-2620-4706-92be-a67a25143945'}),\n",
       "  AIMessage(content='Here are some predictions for AI in 2026:\\n\\n1. **Multi-Agent Systems (MAS)**: By the end of 2026, the focus of enterprise AI will shift from generating tokens to completing tasks autonomously. Multi-Agent Systems (MAS) will be widely deployed, where specialized AI agents collaborate to achieve shared goals without human intervention. These agents will act as \"digital employees\" capable of negotiating, managing workflows, and executing complex tasks like supply chain reordering or full-stack code deployment <SPECIAL_27>0<SPECIAL_28>.\\n\\n2. **Super Agents**: Instead of single-purpose bots, coordinated \"super agents\" will emerge. These agents will plan and execute multi-step tasks across different applications and environments. For example, an AI agent could autonomously gather data from the web, draft a report, generate slides, and schedule a meeting, all while another agent manages your inbox <SPECIAL_27>0<SPECIAL_28>.\\n\\n3. **Financial Impact**: AI is expected to be a critical driver for financial markets and the broader economy. Wall Street analysts predict that the largest hyperscale cloud computing companies will invest over half a trillion dollars in capital expenditures in 2026. The seven biggest tech companies are expected to account for more than 30% of the S&P 500‚Äôs market capitalization and roughly one quarter of the index‚Äôs earnings <SPECIAL_27>1<SPECIAL_28>.\\n\\n4. **Workforce and Software Stack Transformation**: AI is anticipated to rewire the traditional workforce and software stack. This transformation will likely lead to significant changes in how businesses operate and how employees interact with technology <SPECIAL_27>1<SPECIAL_28>.\\n\\nThese predictions highlight the significant advancements and integrations expected in AI by 2026, emphasizing its role in automating tasks, enhancing productivity, and driving economic growth.', additional_kwargs={}, response_metadata={'model': 'mistral-small3.2', 'created_at': '2026-02-10T13:41:19.057049Z', 'done': True, 'done_reason': 'stop', 'total_duration': 21791716208, 'load_duration': 108501167, 'prompt_eval_count': 1137, 'prompt_eval_duration': 3256006125, 'eval_count': 363, 'eval_duration': 18358558097, 'model_name': 'mistral-small3.2'}, id='run-45aaf5fa-4d00-4950-84dc-ef2f4467c2b7-0', usage_metadata={'input_tokens': 1137, 'output_tokens': 363, 'total_tokens': 1500})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\": [HumanMessage(\"What are some predictions for AI in 2026?\")]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
