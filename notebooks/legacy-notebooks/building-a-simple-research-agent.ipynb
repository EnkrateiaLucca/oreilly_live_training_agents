{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a research Agent with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:43.885849Z",
     "iopub.status.busy": "2024-07-18T12:08:43.884846Z",
     "iopub.status.idle": "2024-07-18T12:08:43.891636Z",
     "shell.execute_reply": "2024-07-18T12:08:43.891181Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-community\n",
    "%pip install langchain-openai\n",
    "%pip install langchainhub\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:43.894300Z",
     "iopub.status.busy": "2024-07-18T12:08:43.894040Z",
     "iopub.status.idle": "2024-07-18T12:08:43.896270Z",
     "shell.execute_reply": "2024-07-18T12:08:43.895945Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment this if running locally\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# FILEPATH: /Users/greatmaster/Desktop/projects/oreilly-live-trainings/oreilly_live_training_agents/notebooks/1.3-intro-agents-with-langchain.ipynb\n",
    "# SET YOUR API KEYS FOR LANGSMITH AND TAVILY TO RUN THIS NOTEBOOK!\n",
    "# langsmith: https://docs.smith.langchain.com/#:~:text=install%20-U%20langsmith-,Create%20an%20API%20key,click%20Create%20API%20Key.,-Setup%20your%20environment\n",
    "# tavily: https://app.tavily.com/sign-in\n",
    "# openai: https://platform.openai.com/docs/quickstart\n",
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"your-api-key\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"your-api-key\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE: Create a simple agent that performs a productive task, whatever that means for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:43.898423Z",
     "iopub.status.busy": "2024-07-18T12:08:43.898185Z",
     "iopub.status.idle": "2024-07-18T12:08:44.199173Z",
     "shell.execute_reply": "2024-07-18T12:08:44.198870Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:44.200738Z",
     "iopub.status.busy": "2024-07-18T12:08:44.200672Z",
     "iopub.status.idle": "2024-07-18T12:08:44.227749Z",
     "shell.execute_reply": "2024-07-18T12:08:44.227492Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:44.229070Z",
     "iopub.status.busy": "2024-07-18T12:08:44.229007Z",
     "iopub.status.idle": "2024-07-18T12:08:46.833560Z",
     "shell.execute_reply": "2024-07-18T12:08:46.832411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/List_of_highest_mountains_on_Earth',\n",
       "  'content': \"88 | 4\\n87 |\\n86 | 1\\n85 | 8 1\\n84 | 8\\n83 |\\n82 |\\n81 | 8 6 6 2\\n80 | 9 8 5 3 2\\n79 | 5 4 3 3\\n78 | 9 8 7 6 2 2 1 0\\n77 | 9 9 8 8 5 5 4 1 0 0\\n76 |\\n9 7 6 6 4 1 1\\n75 | 7 7 5 5 4 4 4 3 3 1 1\\n74 | 9 9 9 9 7 6 6 6 5 5 3 3 2 2 2 1 1 1 0 0 0\\n73 | 8 8 8 8 8 6 6 5 5 5 4 2 1 1 1 0\\n72 | 9 9 9 8 8 8 8 7 7 6 6 5 4 4 4 3 2 2 1 1 0 0 0 0 0 0 0\\nGallery[edit]\\n1. All peaks 7,000\\xa0m (23,000\\xa0ft) or higher are located in East, Central or South Asia in a rectangle edged by Noshaq (7,492\\xa0m or 24,580\\xa0ft) on the Afghanistan–Pakistan border in the west, Jengish Chokusu (Tuōmù'ěr Fēng, 7,439\\xa0m or 24,406\\xa0ft) on the Kyrgyzstan–Xinjiang border to the north, Gongga Shan (Minya Konka, 7,556\\xa0m or 24,790\\xa0ft) in Sichuan to the east, and Kabru (7,412\\xa0m or 24,318\\xa0ft) on the Sikkim–Nepal border to the south.\\n Mauna Loa (4,169\\xa0m or 13,678\\xa0ft) is the largest mountain on Earth in terms of base area (about 2,000\\xa0sq\\xa0mi or 5,200\\xa0km2) and volume (about 10,000\\xa0cu\\xa0mi or 42,000\\xa0km3), although, due to the intergrade of lava from Kilauea, Hualalai and Mauna Kea, the volume can only be estimated based on surface area and height of the edifice. The two digits to the left of the line are the first two digits of the mountain's height (metres), and each digit to the right of the line represents the third digit of the mountain's height. Ojos del Salado has the greatest rise on Earth: 13,420\\xa0m (44,029\\xa0ft) vertically to the summit[citation needed] from the bottom of the Atacama Trench, which is about 560\\xa0km (350\\xa0mi) away, although most of this rise is not part of the mountain.\\n\"},\n",
       " {'url': 'https://www.treehugger.com/tallest-mountains-in-the-world-5183890',\n",
       "  'content': \"This section of the Himalayas also blends into eastern Nepal, and the region hosts about 2,000 species of flowering plants, 252 species of birds, and a few of the country’s most endangered mammals, such as the snow leopard and the red panda. In 1950, Maurice Herzog and Louis Lachenal were the first to reach the summit (losing their toes and fingers to frostbite as a result), marking the first of the Earth’s 14 eight-thousanders to be scaled; another successful climb wasn’t achieved until 20 years later.\\n The 642-square-mile Manaslu Conservation Area was declared in 1998 to protect the habitats of the 33 mammal species, 110 bird species, 11 butterfly species, and three reptile species that live in the Manaslu region in the North Nepalese Himalayas.\\n Nanga Parbat (Pakistan)\\nNanga Parbat earned its reputation as the “Killer Mountain” after a total of 26 people died attempting to reach the summit before its first ascent in 1953 (a feat completed by Austrian climber Hermann Buhl, who performed the climb without the use of supplementary oxygen).\\n Although it's considered to be another one of the easiest and shortest of the 8000-meter mountains, Shishapangma claimed the life of one of the world’s most famous climbers, Alex Lowe, after an avalanche struck on October 5, 1999 (his body wasn’t recovered until 16 years later).\"},\n",
       " {'url': 'https://www.worldatlas.com/mountains/10-highest-mountains-in-the-world.html',\n",
       "  'content': \"Several studies have revealed that there are approximately 108 high mountains on the planet that reach an elevation of more than 7,200m. A majority of the world’s tallest summits are situated on the edges of the Indian and Eurasian tectonic plates in the countries of Nepal, India, China, and Pakistan and are part of the Himalayan and Karakoram Mountain Ranges. Isla Mujeres\\nThe Deepest Canyons In The United States\\nThe Longest Caves in the World\\n11 of America's Most Famous Geysers\\nThe Deepest Caves In The World\\nIce Sheets\\nAll maps, graphics, flags, photos and original descriptions © 2024 worldatlas.com Mount Dhaulagiri I – 8,167m\\nMount Dhaulagiri I which rises to an elevation of 8,167m is the world’s seventh-highest mountain and the highest mountain situated entirely within the boundaries of the country Nepal. \\xa0 It is situated in the Mahalangur Himal section of the Himalayan Mountain Range, along the boundary between the Khumbu region of Nepal and the Tibet Autonomous Region of China. The Dhaulagiri massif is bounded by the Myagdi Khola River in the southeast and by the tributaries of the Bheri River in the southwest.\"},\n",
       " {'url': 'https://geology.com/records/highest-mountain-in-the-world.shtml',\n",
       "  'content': 'That shape makes it possible for the top of Chimborazo, which is located slightly south of the equator (and shorter than Mount Everest) to be farther from the center of the Earth than the top of Mount Everest (which is a considerable distance north of the equator).\\n However, the top of Chimborazo is farther from the center of the Earth than the top of Mount Everest and the top of Mauna Kea.\\n However, Mauna Kea is an island, and if the distance from the bottom of the nearby Pacific Ocean floor to the peak of the island is measured, then Mauna Kea is \"taller\" than Mount Everest.\\n Highest Mountain\\nHighest Mountain in the World\\nMount Everest: Highest Altitude\\nHighest Altitude: An altitude of 8,848.86 meters (29,031.69 feet) above sea level makes Mount Everest the mountain on Earth with the highest altitude.\\n In the diagram above, the gray dashed line is a perfect circle, and the solid blue line represents the shape of the Earth (exaggerated a bit to make its departure from spherical obvious).'},\n",
       " {'url': 'https://www.mountainiq.com/highest-mountains-in-the-world/',\n",
       "  'content': 'In South America\\nPopular Mountains\\nAconcagua\\nMont Blanc\\nMount Kenya\\nMount Kilimanjaro\\n7 Summits\\n8000ers\\nMOUNTAINS\\nAfrica\\nAntarctica\\nAsia\\nAustralia & Oceania\\nEurope\\nNorth America\\nSouth & Central America\\nAll Mountain Guides\\nGear\\nAll Gear Reviews\\nPacking Lists\\ncompany\\nAbout\\nNews and Opinions\\nContact\\nOur Family\\nClimb Kilimanjaro Guide\\nMachu Picchu Trek\\nEBC Trek Guide\\nOur 5 Star reviews\\nSee TripAdvisor Reviews\\nSee Google Reviews\\ncontact\\nsocial\\nPrivacy | Terms | DMCA | Affiliate Disclosure\\xa0|\\xa0Site Map\\nAs an Amazon Associate, Mountain IQ earns from qualifying purchases.\\n The other four 8000s are:\\nTallest Mountains In The World On Each Continent\\nAs you may have noticed, all of the worlds highest mountains arein the Asian mountain ranges This is a little boring if you want to do mountain climbing by destination. Also Read: The Most Beautiful Mountains In The World\\nAbout the author\\nWith a degree in Nature Conservation and experience working with wildlife including the Big 5, Alison used to work as a guide for a 5-star safari reserve in South Africa. Everest and Nanga Parbat are the only two mountains in the world that rank amongst the tallest mountains in the world as well as the top 20 most prominent peaks.\\n In total, there are 14 mountains in the world with summits above 8000m. Even though the last few didn’t make the cut as top 10 tallest mountains in the world, they are giants in their own right and deserve some credit.'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import tool\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "results = search.invoke(\"biggest moutains in the world\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:46.860792Z",
     "iopub.status.busy": "2024-07-18T12:08:46.860599Z",
     "iopub.status.idle": "2024-07-18T12:08:48.358523Z",
     "shell.execute_reply": "2024-07-18T12:08:48.357833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.medicinenet.com/are_pancakes_healthy_or_unhealthy_breakfast_food/article.htm',\n",
       " 'https://www.eatingwell.com/article/17772/which-is-a-healthier-breakfast-pancakes-or-eggs/',\n",
       " 'https://www.chefsresource.com/faq/is-pancakes-good-for-breakfast/',\n",
       " 'https://www.popsugar.com/food/why-pancakes-better-than-waffles-46335811',\n",
       " 'https://fitonapp.com/nutrition/healthy-pancakes/']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import tool\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str):\n",
    "    \"\"\"Searches the web given a user query and returns the most relevant links\"\"\"\n",
    "    output = search.invoke(query)\n",
    "    return [r['url'] for r in output if type(r)==dict]\n",
    "\n",
    "web_search.invoke(\"Current resources on why pancakes are the best breakfast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:48.361546Z",
     "iopub.status.busy": "2024-07-18T12:08:48.361362Z",
     "iopub.status.idle": "2024-07-18T12:08:48.986478Z",
     "shell.execute_reply": "2024-07-18T12:08:48.986253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:48.987834Z",
     "iopub.status.busy": "2024-07-18T12:08:48.987766Z",
     "iopub.status.idle": "2024-07-18T12:08:48.989798Z",
     "shell.execute_reply": "2024-07-18T12:08:48.989587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent_scratchpad', 'input']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:48.991045Z",
     "iopub.status.busy": "2024-07-18T12:08:48.990966Z",
     "iopub.status.idle": "2024-07-18T12:08:48.992560Z",
     "shell.execute_reply": "2024-07-18T12:08:48.992403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]],\n",
       " 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:48.993702Z",
     "iopub.status.busy": "2024-07-18T12:08:48.993634Z",
     "iopub.status.idle": "2024-07-18T12:08:48.995512Z",
     "shell.execute_reply": "2024-07-18T12:08:48.995348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'input_variables': ['agent_scratchpad', 'input'],\n",
       " 'input_types': {'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]],\n",
       "  'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]},\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'metadata': {'lc_hub_owner': 'hwchase17',\n",
       "  'lc_hub_repo': 'openai-tools-agent',\n",
       "  'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'},\n",
       " 'tags': None,\n",
       " 'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       "  MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       "  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       "  MessagesPlaceholder(variable_name='agent_scratchpad')],\n",
       " 'validate_template': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build an agent I need to do 2 essential things:\n",
    "\n",
    "1. Connect a model to tools\n",
    "2. Set up a loop in which the model continuously tries to solve the problem by either just calling the llm or calling a tool, observing the result and repeating until finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:48.996669Z",
     "iopub.status.busy": "2024-07-18T12:08:48.996598Z",
     "iopub.status.idle": "2024-07-18T12:08:48.998327Z",
     "shell.execute_reply": "2024-07-18T12:08:48.998123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:48.999431Z",
     "iopub.status.busy": "2024-07-18T12:08:48.999364Z",
     "iopub.status.idle": "2024-07-18T12:08:49.001319Z",
     "shell.execute_reply": "2024-07-18T12:08:49.001138Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "tools = [web_search]\n",
    "\n",
    "agent = create_tool_calling_agent(llm_chat, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:49.002473Z",
     "iopub.status.busy": "2024-07-18T12:08:49.002396Z",
     "iopub.status.idle": "2024-07-18T12:08:49.003923Z",
     "shell.execute_reply": "2024-07-18T12:08:49.003748Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:49.005025Z",
     "iopub.status.busy": "2024-07-18T12:08:49.004952Z",
     "iopub.status.idle": "2024-07-18T12:08:54.888606Z",
     "shell.execute_reply": "2024-07-18T12:08:54.887656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'resources to learn new languages'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.fluentu.com/blog/learn/free-language-learning-websites/', 'https://nymag.com/strategist/article/how-to-learn-languages-at-home.html', 'https://www.businessinsider.com/guides/learning/best-online-apps-courses-to-learn-new-language?op=1', 'https://www.theintrepidguide.com/top-language-learning-resources/', 'https://www.pcmag.com/picks/the-best-language-learning-software']\u001b[0m\u001b[32;1m\u001b[1;3mHere are some resources to learn new languages:\n",
      "\n",
      "1. [FluentU - Free Language Learning Websites](https://www.fluentu.com/blog/learn/free-language-learning-websites/)\n",
      "2. [NYMag - How to Learn Languages at Home](https://nymag.com/strategist/article/how-to-learn-languages-at-home.html)\n",
      "3. [Business Insider - Best Online Apps and Courses to Learn New Language](https://www.businessinsider.com/guides/learning/best-online-apps-courses-to-learn-new-language?op=1)\n",
      "4. [The Intrepid Guide - Top Language Learning Resources](https://www.theintrepidguide.com/top-language-learning-resources/)\n",
      "5. [PCMag - The Best Language Learning Software](https://www.pcmag.com/picks/the-best-language-learning-software)\n",
      "\n",
      "You can explore these resources to find the best fit for your language learning journey.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are good resources to learn about learning new languages?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'Here are some resources to learn new languages:\\n\\n1. [FluentU - Free Language Learning Websites](https://www.fluentu.com/blog/learn/free-language-learning-websites/)\\n2. [NYMag - How to Learn Languages at Home](https://nymag.com/strategist/article/how-to-learn-languages-at-home.html)\\n3. [Business Insider - Best Online Apps and Courses to Learn New Language](https://www.businessinsider.com/guides/learning/best-online-apps-courses-to-learn-new-language?op=1)\\n4. [The Intrepid Guide - Top Language Learning Resources](https://www.theintrepidguide.com/top-language-learning-resources/)\\n5. [PCMag - The Best Language Learning Software](https://www.pcmag.com/picks/the-best-language-learning-software)\\n\\nYou can explore these resources to find the best fit for your language learning journey.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What are good resources to learn about learning new languages?\",\n",
    "                             \"agent_scratchpad\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:08:54.892947Z",
     "iopub.status.busy": "2024-07-18T12:08:54.892739Z",
     "iopub.status.idle": "2024-07-18T12:09:02.096458Z",
     "shell.execute_reply": "2024-07-18T12:09:02.095782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mLearning good programming practices is essential for becoming a successful programmer.\n",
      "Action: web_search\n",
      "Action Input: \"best way to learn good programming practices\"\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m['https://www.datacamp.com/tutorial/coding-best-practices-and-guidelines', 'https://www.educative.io/blog/coding-best-practices', 'https://stackoverflow.com/questions/1301606/how-can-i-practice-better-object-oriented-programming', 'https://www.freecodecamp.org/news/learn-coding-for-everyone-handbook/', 'https://www.freecodecamp.org/news/how-to-learn-programming/']\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThere are several resources available online to learn good programming practices.\n",
      "Action: web_search\n",
      "Action Input: \"coding best practices tutorial\"\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m['https://www.datacamp.com/tutorial/coding-best-practices-and-guidelines', 'https://www.freecodecamp.org/news/clean-coding-for-beginners/', 'https://www.freecodecamp.org/news/how-to-write-clean-code/', 'https://realpython.com/tutorials/best-practices/', 'https://www.datacamp.com/blog/python-best-practices-for-better-code']\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI should explore these tutorials and articles to understand and practice good programming practices.\n",
      "Final Answer: The best way to learn good programming practices is to explore tutorials and articles available online that cover coding best practices.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the best way to learn good programming practices?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'The best way to learn good programming practices is to explore tutorials and articles available online that cover coding best practices.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(llm_chat, tools, prompt)\n",
    "\n",
    "react_agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "react_agent_executor.invoke({\"input\": \"What is the best way to learn good programming practices?\",\n",
    "                             \"agent_scratchpad\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build this same agent but using a more in depth approach going one level down in the abstraction layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go down the latter of abstraction and build this same agent but leveraging the lower-level capabilities of LangChain's LCEL language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.101366Z",
     "iopub.status.busy": "2024-07-18T12:09:02.100902Z",
     "iopub.status.idle": "2024-07-18T12:09:02.105195Z",
     "shell.execute_reply": "2024-07-18T12:09:02.104089Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.108994Z",
     "iopub.status.busy": "2024-07-18T12:09:02.108616Z",
     "iopub.status.idle": "2024-07-18T12:09:02.156066Z",
     "shell.execute_reply": "2024-07-18T12:09:02.155647Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_chat = ChatOpenAI(model=\"gpt-4o\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.158259Z",
     "iopub.status.busy": "2024-07-18T12:09:02.158127Z",
     "iopub.status.idle": "2024-07-18T12:09:02.161908Z",
     "shell.execute_reply": "2024-07-18T12:09:02.161579Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import tool\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str):\n",
    "    \"\"\"Searches the web given a user query and returns the most relevant links\"\"\"\n",
    "    output = search.invoke(query)\n",
    "    return [r['url'] for r in output if type(r)==dict]\n",
    "\n",
    "\n",
    "tools = [web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.163602Z",
     "iopub.status.busy": "2024-07-18T12:09:02.163483Z",
     "iopub.status.idle": "2024-07-18T12:09:02.165310Z",
     "shell.execute_reply": "2024-07-18T12:09:02.165045Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.166678Z",
     "iopub.status.busy": "2024-07-18T12:09:02.166594Z",
     "iopub.status.idle": "2024-07-18T12:09:02.168560Z",
     "shell.execute_reply": "2024-07-18T12:09:02.168326Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \"You are a powerful research assistant.\\\n",
    "            Given a user query you will perform research on the \\\n",
    "                topic using the tools available.\"\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bind tools to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.169989Z",
     "iopub.status.busy": "2024-07-18T12:09:02.169902Z",
     "iopub.status.idle": "2024-07-18T12:09:02.171966Z",
     "shell.execute_reply": "2024-07-18T12:09:02.171746Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_with_tools = llm_chat.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we have to do is import two last utility functions:\n",
    "- a component for formatting intermediate steps (agent action, tool output pairs) to input messages that can be sent to the model, \n",
    "- and a component for converting the output message into an agent action/agent finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.173508Z",
     "iopub.status.busy": "2024-07-18T12:09:02.173422Z",
     "iopub.status.idle": "2024-07-18T12:09:02.174874Z",
     "shell.execute_reply": "2024-07-18T12:09:02.174681Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.tools import format_to_tool_messages\n",
    "from langchain.agents.output_parsers import ToolsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.176062Z",
     "iopub.status.busy": "2024-07-18T12:09:02.175985Z",
     "iopub.status.idle": "2024-07-18T12:09:02.177969Z",
     "shell.execute_reply": "2024-07-18T12:09:02.177741Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"], \n",
    "        \"agent_scratchpad\": lambda x: format_to_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | ToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.179196Z",
     "iopub.status.busy": "2024-07-18T12:09:02.179123Z",
     "iopub.status.idle": "2024-07-18T12:09:02.180764Z",
     "shell.execute_reply": "2024-07-18T12:09:02.180545Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:02.181933Z",
     "iopub.status.busy": "2024-07-18T12:09:02.181863Z",
     "iopub.status.idle": "2024-07-18T12:09:12.639322Z",
     "shell.execute_reply": "2024-07-18T12:09:12.638203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'open source large language models resources'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m['https://llama.meta.com/llama2/', 'https://llama.meta.com/', 'https://www.datacamp.com/blog/top-open-source-llms', 'https://ai.meta.com/blog/meta-llama-3/', 'https://github.com/Hannibal046/Awesome-LLM']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'best open source large language models 2023'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m['https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en', 'https://huggingface.co/blog/2023-in-llms', 'https://www.shakudo.io/blog/comparing-opensource-large-language-models', 'https://www.clarifai.com/blog/top-10-open-source-large-language-models-in-2023', 'https://www.lakera.ai/blog/open-source-llms']\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHere are some good resources about open source large language models:\n",
      "\n",
      "1. **Meta's LLaMA (Large Language Model Meta AI)**\n",
      "   - [LLaMA 2](https://llama.meta.com/llama2/)\n",
      "   - [LLaMA](https://llama.meta.com/)\n",
      "   - [Meta AI Blog on LLaMA 3](https://ai.meta.com/blog/meta-llama-3/)\n",
      "\n",
      "2. **DataCamp Blog**\n",
      "   - [Top Open Source LLMs](https://www.datacamp.com/blog/top-open-source-llms)\n",
      "\n",
      "3. **GitHub Repository**\n",
      "   - [Awesome LLM](https://github.com/Hannibal046/Awesome-LLM)\n",
      "\n",
      "4. **CheatSheet.md**\n",
      "   - [LLM Leaderboard: Best Open Source LLM](https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en)\n",
      "\n",
      "5. **Hugging Face Blog**\n",
      "   - [2023 in LLMs](https://huggingface.co/blog/2023-in-llms)\n",
      "\n",
      "6. **Shakudo Blog**\n",
      "   - [Comparing Open Source Large Language Models](https://www.shakudo.io/blog/comparing-opensource-large-language-models)\n",
      "\n",
      "7. **Clarifai Blog**\n",
      "   - [Top 10 Open Source Large Language Models in 2023](https://www.clarifai.com/blog/top-10-open-source-large-language-models-in-2023)\n",
      "\n",
      "8. **Lakera Blog**\n",
      "   - [Open Source LLMs](https://www.lakera.ai/blog/open-source-llms)\n",
      "\n",
      "These resources provide a comprehensive overview of the best open source large language models available, their features, and comparisons.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='web_search', tool_input={'query': 'open source large language models resources'}, log=\"\\nInvoking: `web_search` with `{'query': 'open source large language models resources'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31'}, id='run-519eeb64-5938-4b64-9918-0af8e5034324', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'type': 'tool_call'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'index': 1, 'type': 'tool_call_chunk'}])], tool_call_id='call_azX6KCUwWb6kB2TpvAvG6Jem')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31'}, id='run-519eeb64-5938-4b64-9918-0af8e5034324', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'type': 'tool_call'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'index': 1, 'type': 'tool_call_chunk'}])]},\n",
       " {'actions': [ToolAgentAction(tool='web_search', tool_input={'query': 'best open source large language models 2023'}, log=\"\\nInvoking: `web_search` with `{'query': 'best open source large language models 2023'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31'}, id='run-519eeb64-5938-4b64-9918-0af8e5034324', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'type': 'tool_call'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'index': 1, 'type': 'tool_call_chunk'}])], tool_call_id='call_32hx2DuacrlXsmQmh5r2qTwm')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31'}, id='run-519eeb64-5938-4b64-9918-0af8e5034324', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'type': 'tool_call'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'index': 1, 'type': 'tool_call_chunk'}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='web_search', tool_input={'query': 'open source large language models resources'}, log=\"\\nInvoking: `web_search` with `{'query': 'open source large language models resources'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31'}, id='run-519eeb64-5938-4b64-9918-0af8e5034324', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'type': 'tool_call'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'index': 1, 'type': 'tool_call_chunk'}])], tool_call_id='call_azX6KCUwWb6kB2TpvAvG6Jem'), observation=['https://llama.meta.com/llama2/', 'https://llama.meta.com/', 'https://www.datacamp.com/blog/top-open-source-llms', 'https://ai.meta.com/blog/meta-llama-3/', 'https://github.com/Hannibal046/Awesome-LLM'])],\n",
       "  'messages': [FunctionMessage(content='[\"https://llama.meta.com/llama2/\", \"https://llama.meta.com/\", \"https://www.datacamp.com/blog/top-open-source-llms\", \"https://ai.meta.com/blog/meta-llama-3/\", \"https://github.com/Hannibal046/Awesome-LLM\"]', name='web_search')]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='web_search', tool_input={'query': 'best open source large language models 2023'}, log=\"\\nInvoking: `web_search` with `{'query': 'best open source large language models 2023'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31'}, id='run-519eeb64-5938-4b64-9918-0af8e5034324', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'type': 'tool_call'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_azX6KCUwWb6kB2TpvAvG6Jem', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_32hx2DuacrlXsmQmh5r2qTwm', 'index': 1, 'type': 'tool_call_chunk'}])], tool_call_id='call_32hx2DuacrlXsmQmh5r2qTwm'), observation=['https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en', 'https://huggingface.co/blog/2023-in-llms', 'https://www.shakudo.io/blog/comparing-opensource-large-language-models', 'https://www.clarifai.com/blog/top-10-open-source-large-language-models-in-2023', 'https://www.lakera.ai/blog/open-source-llms'])],\n",
       "  'messages': [FunctionMessage(content='[\"https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en\", \"https://huggingface.co/blog/2023-in-llms\", \"https://www.shakudo.io/blog/comparing-opensource-large-language-models\", \"https://www.clarifai.com/blog/top-10-open-source-large-language-models-in-2023\", \"https://www.lakera.ai/blog/open-source-llms\"]', name='web_search')]},\n",
       " {'output': \"Here are some good resources about open source large language models:\\n\\n1. **Meta's LLaMA (Large Language Model Meta AI)**\\n   - [LLaMA 2](https://llama.meta.com/llama2/)\\n   - [LLaMA](https://llama.meta.com/)\\n   - [Meta AI Blog on LLaMA 3](https://ai.meta.com/blog/meta-llama-3/)\\n\\n2. **DataCamp Blog**\\n   - [Top Open Source LLMs](https://www.datacamp.com/blog/top-open-source-llms)\\n\\n3. **GitHub Repository**\\n   - [Awesome LLM](https://github.com/Hannibal046/Awesome-LLM)\\n\\n4. **CheatSheet.md**\\n   - [LLM Leaderboard: Best Open Source LLM](https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en)\\n\\n5. **Hugging Face Blog**\\n   - [2023 in LLMs](https://huggingface.co/blog/2023-in-llms)\\n\\n6. **Shakudo Blog**\\n   - [Comparing Open Source Large Language Models](https://www.shakudo.io/blog/comparing-opensource-large-language-models)\\n\\n7. **Clarifai Blog**\\n   - [Top 10 Open Source Large Language Models in 2023](https://www.clarifai.com/blog/top-10-open-source-large-language-models-in-2023)\\n\\n8. **Lakera Blog**\\n   - [Open Source LLMs](https://www.lakera.ai/blog/open-source-llms)\\n\\nThese resources provide a comprehensive overview of the best open source large language models available, their features, and comparisons.\",\n",
       "  'messages': [AIMessage(content=\"Here are some good resources about open source large language models:\\n\\n1. **Meta's LLaMA (Large Language Model Meta AI)**\\n   - [LLaMA 2](https://llama.meta.com/llama2/)\\n   - [LLaMA](https://llama.meta.com/)\\n   - [Meta AI Blog on LLaMA 3](https://ai.meta.com/blog/meta-llama-3/)\\n\\n2. **DataCamp Blog**\\n   - [Top Open Source LLMs](https://www.datacamp.com/blog/top-open-source-llms)\\n\\n3. **GitHub Repository**\\n   - [Awesome LLM](https://github.com/Hannibal046/Awesome-LLM)\\n\\n4. **CheatSheet.md**\\n   - [LLM Leaderboard: Best Open Source LLM](https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en)\\n\\n5. **Hugging Face Blog**\\n   - [2023 in LLMs](https://huggingface.co/blog/2023-in-llms)\\n\\n6. **Shakudo Blog**\\n   - [Comparing Open Source Large Language Models](https://www.shakudo.io/blog/comparing-opensource-large-language-models)\\n\\n7. **Clarifai Blog**\\n   - [Top 10 Open Source Large Language Models in 2023](https://www.clarifai.com/blog/top-10-open-source-large-language-models-in-2023)\\n\\n8. **Lakera Blog**\\n   - [Open Source LLMs](https://www.lakera.ai/blog/open-source-llms)\\n\\nThese resources provide a comprehensive overview of the best open source large language models available, their features, and comparisons.\")]}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"What are some good resources about open source large language models?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we want the agent to actually read the links and return a research report rather than just the urls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:12.645194Z",
     "iopub.status.busy": "2024-07-18T12:09:12.644890Z",
     "iopub.status.idle": "2024-07-18T12:09:12.679988Z",
     "shell.execute_reply": "2024-07-18T12:09:12.679735Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_text(url: str):\n",
    "    \"\"\"Scrapes the text from a given URL and returns it.\"\"\"\n",
    "    # Send a GET request to the webpage\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the content of the request with BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # Extract all text from the webpage\n",
    "            page_text = soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "            # Print the extracted text\n",
    "            return page_text[:10000]\n",
    "        else:\n",
    "            return f\"Failed to retrieve the webpage: Status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Failed to retrieve the webpage: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:12.681763Z",
     "iopub.status.busy": "2024-07-18T12:09:12.681671Z",
     "iopub.status.idle": "2024-07-18T12:09:12.683416Z",
     "shell.execute_reply": "2024-07-18T12:09:12.683160Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [web_search, scrape_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:12.684806Z",
     "iopub.status.busy": "2024-07-18T12:09:12.684717Z",
     "iopub.status.idle": "2024-07-18T12:09:12.687096Z",
     "shell.execute_reply": "2024-07-18T12:09:12.686861Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_with_tools = llm_chat.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:12.688371Z",
     "iopub.status.busy": "2024-07-18T12:09:12.688291Z",
     "iopub.status.idle": "2024-07-18T12:09:12.690194Z",
     "shell.execute_reply": "2024-07-18T12:09:12.689995Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:12.691421Z",
     "iopub.status.busy": "2024-07-18T12:09:12.691345Z",
     "iopub.status.idle": "2024-07-18T12:09:12.693015Z",
     "shell.execute_reply": "2024-07-18T12:09:12.692782Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \"You are a powerful research assistant. Given a user query you will perform research on the topic using the tools available.\"\n",
    "        ),\n",
    "        (\"user\", \"Scrape and summarize the contents from these urls: {input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:12.694372Z",
     "iopub.status.busy": "2024-07-18T12:09:12.694297Z",
     "iopub.status.idle": "2024-07-18T12:09:12.696028Z",
     "shell.execute_reply": "2024-07-18T12:09:12.695790Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"], \n",
    "        \"agent_scratchpad\": lambda x: format_to_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | ToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:12.697227Z",
     "iopub.status.busy": "2024-07-18T12:09:12.697147Z",
     "iopub.status.idle": "2024-07-18T12:09:12.698737Z",
     "shell.execute_reply": "2024-07-18T12:09:12.698551Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:12.699887Z",
     "iopub.status.busy": "2024-07-18T12:09:12.699804Z",
     "iopub.status.idle": "2024-07-18T12:09:40.340640Z",
     "shell.execute_reply": "2024-07-18T12:09:40.339338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'How to build a simple research agent using langchain in Python'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m['https://python.langchain.com/v0.2/docs/tutorials/agents/', 'https://towardsdatascience.com/building-a-simple-agent-with-tools-and-toolkits-in-langchain-77e0f9bd1fa5', 'https://dev.to/timesurgelabs/how-to-make-an-ai-agent-in-10-minutes-with-langchain-3i2n', 'https://build5nines.com/introduction-to-building-ai-agents-with-langchain-and-python/', 'https://analyzingalpha.com/langchain-python-tutorial']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'Langchain research agent tutorial'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m['https://python.langchain.com/v0.2/docs/tutorials/agents/', 'https://medium.com/@ranadevrat/understanding-langchain-agents-a-beginners-guide-8a87708dc48e', 'https://dev.to/timesurgelabs/how-to-make-an-ai-agent-in-10-minutes-with-langchain-3i2n', 'https://js.langchain.com/v0.2/docs/tutorials/agents/', 'https://blog.langchain.dev/how-to-build-the-ultimate-ai-automation-with-multi-agent-collaboration/']\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://python.langchain.com/v0.2/docs/tutorials/agents/'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mBuild an Agent | 🦜️🔗 LangChain Skip to main content LangChain 0.2 is out! Leave feedback on the v0.2 docs here . You can view the v0.1 docs here . Integrations API Reference More People Contributing Templates Cookbooks 3rd party tutorials YouTube arXiv v0.2 v0.2 v0.1 🦜️🔗 LangSmith LangSmith Docs Templates GitHub Templates Hub LangChain Hub JS/TS Docs 💬 Search Introduction Tutorials Build a Question Answering application over a Graph Database Tutorials Build a Simple LLM Application with LCEL Build a Query Analysis System Build a Chatbot Conversational RAG Build an Extraction Chain Build an Agent Tagging data_generation Build a Local RAG Application Build a PDF ingestion and Question/Answering system Build a Retrieval Augmented Generation (RAG) App Vector stores and retrievers Build a Question/Answering system over SQL data Summarize Text How-to guides How-to guides How to use tools in a chain How to use a vectorstore as a retriever How to add memory to chatbots How to use example selectors How to map values to a graph database How to add a semantic layer over graph database How to invoke runnables in parallel How to stream chat model responses How to add default invocation args to a Runnable How to add retrieval to chatbots How to use few shot examples in chat models How to do tool/function calling How to best prompt for Graph-RAG How to install LangChain packages How to add examples to the prompt for query analysis How to use few shot examples How to run custom functions How to use output parsers to parse an LLM response into structured format How to handle cases where no queries are generated How to route between sub-chains How to return structured data from a model How to use toolkits How to add ad-hoc tool calling capability to LLMs and Chat Models Build an Agent with AgentExecutor (Legacy) How to construct knowledge graphs How to partially format prompt templates How to handle multiple queries when doing query analysis How to use built-in tools and toolkits How to pass through arguments from one step to the next How to compose prompts together How to handle multiple retrievers when doing query analysis How to add values to a chain's state How to construct filters for query analysis How to configure runtime chain internals How deal with high cardinality categoricals when doing query analysis Custom Document Loader How to split by HTML header How to split by HTML sections How to use the MultiQueryRetriever How to add scores to retriever results Caching How to use callbacks in async environments How to attach callbacks to a runnable How to propagate callbacks  constructor How to dispatch custom callback events How to pass callbacks in at runtime How to split by character How to cache chat model responses How to init any model in one line How to track token usage in ChatModels How to add tools to chatbots How to split code How to do retrieval with contextual compression How to convert Runnables as Tools How to create custom callback handlers How to create a custom chat model class How to create a custom LLM class Custom Retriever How to create tools How to debug your LLM apps How to load CSVs How to load documents from a directory How to load HTML How to load JSON How to load Markdown How to load Microsoft Office files How to load PDFs How to create a dynamic (self-constructing) chain Text embedding models How to combine results from multiple retrievers How to select examples by length How to select examples by maximal marginal relevance (MMR) How to select examples by n-gram overlap How to select examples by similarity How to use reference examples when doing extraction How to handle long text when doing extraction How to use prompting alone (no tool calling) to do extraction How to add fallbacks to a runnable How to filter messages Hybrid Search How to use the LangChain indexing API How to inspect runnables LangChain Expression Language Cheatsheet How to cache LLM responses How to track token usage for LLMs Run LLMs locally How to get log probabilities How to reorder retrieved results to mitigate the \"lost in the middle\" effect How to split Markdown by Headers How to merge consecutive messages of the same type How to add message history How to migrate from legacy LangChain agents to LangGraph How to migrate chains to LCEL How to retrieve using multiple vectors per document How to pass multimodal data directly to models How to use multimodal prompts How to create a custom Output Parser How to use the output-fixing parser How to parse JSON output How to retry when a parsing error occurs How to parse XML output How to parse YAML output How to use the Parent Document Retriever How to use LangChain with different Pydantic versions How to add chat history How to get a RAG application to add citations How to do per-user retrieval How to get your RAG application to return sources How to stream results from your RAG application How to split JSON data How to recursively split text by characters Response metadata How to do \"self-querying\" retrieval How to split text based on semantic similarity How to chain runnables How to save and load LangChain objects How to split text by tokens How to do question answering over CSVs How to deal with large databases when doing SQL question-answering How to better prompt when doing SQL question-answering How to do query validation as part of SQL question-answering How to stream runnables How to stream responses from an LLM How to use a time-weighted vector store retriever How to return artifacts from a tool How to use chat models to call tools How to disable parallel tool calling How to force models to call a tool How to access the RunnableConfig from a tool How to pass tool outputs to chat models How to pass run time values to tools How to stream events from a tool How to stream tool calls How to convert tools to OpenAI Functions How to handle tool errors How to use few-shot prompting with tool calling How to add a human-in-the-loop for tools How to bind model-specific tools How to trim messages How to create and query vector stores Conceptual guide Ecosystem 🦜🛠️ LangSmith 🦜🕸️ LangGraph Versions Overview Release Policy Packages v0.2 LangChain v0.2 astream_events v2 Changes Security Tutorials Build an Agent On this page Build an Agent Prerequisites This guide assumes familiarity with the following concepts: Chat Models Tools Agents By themselves, language models can't take actions - they just output text.\n",
      "A big use case for LangChain is creating agents .\n",
      "Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs to pass them.\n",
      "After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. In this tutorial we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it. End-to-end agent ​ The code snippet below represents a fully functional agent that uses an LLM to decide which tools to use. It is equipped with a generic search tool. It has conversational memory - meaning that it can be used as a multi-turn chatbot. In the rest of the guide, we will walk through the individual components and what each part does - but if you want to just grab some code and get started, feel free to use this! # Import relevant functionality from langchain_anthropic import ChatAnthropic from langchain_community . tools . tavily_search import TavilySearchResults from langchain_core . messages import HumanMessage from langgraph . checkpoint . sqlite import SqliteSaver from langgraph . prebuilt import create_react_agent # Create the agent memory = SqliteSaver . from_conn_string ( \":memory:\" ) model = ChatAnthropic ( model_name = \"claude-3-sonnet-20240229\" ) search = TavilySearchResults ( max_results = 2 ) tools = [ search ] agent_executor = create_react_agent ( model , tools , checkpointer = memory ) # Use the agent config = { \"configurable\" : { \"thread_id\" : \"abc123\" } } for chunk in agent_executor . stream ( { \"messages\" : [ HumanMessage ( content = \"hi im bob! and i live in sf\" ) ] } , config ) : print ( chunk ) print ( \"----\" ) for chunk in agent_executor . stream ( { \"messages\" : [ HumanMessage ( content = \"whats the weather where I live?\" ) ] } , config ) : print ( chunk ) print ( \"----\" ) API Reference: ChatAnthropic | TavilySearchResults | HumanMessage {'agent': {'messages': [AIMessage(content=\"Hello Bob! Since you didn't ask a specific question, I don't need to use any tools to respond. It's nice to meet you. San Francisco is a wonderful city with lots to see and do. I hope you're enjoying living there. Please let me know if you have any other questions!\", response_metadata={'id': 'msg_01Mmfzfs9m4XMgVzsCZYMWqH', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 271, 'output_tokens': 65}}, id='run-44c57f9c-a637-4888-b7d9-6d985031ae48-0', usage_metadata={'input_tokens': 271, 'output_tokens': 65, 'total_tokens': 336})]}} ---- {'agent': {'messages': [AIMessage(content=[{'text': 'To get current weather information for your location in San Francisco, let me invoke the search tool:', 'type': 'text'}, {'id': 'toolu_01BGEyQaSz3pTq8RwUUHSRoo', 'input': {'query': 'san francisco weather'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], response_metadata={'id': 'msg_013AVSVsRLKYZjduLpJBY4us', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 347, 'output_tokens': 80}}, id='run-de7923b6-5ee2-4ebe-bd95-5aed4933d0e3-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'san francisco weather'}, 'id': 'toolu_01BGEyQaSz3pTq8RwUUHSRoo'}], usage_metadata={'input_tokens': 347, 'output_tokens': 80, 'total_tokens': 427})]}} ---- {'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'locati\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://towardsdatascience.com/building-a-simple-agent-with-tools-and-toolkits-in-langchain-77e0f9bd1fa5'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mBuilding a simple Agent with Tools and Toolkits in LangChain | by Sami Maameri | Towards Data Science Open in app Sign up Sign in Write Sign up Sign in Building a simple Agent with Tools and Toolkits in LangChain Get familiar with the building blocks of Agents in LangChain Sami Maameri · Follow Published in Towards Data Science · 13 min read · Apr 10, 2024 -- 1 Listen Share Photo by Dan LeFebvre on Unsplash Let’s build a simple agent in LangChain to help us understand some of the foundational concepts and building blocks for how agents work there. By keeping it simple we can get a better grasp of the foundational ideas behind these agents, allowing us to build more complex agents in the future. Contents What are Agents? Building the Agent - The Tools - The Toolkit - The LLM - The Prompt The Agent Testing our Agent Observations The Future Conclusion Want to get notified about my future posts? Subscribe here What are Agents The LangChain documentation actually has a pretty good page on the high level concepts around its agents. It’s a short easy read, and definitely worth skimming through before getting started. If you lookup the definition of AI Agents, you get something along the lines of “An entity that is able to perceive its environment, act on its environment, and make intelligent decisions about how to reach a goal it has been given, as well as the ability to learn as it goes” That fits the definition of LangChain agents pretty well I would say. What makes all this possible in software is the reasoning abilities of Large Language Model’s (LLM’s). The brains of a LangChain agent are an LLM. It is the LLM that is used to reason about the best way to carry out the ask requested by a user. In order to carry out its task, and operate on things and retrieve information, the agent has what are called Tool’s in LangChain, at its disposal. It is through these tools that it is able to interact with its environment. The tools are basically just methods/classes the agent has access to that can do things like interact with a Stock Market index over an API, update a Google Calendar event, or run a query against a database. We can build out tools as needed, depending on the nature of tasks we are trying to carry out with the agent to fulfil. A collection of Tools in LangChain are called a Toolkit. Implementation wise, this is literally just an array of the Tools that are available for the agent. As such, the high level overview of an agent in LangChain looks something like this Image by author So, at a basic level, an agent needs an LLM to act as its brain, and to give it its reasoning abilities tools so that it can interact with the environment around it and achieve its goals Building the Agent To make some of these concepts more concrete, let’s build a simple agent. We will create a Mathematics Agent that can perform a few simple mathematical operations. Environment setup First lets setup our environment and script mkdir simple-math-agent && cd simple-math-agent touch math-agent.py python3 -m venv .venv . .venv/bin/activate pip install langchain langchain_openai Alternatively, you can also clone the code used here from GitHub git clone git@github.com:smaameri/simple-math-agent.git or check out the code inside a Google Colab also. The Tools The simplest place to start will be to fist define the tools for our Maths agent. Let’s give it “add”, “multiply” and “square” tools, so that it can perform those operations on questions we pass to it. By keeping our tools simple we can focus on the core concepts, and build the tools ourselves, instead of relying on an existing and more complex tools like the WikipediaTool, that acts as a wrapper around the Wikipedia API, and requires us to import it from the LangChain library. Again, we are not trying to do anything fancy here, just keeping it simple and putting the main building blocks of an agent together so we can understand how they work, and get our first agent up and running. Let’s start with the “add” tool. The bottom up way to create a Tool in LangChain would be to extend the BaseTool class, set the name and description fields on the class, and implement the _run method. That would look like this from langchain_core.tools import BaseTool class AddTool(BaseTool): name = \"add\" description = \"Adds two numbers together\" args_schema: Type[BaseModel] = AddInput return_direct: bool = True def _run( self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None ) -> str: return a + b Notice that we need to implement the _run method to show what our tool does with the parameters that are passed to it. Notice also how it requires a pydantic model for the args_schema . We will define that here AddInput a: int = Field(description=\"first number\") b: int = Field(description=\"second number\") Now, LangChain does give us an easier way to define tools, then by needing to extend the BaseTool class each time. We can do this with the help of the @too l decorator. Defining the “add” tool in LangChain using the @tool decorator will look like this from langchain.tools import tool @tool def add(a: int, b: int) -> int: “””Adds two numbers together””” # this docstring gets used as the description return a + b # the actions our tool performs Much simpler right. Behind the scenes, the decorator magically uses the method provided to extend the BaseTool class, just as we did earlier. Some thing to note: the method name also becomes the tool name the method params define the input parameters for the tool the docstring gets converted into the tools description You can access these properties on the tool also print(add.name) # add print(add.description) # Adds two numbers together. print(add.args) # {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}} Note that the description of a tool is very important as this is what the LLM uses to decide whether or not it is the right tool for the job. A bad description may lead to the not tool getting used when it should be, or getting used at the wrong times. With the add tool done, let’s move on to the definitions for our multiply and square tools. @tool def multiply(a: int, b: int) -> int: \"\"\"Multiply two numbers.\"\"\" return a * b @tool def square(a) -> int: \"\"\"Calculates the square of a number.\"\"\" a = int(a) return a * a And that is it, simple as that. So we have defined our own three custom tools . A more common use case might be to use some of the already provided and existing tools in LangChain, which you can see here . However, at the source code level, they would all be built and defined using a similar methods as described above. And that is it as far as our Tools our concerned. Now time to combine our tools into a Toolkit. The Toolkit Toolkits sound fancy, but they are actually very simple. They are literally just a a list of tools. We can define our toolkit as an array of tools like so toolkit = [add, multiply, square] And that’s it. Really straightforward, and nothing to get confused over. Usually Toolkits are groups of tools that are useful together, and would be helpful for agents trying to carry out certain kinds of tasks. For example an SQLToolkit might contain a tool for generating an SQL query, validating an SQL query, and executing an SQL query. The Integrations Toolkit page on the LangChain docs has a large list of toolkits developed by the community that might be useful for you. The LLM As mentioned above, an LLM is the brains of an agent. It decides which tools to call based on the question passed to it, what are the best next steps to take based on a tools description. It also decides when it has reached its final answer, and is ready to return that to the user. Let’s setup the LLM here from langchain_openai import ChatOpenAI llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0) The Prompt Lastly we need a prompt to pass into our agent, so it has a general idea bout what kind of agent it is, and what sorts of tasks it should solve. Our agent requires a ChatPromptTemplate to work (more on that later). This is what a barebones ChatPromptTemplate looks like. The main part we care about is the system prompt, and the rest are just the default settings we are required to pass in. In our prompt we have included a sample answer, showing the agent how we want it to return the answer only, and not any descriptive text along with the answer prompt = ChatPromptTemplate.from_messages( [ (\"system\", \"\"\" You are a mathematical assistant. Use your tools to answer questions. If you do not have a tool to answer the question, say so. Return only the answers. e.g Human: What is 1 + 1? AI: 2 \"\"\"), MessagesPlaceholder(\"chat_history\", optional=True), (\"human\", \"{input}\"), MessagesPlaceholder(\"agent_scratchpad\"), ] ) That is it. We have setup our Tools and Toolkit, which our agent will need as part of its setup, so its knows what are the types of actions and capabilities it has at its disposal. And we have also setup the LLM and system prompt. Now for the fun part. Setting up our Agent! The Agent LangChain has a number of different agents types that can be created, with different reasoning powers and abilities. We will be using the most capable and powerful agent currently available, the OpenAI Tools agent. As per the docs on the the OpenAI Tools agent, which uses newer OpenAI models also, Newer OpenAI models have been fine-tuned to detect when one or more function(s) should be called and respond with the inputs that should be passed to the function(s). In an API call, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call these functions. The goal of the OpenAI tools APIs is to more reliably return valid and useful function calls than what can be done using a generic text completion or chat API. In other words this agents is good at generating the correct structure for calling functions, and is able to understand if more than one function (tool) might be n\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://dev.to/timesurgelabs/how-to-make-an-ai-agent-in-10-minutes-with-langchain-3i2n'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mHow I Made an AI Agent in 10 Minutes with LangChain - DEV Community Skip to content Navigation menu Search Powered by Search Algolia Search Log in Create account DEV Community Close Add reaction Like Unicorn Exploding Head Raised Hands Fire Jump to Comments Save More... Copy link Copy link Copied to Clipboard Share to Twitter Share to LinkedIn Share to Reddit Share to Hacker News Share to Facebook Share to Mastodon Report Abuse Chandler for TimeSurge Labs Posted on Aug 15, 2023 • Updated on Feb 19 How I Made an AI Agent in 10 Minutes with LangChain # ai # chatgpt # python # tutorial LangChain Crash Course (3 Part Series) 1 How To Use LangChain in 10 Minutes 2 How I Made an AI Agent in 10 Minutes with LangChain 3 How I Use Google's Gemini Pro with LangChain LangChain is a powerful library for Python and Javascript/Typescript that allows you to quickly prototype large language model applications. It allows you to chain together LLM tasks (hence the name) and even allows you to run autonomous agents quickly and easily. In this blog post, we'll explore how to create agents and define custom tools that those agents can use. Prerequisites Python 3.9 3.10 and up have some issues with some of LangChain’s modules. An OpenAI API Key Getting Started We’re going to create a Python virtual environment and install the dependencies that way. mkdir myproject cd myproject # or python3, python3.9, etc depending on your setup python -m venv env\n",
      "source env /bin/activate # this will need run every time before using your agent Enter fullscreen mode Exit fullscreen mode Once that is done we can install dependencies. The only ones we need for this tutorial are LangChain and OpenAI. Finally, python-dotenv will be used to load the OpenAI API keys into the environment. pip install langchain openai python-dotenv requests duckduckgo-search Enter fullscreen mode Exit fullscreen mode LangChain is a very large library so that may take a few minutes. While this is downloading, create a new file called .env and paste your API key in. Here is an example: OPENAI_API_KEY = Your - api - key - here Enter fullscreen mode Exit fullscreen mode Once that is complete we can make our first chain! Quick Concepts Agents are a way to run an LLM in a loop in order to complete a task. Agents are defined with the following: Agent Type - This defines how the Agent acts and reacts to certain events and inputs. For this tutorial we will focus on the ReAct Agent Type. LLM - The AI that actually runs your prompts. Tools - These are Python (or JS/TS) functions that your Agent can call to interact with the world outside of itself. These can be as simple or as complex as you want them to be! Many tools make a Toolkit . There are many toolkits already available built-in to LangChain, but for this example we’ll make our own. Agents Agents use a combination of an LLM (or an LLM Chain) as well as a Toolkit in order to perform a predefined series of steps to accomplish a goal. For this example, we’ll create a couple of custom tools as well as LangChain’s provided DuckDuckGo search tool to create a research agent. 1. Importing Necessary Libraries import requests from bs4 import BeautifulSoup from dotenv import load_dotenv from langchain.tools import Tool , DuckDuckGoSearchResults from langchain.prompts import PromptTemplate from langchain.chat_models import ChatOpenAI from langchain.chains import LLMChain from langchain.agents import initialize_agent , AgentType Enter fullscreen mode Exit fullscreen mode Here's a breakdown of the imports: requests : A popular Python library for making HTTP requests. BeautifulSoup : A library for web scraping purposes to pull the data out of HTML and XML files. load_dotenv : A method to load environment variables from a .env file. LangChain specific imports: These are specific to the LangChain framework and are used to define tools, prompts, chat models, chains, and agents. 2. Loading Environment Variables load_dotenv () Enter fullscreen mode Exit fullscreen mode This line loads environment variables from a .env file. This is useful if you have API keys or other sensitive information that you don't want to hard-code into your script. 3. Setting Up the DuckDuckGo Search Tool ddg_search = DuckDuckGoSearchResults () Enter fullscreen mode Exit fullscreen mode This initializes the DuckDuckGo search tool provided by LangChain. It allows you to search the web using DuckDuckGo and retrieve the results. 4. Defining Headers for Web Requests HEADERS = { ' User-Agent ' : ' Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:90.0) Gecko/20100101 Firefox/90.0 ' } Enter fullscreen mode Exit fullscreen mode This sets a user-agent header for our web requests. Some websites might block requests that don't have a user-agent set, thinking they're from bots. 5. Parsing HTML Content def parse_html ( content ) -> str : soup = BeautifulSoup ( content , ' html.parser ' ) text_content_with_links = soup . get_text () return text_content_with_links Enter fullscreen mode Exit fullscreen mode This function takes in HTML content, uses BeautifulSoup to parse it, and then extracts all the text from it. 6. Fetching Web Page Content def fetch_web_page ( url : str ) -> str : response = requests . get ( url , headers = HEADERS ) return parse_html ( response . content ) Enter fullscreen mode Exit fullscreen mode This function fetches the content of a web page using the requests library and then parses the HTML to extract the text. 7. Creating the Web Fetcher Tool web_fetch_tool = Tool . from_function ( func = fetch_web_page , name = \" WebFetcher \" , description = \" Fetches the content of a web page \" ) Enter fullscreen mode Exit fullscreen mode Here, we're creating a new tool using the Tool.from_function method. This tool will use our fetch_web_page function to fetch and parse web pages. 8. Setting Up the Summarizer prompt_template = \" Summarize the following content: {content} \" llm = ChatOpenAI ( model = \" gpt-3.5-turbo-16k \" ) llm_chain = LLMChain ( llm = llm , prompt = PromptTemplate . from_template ( prompt_template ) ) summarize_tool = Tool . from_function ( func = llm_chain . run , name = \" Summarizer \" , description = \" Summarizes a web page \" ) Enter fullscreen mode Exit fullscreen mode This section sets up a summarizer using the ChatOpenAI model from LangChain. We define a prompt template for summarization, create a chain using the model and the prompt, and then define a tool for summarization. We use ChatGPT 3, 5 16k context as most web pages will exceed the 4k context of ChatGPT 3.5. 9. Initializing the Agent tools = [ ddg_search , web_fetch_tool , summarize_tool ] agent = initialize_agent ( tools = tools , agent_type = AgentType . ZERO_SHOT_REACT_DESCRIPTION , llm = llm , verbose = True ) Enter fullscreen mode Exit fullscreen mode Here, we're initializing an agent with the tools we've defined. This agent will be able to search the web, fetch web pages, and summarize them. Notice how we can re-use the LLM from the summarize tool. 10. Running the Agent prompt = \" Research how to use the requests library in Python. Use your tools to search and summarize content into a guide on how to use the requests library. \" print ( agent . run ( prompt )) Enter fullscreen mode Exit fullscreen mode Finally, we define a prompt for our agent and run it. The agent will search the web for information about the Python’s Requests Library, fetch the content fetch some of the content, and then summarize it. Experimentation In this section, we'll explore how to modify the code from the blog post draft to use the experimental Plan and Execute agent. The Plan and Execute agent accomplishes an objective by first planning what to do, then executing the sub-tasks. The planning is almost always done by an LLM, while the execution is usually done by a separate agent equipped with tools. First, install the LangChain experimental package. pip install langchain_experimental Enter fullscreen mode Exit fullscreen mode Then you can import the necessary modules from the langchain_experimental.plan_and_execute package: from langchain_experimental.plan_and_execute import PlanAndExecute , load_agent_executor , load_chat_planner Enter fullscreen mode Exit fullscreen mode Load the planner and executor: planner = load_chat_planner ( llm ) executor = load_agent_executor ( llm , tools , verbose = True ) Enter fullscreen mode Exit fullscreen mode Initialize the Plan and Execute agent: agent = PlanAndExecute ( planner = planner , executor = executor , verbose = True ) Enter fullscreen mode Exit fullscreen mode Run the agent with a prompt: result = agent . run ( \" Research how to use the requests library in Python. Use your tools to search and summarize content into a guide on how to use the requests library. \" ) print ( result ) Enter fullscreen mode Exit fullscreen mode In this example, the agent will first plan the steps needed to accomplish the objective, then execute the sub-tasks using the tools provided. The agent will search the web for information about the requests library in Python, fetch the content of the relevant results, and then summarize them into a guide. Note that the Plan and Execute agent is experimental and may not work as expected in all cases. However, it can be a powerful tool for automating complex tasks that require multiple steps and interactions with external tools. Conclusion LangChain is a game-changer for anyone looking to quickly prototype large language model applications. In just a few minutes, we’ve walked through the process of creating agents, defining custom tools, and even experimenting with the experimental Plan and Execute agent to automate complex tasks. The power of LangChain lies in its simplicity and flexibility. Whether you’re a seasoned developer or just starting out, LangChain’s intuitive design allows you to harness the capabilities of large language models like never before. From generating creative content to running autonomous agents, the possibilities are endless. \u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://build5nines.com/introduction-to-building-ai-agents-with-langchain-and-python/'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mIntroduction To Building AI Agents With LangChain And Python | Build5Nines Newsletter Advertise Tools IPv4 Address CIDR Range Reference and Calculator Byte Conversion Calculator from KB, MB, GB, TB, PB More Cloud DevOps CI / CD Artificial Intelligence Certification Internet of Things Blockchain Community Development Hardware Operating Systems Cloud, DevOps & SRE Guidance Cloud Microsoft Azure Amazon AWS Google Cloud Platform DevOps HashiCorp Terraform Azure Bicep ARM Templates Azure CLI PowerShell CI / CD Azure DevOps GitHub Git AI Microsoft OpenAI Development C# Node.js Python Certification Top DevOps and SRE Certifications Microsoft Certification HashiCorp Certification GitHub Certification Development • Python Introduction to Building AI Agents with LangChain and Python By Chris Pietschmann June 23, 2024  7:07 AM EDT LangChain is a tool for more easily creating AI agents that can autonomously perform tasks. These agents can streamline operations, enhance user experiences, and handle complex processes with minimal human intervention. Building these AI agents can be difficult and this is the reason for why LangChain exists. LangChain is a cutting-edge framework designed to simplify the creation of AI agents. It enables you to leverage Large Language Models (LLMs) like OpenAI’s GPT-4o or GPT-3.5, providing a robust platform for developing versatile and powerful AI agents. Whether you’re looking to automate customer service, perform data analysis, or create interactive chatbots, LangChain offers the tools and functionalities needed to bring your AI projects to life. This article introduces you to the process of building AI agents with LangChain. We’ll walk you through the essential steps from setting up your environment all the way to an introduction of more advanced features. After reading, you’ll have a great understanding of how to use LangChain to build AI agents using Python. Table of Contents Why LangChain? What is an AI Agent? The Components of LangChain Step-by-Step Guide to Building an AI Agent with LangChain and Python Advanced Concepts Types of LangChain Agents Conclusion Why LangChain? The rise of Large Language Models (LLMs) has revolutionized the field of AI, making it possible to create agents that understand and respond to human language with unprecedented accuracy. LangChain harnesses the power of these models, providing a user-friendly framework that abstracts away much of the complexity involved in AI development and building AI agents. This allows developers to focus on defining their agents’ behaviors and functionalities rather than getting bogged down by technical details. Moreover, LangChain supports a variety of tools and integrations, making it a versatile choice for a wide range of applications. From web scraping and data fetching to natural language processing and summarization, LangChain equips you with everything you need to build sophisticated AI agents. What is an AI Agent? AI agents and the term “ Agentic AI ” describes AI systems designed with a high degree of autonomy, interaction capability, and goal-oriented behavior. These AI agents are capable of performing tasks independently, making decisions, and interacting with users or other systems to fulfill specific objectives. Unlike traditional automated systems, AI agents are proactive and adaptable, making them useful for complex tasks like summarizing documents, generating charts, or scheduling meetings. A great example of an AI agent is Microsoft Copilot , which integrates LLMs and other data sources to enhance productivity through autonomous assistance. The Components of LangChain LangChain is a framework designed to streamline the development of AI agents by leveraging the power of large language models (LLMs). To fully grasp how LangChain operates, it’s essential to understand its core components: chat models, tools, and agents. Each of these plays a crucial role in building functional and efficient AI systems. Chat Models Chat models are the backbone of LangChain. They are advanced language models capable of generating human-like text based on given inputs. These models, such as OpenAI’s GPT-3 and GPT-4, are trained on vast amounts of data, enabling them to understand and respond to a wide range of queries. The primary function of chat models in LangChain is to act as the reasoning engine, processing inputs and generating appropriate responses. Language Models as Reasoning Engines : Chat models in LangChain are not just for generating text; they serve as reasoning engines that determine which actions to take based on the given input. This makes them integral to the decision-making process within an AI agent. Multi-Turn Conversations : These models support multi-turn conversations, allowing them to maintain context over several interactions. This is crucial for applications like customer service chatbots, where continuity and context retention are essential for providing coherent and helpful responses. Tools Tools in LangChain are specialized functions or APIs that the agent can use to perform specific tasks. These tasks can range from simple operations like fetching data from a web page to more complex activities like summarizing a document or performing data analysis. Tool Definition and Integration : Tools are defined using Python functions and can be easily integrated into LangChain. For example, a tool might be created to fetch web content, process data, or interact with other APIs. This modularity allows developers to customize the agent’s capabilities according to their needs. Tool Examples : Common tools include web search utilities, web content fetchers, and summarization tools. These tools enhance the agent’s functionality, enabling it to perform a broader range of tasks effectively. Agents Agents are the orchestrators in LangChain. They use the chat models and tools to perform actions and generate outputs based on user inputs. An agent’s primary role is to determine which tool to use and how to apply it to achieve the desired result. Initialization and Execution : Agents are initialized by combining one or more tools with a chat model. They follow a defined logic to decide which actions to take, often using a zero-shot or few-shot learning approach to understand the context and requirements of the task. Agent Types : LangChain supports various types of agents, each suited to different tasks and scenarios. These include: Zero-Shot Agents : Capable of handling tasks without prior examples, relying solely on the input provided. Few-Shot Agents : Use a few examples to better understand the task before performing it. Memory-Enhanced Agents : Incorporate memory to retain context over multiple interactions, improving the coherence and relevance of responses in long conversations. Advanced Features Beyond the basic components, LangChain offers advanced features that enhance the functionality and versatility of AI agents. These include: Plan and Execute : This approach separates the planning and execution phases, allowing for more structured and efficient task handling. It involves using the langchain_experimental package to define and execute plans. Agent Memory : Adding memory capabilities to agents enables them to remember previous interactions, making them more context-aware and capable of maintaining coherent multi-turn conversations. Interoperability : LangChain is designed to work seamlessly with other frameworks and tools, allowing for easy integration and extended functionality. This includes compatibility with LangGraph for more complex workflows and state management. Practical Application To illustrate how these components work together, let’s consider a practical example. Suppose we want to build an agent that can perform web searches and summarize the results. Here’s how LangChain’s components would come into play: Chat Model : The core of the agent, processing user queries and generating responses. Tools : A web search tool to fetch search results and a summarization tool to condense the information. Agent : Combines the chat model with the tools, determining when to use each tool based on the query and generating a summarized output. # Import necessary libraries\n",
      "from langchain.agents import initialize_agent, AgentType\n",
      "from langchain.tools import DuckDuckGoSearchResults, Tool\n",
      "from langchain.chains import LLMChain\n",
      "from langchain.llms.openai import ChatOpenAI\n",
      "from langchain.prompts import PromptTemplate\n",
      "\n",
      "# Initialize tools\n",
      "ddg_search = DuckDuckGoSearchResults()\n",
      "web_fetch_tool = Tool.from_function(\n",
      "    func=fetch_web_page,\n",
      "    name=\"WebFetcher\",\n",
      "    description=\"Fetches the content of a web page\"\n",
      ")\n",
      "\n",
      "# Create summarization tool\n",
      "prompt_template = \"Summarize the following content: {content}\"\n",
      "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
      "llm_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))\n",
      "summarize_tool = Tool.from_function(\n",
      "    func=llm_chain.run,\n",
      "    name=\"Summarizer\",\n",
      "    description=\"Summarizes a web page\"\n",
      ")\n",
      "\n",
      "# Initialize agent with tools\n",
      "tools = [ddg_search, web_fetch_tool, summarize_tool]\n",
      "agent = initialize_agent(\n",
      "    tools=tools,\n",
      "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
      "    llm=llm,\n",
      "    verbose=True\n",
      ")\n",
      "\n",
      "# Run the agent\n",
      "prompt = \"Research how to use the requests library in Python. Use your tools to search and summarize content into a guide on how to use the requests library.\"\n",
      "print(agent.run(prompt)) By understanding these core components and how they interact, you can harness the power of LangChain to build sophisticated AI agents capable of performing a wide range of tasks efficiently. Step-by-Step Guide to Building an AI Agent with LangChain and Python Let’s look at the process of building an AI agent using LangChain and a vector database for Retrieval Augmented Generation (RAG) . This setup will allow the agent to perform complex queries by leveraging the power of vector databases for efficient and accurate information retrieval. Step 1: Setup Environment Before\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://analyzingalpha.com/langchain-python-tutorial'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mLangChain Python Tutorial: The Ultimate Step-by-Step Guide - Analyzing Alpha Skip to content Analyzing Alpha Analyzing Alpha Menu Home About Blog Podcast Recommended Menu Home About Blog Podcast Recommended Programming LangChain Python Tutorial: The Ultimate Step-by-Step Guide By Leo Smigel Updated on October 13, 2023 As a Python programmer, you might be looking to incorporate large language models (LLMs) into your projects – anything from text generators to trading algorithms. That’s where this comprehensive LangChain Python guide comes in, tailored to fit both novices and seasoned coders. Unlike dense official documents or confusing tutorials, I bring a simplified approach to this tutorial, drawing from years of experience in making complex concepts more digestible. With easy-to-follow instructions and lucid examples, I’ll guide you through the intricate world of LangChain, unlocking its immense potential. Don’t delay; start leveraging LangChain to build innovative applications today. What Is LangChain? LangChain is a software development framework that makes it easier to create applications using large language models (LLMs). It’s an open-source tool with a Python and JavaScript codebase. LangChain allows developers to combine LLMs like GPT-4 with external data, opening up possibilities for various applications such as chatbots, code understanding, summarization, and more. LangChain Pros and Cons Pros: Freely available Open source Supports all major LLMs Variety of modules to perform common tasks Cons: Limited support for languages other than Python Some people express security concerns over the handling of sensitive information. LangChain Pricing LangChain framework is a free-to-use open-source framework. To use some of the LangChain-supported large language models, you must subscribe to the developers of these models and obtain API keys. Getting Started with LangChain Getting started with the LangChain framework is straightforward. You can download the LangChain Python package, import one or more of the LangChain modules, and start building Python applications using large language models. Installation You can install the LangChain package via the following pip command. !pip install langchain Alternatively, if you are using the Anaconda distribution of Python, you can install LangChain via the following conda command. !conda install langchain -c conda-forge A Simple Example LangChain simplifies the use of large language models by offering modules that cover different functions. Later on, I’ll provide detailed explanations of each module. In this section, let’s call a large language model for text generation. The general principle for calling different modules remains consistent throughout. You must perform the following steps to call a Large Language Model (LLM) via LangChain in Python. Step 1: Install Python Package For instance, for OpenAI LLMs, you need to install the OpenAI library. !pip install openai Step 2: Get API Key Get an API key for the corresponding large language module. You can access some LLMs without an API key. The following script imports OpenAI API key from the environment variables. import os\n",
      "api_key = os.getenv('OpenAI_KEY') Step 3: Import LLM Model Import an LLM model from LangChain. For example, we import the OpenAI model in the following script. Sometimes, you need to initialize an LLM model using its API key. from langchain.llms import OpenAI\n",
      "llm = OpenAI(openai_api_key = api_key, temperature=0.9) Step 4: Pass Prompt Pass the prompt to the LLM object you just created. prompt = \"Suggest me a good name for an ice cream parlour that is located on a beach!\"\n",
      "print(llm(prompt)) And that’s it. You can see how simple it is to call an LLM with LangChain. You can replace OpenAI with other LangChain-supported large language models . Let’s now see what other functionalities you can achieve with LangChain modules. LangChain Modules LangChain groups its functionalities into modules enlisted below: Models Prompts Chains Agents Memory Document Loaders and Indexes Models LangChain supports three types of models: Large Language Models Chat Models Text Embedding Models Large Language Models Large language models (LLMs) are the simplest of LangChain models and are the backbone of many other LangChain modules. An LLM takes user inputs as texts and outputs a response as text. LangChain supports a large number of LLMs . We will see a couple of examples in this section. OpenAI Example I have already explained in the basic example section how to use OpenAI LLM. If you want to learn more about directly accessing OpenAI functionalities , check out our OpenAI Python Tutorial. Let’s dig a little further into using OpenAI in LangChain. You can pass an OpenAI model name to the OpenAI model from the langchain.llms module. In the following example, we pass the text-davinci-003 model, which is also the default model. from langchain.llms import OpenAI\n",
      "\n",
      "llm = OpenAI(openai_api_key = api_key,\n",
      "             model_name=\"text-davinci-003\")\n",
      "\n",
      "print(llm(\"Can you tell me a riddle about water?\")) You can pass multiple text prompts to an OpenAI model via the generate() method. For example, the following script returns two outputs, one for each prompt. llm_result = llm.generate([\"Write a poem about hills\", \"Tell me a riddle about oranges\"])\n",
      "len(llm_result.generations) You can access the first output using the generations[0][0].text code. print(llm_result.generations[0][0].text) Likewise, generations[1][0].text returns the second output. print(llm_result.generations[1][0].text) C Transformers Example C transformers package implements various LLMs that you can use in LangChain. You do not need an API key to access C transformers LLMs. To use the C transformers language models in LangChain, you must import the CTransformers model and pass the model name to the model attribute. You can then generate text using CTransformers LLM. from langchain.llms import CTransformers\n",
      "\n",
      "llm = CTransformers(model='marella/gpt-2-ggml')\n",
      "print(llm(\"I am flying to Lisbon on\")) Chat Models LangChain chat models use LLMs at the backend. However, they allow conversational interaction with users. Generating a Single Response To create a chat model, import one of the LangChain-supported chat models , from the langchain.chat_models module. In the following example, we import the ChatOpenAI model, which uses OpenAI LLM at the backend. You also need to import HumanMessage and SystemMessage objects from the langchain.schema module. The former allows you to specify human/user input, while the latter helps you define the system’s/chat bots role. Next, you must create an object of the ChatOpenAI model and pass it your API key. I set the temperature to 0 in the following script since I want the best response. Increasing the temperature will allow the model to generate more creative responses. from langchain.chat_models import ChatOpenAIfrom langchain.schema import (    HumanMessage,    SystemMessage)\n",
      "\n",
      "chat = ChatOpenAI(openai_api_key = api_key, \n",
      "                  temperature=0) To create a human or a system message, you need to pass the message text to the content attribute of the HumanMesssage and SystemMessage objects, respectively. You must pass messages in a list to the chat model. It is not mandatory to pass system messages. We pass a single human message to the OpenAI chat model in the following script. human_message = \"Translate from English to Frech: I love playing Tennis\"\n",
      "chat([HumanMessage(content = human_message)]) Though you can pass anything to the system messages, you will primarily use it to define the system role. Here’s an example. messages = [\n",
      "    SystemMessage(content=\"You are a football historian.\"),\n",
      "    HumanMessage(content=\" Who won the player of the tournament in the 11th Fifa World Cup?\")\n",
      "]\n",
      "chat(messages) Generating Batch Responses You can generate batch responses from chat models. To do so, you must pass a list containing human and system messages. batch_messages = [\n",
      "    [\n",
      "        SystemMessage(content=\"You are a football historian.\"),\n",
      "        HumanMessage(content=\" Who won the player of the tournament in the 11th Fifa World Cup?\")\n",
      "    ],\n",
      "    [\n",
      "        SystemMessage(content=\"You are a Pizza chef.\"),\n",
      "        HumanMessage(content=\"Give me the 7-step recipe to prepare a pizza.\")\n",
      "    ],\n",
      "]\n",
      "result = chat.generate(batch_messages) As with language models, you can access multiple responses using generations list. For instance, you can access the first response via the following script. print(result.generations[0][0].text) The following script prints the second response. print(result.generations[1][0].text) Text Embedding Models The LangChain text embedding models return numeric representations of text inputs that you can use to train statistical algorithms such as machine learning models. You have to import an embedding model from the langchain.embeddings module and pass the input text to the embed_query() method. The following script uses the OpenAIEmbeddings model to generate text embeddings. The output will be a 1536-dimensional vector. from langchain.embeddings import OpenAIEmbeddings\n",
      "\n",
      "embeddings = OpenAIEmbeddings(openai_api_key = api_key)\n",
      "\n",
      "text = \"Paris the capital of france and is famous for its wines and perfumes\"\n",
      "embeddings_result = embeddings.embed_query(text)\n",
      "\n",
      "print(len(embeddings_result)) You can pass multiple text inputs in a list to embed_documents() method, which returns embeddings for all the text inputs. For example, the following script returns embeddings for three text inputs. text = [\"Paris the capital of france and is famous for its wines and perfumes\",\n",
      "        \"London is the Capital of England\",\n",
      "        \"Tokyo is the Capital of Japan\"\n",
      "       ]\n",
      "\n",
      "embeddings_result = embeddings.embed_documents(text)\n",
      "\n",
      "print(\"Total Embeddings:\", len(embeddings_result)) In the next section, I will show you how to replace your hard-coded input templates with something more generic using the LangChain prompts module. Prompts Prompts refer to model inpu\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHere is a summary of the contents from the scraped URLs on how to build a simple research agent using LangChain in Python:\n",
      "\n",
      "1. **LangChain Documentation: Build an Agent**\n",
      "   - **Overview**: This guide provides a comprehensive tutorial on building an agent that can interact with a search engine using LangChain.\n",
      "   - **Components**:\n",
      "     - **Chat Models**: Used as reasoning engines.\n",
      "     - **Tools**: Methods or classes that the agent can use to interact with its environment.\n",
      "     - **Agents**: Systems that use LLMs to determine actions and inputs.\n",
      "   - **Example**: The tutorial includes a code snippet for creating an agent with conversational memory and a search tool.\n",
      "   - **Steps**:\n",
      "     1. Import necessary modules.\n",
      "     2. Create the agent with memory and tools.\n",
      "     3. Use the agent to interact with the environment.\n",
      "\n",
      "2. **Towards Data Science: Building a Simple Agent with Tools and Toolkits in LangChain**\n",
      "   - **Overview**: This article explains the foundational concepts and building blocks of LangChain agents.\n",
      "   - **Components**:\n",
      "     - **Tools**: Custom methods for specific tasks (e.g., add, multiply, square).\n",
      "     - **Toolkit**: A collection of tools.\n",
      "     - **LLM**: The brain of the agent.\n",
      "     - **Prompt**: Defines the agent's tasks and behavior.\n",
      "   - **Example**: A Mathematics Agent that performs simple operations.\n",
      "   - **Steps**:\n",
      "     1. Define tools using the `@tool` decorator.\n",
      "     2. Create a toolkit.\n",
      "     3. Set up the LLM and prompt.\n",
      "     4. Initialize and test the agent.\n",
      "\n",
      "3. **DEV Community: How I Made an AI Agent in 10 Minutes with LangChain**\n",
      "   - **Overview**: A quick guide to creating an AI agent using LangChain.\n",
      "   - **Components**:\n",
      "     - **Agent Type**: Defines the agent's behavior.\n",
      "     - **LLM**: The AI that runs the prompts.\n",
      "     - **Tools**: Functions the agent can call.\n",
      "   - **Example**: A research agent using DuckDuckGo search and a summarizer tool.\n",
      "   - **Steps**:\n",
      "     1. Set up the environment and install dependencies.\n",
      "     2. Define custom tools and use built-in tools.\n",
      "     3. Initialize the agent with tools.\n",
      "     4. Run the agent with a prompt.\n",
      "\n",
      "4. **Build5Nines: Introduction to Building AI Agents with LangChain and Python**\n",
      "   - **Overview**: Introduction to creating AI agents with LangChain.\n",
      "   - **Components**:\n",
      "     - **Chat Models**: Backbone of LangChain.\n",
      "     - **Tools**: Specialized functions for specific tasks.\n",
      "     - **Agents**: Orchestrators that use chat models and tools.\n",
      "   - **Example**: An agent that performs web searches and summarizes results.\n",
      "   - **Steps**:\n",
      "     1. Set up the environment.\n",
      "     2. Define tools and initialize the agent.\n",
      "     3. Run the agent with a prompt.\n",
      "\n",
      "5. **Analyzing Alpha: LangChain Python Tutorial**\n",
      "   - **Overview**: A step-by-step guide to using LangChain for various applications.\n",
      "   - **Components**:\n",
      "     - **Models**: LLMs, chat models, text embedding models.\n",
      "     - **Prompts**: Model inputs.\n",
      "     - **Chains**: Sequences of actions.\n",
      "     - **Agents**: Systems that use models and tools.\n",
      "   - **Example**: Using OpenAI models for text generation and other tasks.\n",
      "   - **Steps**:\n",
      "     1. Install LangChain and dependencies.\n",
      "     2. Import and set up models.\n",
      "     3. Define prompts and chains.\n",
      "     4. Initialize and run agents.\n",
      "\n",
      "These resources collectively provide a detailed guide on building simple research agents using LangChain in Python, covering the setup, components, and practical examples.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How to build a simple research agent using langchain in Python?',\n",
       " 'output': \"Here is a summary of the contents from the scraped URLs on how to build a simple research agent using LangChain in Python:\\n\\n1. **LangChain Documentation: Build an Agent**\\n   - **Overview**: This guide provides a comprehensive tutorial on building an agent that can interact with a search engine using LangChain.\\n   - **Components**:\\n     - **Chat Models**: Used as reasoning engines.\\n     - **Tools**: Methods or classes that the agent can use to interact with its environment.\\n     - **Agents**: Systems that use LLMs to determine actions and inputs.\\n   - **Example**: The tutorial includes a code snippet for creating an agent with conversational memory and a search tool.\\n   - **Steps**:\\n     1. Import necessary modules.\\n     2. Create the agent with memory and tools.\\n     3. Use the agent to interact with the environment.\\n\\n2. **Towards Data Science: Building a Simple Agent with Tools and Toolkits in LangChain**\\n   - **Overview**: This article explains the foundational concepts and building blocks of LangChain agents.\\n   - **Components**:\\n     - **Tools**: Custom methods for specific tasks (e.g., add, multiply, square).\\n     - **Toolkit**: A collection of tools.\\n     - **LLM**: The brain of the agent.\\n     - **Prompt**: Defines the agent's tasks and behavior.\\n   - **Example**: A Mathematics Agent that performs simple operations.\\n   - **Steps**:\\n     1. Define tools using the `@tool` decorator.\\n     2. Create a toolkit.\\n     3. Set up the LLM and prompt.\\n     4. Initialize and test the agent.\\n\\n3. **DEV Community: How I Made an AI Agent in 10 Minutes with LangChain**\\n   - **Overview**: A quick guide to creating an AI agent using LangChain.\\n   - **Components**:\\n     - **Agent Type**: Defines the agent's behavior.\\n     - **LLM**: The AI that runs the prompts.\\n     - **Tools**: Functions the agent can call.\\n   - **Example**: A research agent using DuckDuckGo search and a summarizer tool.\\n   - **Steps**:\\n     1. Set up the environment and install dependencies.\\n     2. Define custom tools and use built-in tools.\\n     3. Initialize the agent with tools.\\n     4. Run the agent with a prompt.\\n\\n4. **Build5Nines: Introduction to Building AI Agents with LangChain and Python**\\n   - **Overview**: Introduction to creating AI agents with LangChain.\\n   - **Components**:\\n     - **Chat Models**: Backbone of LangChain.\\n     - **Tools**: Specialized functions for specific tasks.\\n     - **Agents**: Orchestrators that use chat models and tools.\\n   - **Example**: An agent that performs web searches and summarizes results.\\n   - **Steps**:\\n     1. Set up the environment.\\n     2. Define tools and initialize the agent.\\n     3. Run the agent with a prompt.\\n\\n5. **Analyzing Alpha: LangChain Python Tutorial**\\n   - **Overview**: A step-by-step guide to using LangChain for various applications.\\n   - **Components**:\\n     - **Models**: LLMs, chat models, text embedding models.\\n     - **Prompts**: Model inputs.\\n     - **Chains**: Sequences of actions.\\n     - **Agents**: Systems that use models and tools.\\n   - **Example**: Using OpenAI models for text generation and other tasks.\\n   - **Steps**:\\n     1. Install LangChain and dependencies.\\n     2. Import and set up models.\\n     3. Define prompts and chains.\\n     4. Initialize and run agents.\\n\\nThese resources collectively provide a detailed guide on building simple research agents using LangChain in Python, covering the setup, components, and practical examples.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"How to build a simple research agent using langchain in Python?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encounter a few issues when we try to just add the scrape function to the agent without any other consideration. \n",
    "How about we make this better by improving the inner chain of the agent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:40.347226Z",
     "iopub.status.busy": "2024-07-18T12:09:40.346974Z",
     "iopub.status.idle": "2024-07-18T12:09:57.693493Z",
     "shell.execute_reply": "2024-07-18T12:09:57.692280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'LangChain framework learning resources'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m['https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702', 'https://python.langchain.com/v0.2/docs/introduction/', 'https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-️-5e751622edb7', 'https://www.freecodecamp.org/news/beginners-guide-to-langchain/', 'https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8']\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mTop 5 Resources to learn LangChain | by Ankit Yadav | Medium Open in app Sign up Sign in Write Sign up Sign in Top 5 Resources to learn LangChain Ankit Yadav · Follow 3 min read · Jul 8, 2023 -- Listen Share Photo by Karine Avetisyan on Unsplash Large Language Models(LLMs) have taken the world by storm ever since OpenAI announced the launch of ChatGPT. ChatGPT holds the record for fastest to 100 million Daily Active Users(DAU) which was achieved in 2 months after its launch. Meta’s Threads App is on track to break this record, but it does have the advantage of a seamless integration for Instagram users. OpenAI and other open-source LLMs are here to stay,bringing with them a new wave of applications and use cases. One crucial foundation for these applications is LangChain, a Python framework for building Language Model Applications. The highlight of the framework is its ability to create chains of components that perform complex tasks. Furthermore, with ongoing active development in the open-source community, the list of data connection and integration endpoints continues to grow daily. After exploring the LangChain library for a couple of weeks, I wanted to share some valuable resources that helped me learn and build with this framework. Here is a curated list of the top 5 resources to learn LangChain: DeepLearning.ai Short Courses I recommend starting with these courses as they are currently free to enroll in and have been created by Harrison Chase, the creator of LangChain, along with renowned instructor Andrew Ng. DeepLearning.ai offers two courses on LangChain which are LangChain: Chat with Your Data and LangChain for LLM Application Development. Both courses are short and provide example Jupyter notebooks for self-practice. 2. TDS Article: A Gentle Intro to Chaining LLMs, Agents, and utils via LangChain Medium has always been a great learning resource for me and many others. This article by Dr. Varshita Sher acted as an excellent starting point for me, allowing me to understand the basics of Chains and Agents. I highly recommend following her and exploring some of her other insightful articles as well. 3. Greg Kamradt’s LangChain Youtube Playlist Greg Kamradt has consistently posted awesome content on LangChain for over four months, covering a variety of topics. The Cookbook videos served as a great starting point for me. Greg has also shared videos for specific use cases, such as Connecting Google Drive to OpenAI . 4. 1littlecoder LangChain Youtube Playlist Learning any new tool, framework, or language requires hands-on practice, and LangChain is no exception. However, LLMs cannot be tested on local machines due to their GPU requirements. The only way to use OpenAI APIs is through the paid version. ( New free trial users receive $5 (USD) worth of credit, which expires after three months ). This pushed me to search for Open Source Models and easy ways to run them. Enter 1littlecoder and his Youtube Channel . 1littlecoder helped me understand the capabilites of Google Colab and how I can setup powerful open source LLM models such as Falcon with ease. Highly recommended! 5. Tutorials Page on LangChain The Tutorials page of the official LangChain website covers some of the above mentioned resources along with additional videos. I am currently in the process of going through the LangChain AI Handbook which covers many of the core concepts in the framework. These resources will be instrumental in learning how to use the LangChain Framework to build applications and connect LLMs to third-party applications via APIs. I firmly believe that LLM-powered applications are the future, and we should be prepared to leverage them according to our preferences.😊 Please do follow me on Medium if you found this article useful. I am currently working on other LLM articles and tutorials which will be posted in the coming weeks. Large Language Models Llm What Is Langchain Langchain Top 5 -- -- Follow Written by Ankit Yadav 111 Followers Solutions Architect @ Databricks Follow Help Status About Careers Press Blog Privacy Terms Text to speech Teams\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://python.langchain.com/v0.2/docs/introduction/'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mIntroduction | 🦜️🔗 LangChain Skip to main content LangChain 0.2 is out! Leave feedback on the v0.2 docs here . You can view the v0.1 docs here . Integrations API Reference More People Contributing Templates Cookbooks 3rd party tutorials YouTube arXiv v0.2 v0.2 v0.1 🦜️🔗 LangSmith LangSmith Docs Templates GitHub Templates Hub LangChain Hub JS/TS Docs 💬 Search Introduction Tutorials Build a Question Answering application over a Graph Database Tutorials Build a Simple LLM Application with LCEL Build a Query Analysis System Build a Chatbot Conversational RAG Build an Extraction Chain Build an Agent Tagging data_generation Build a Local RAG Application Build a PDF ingestion and Question/Answering system Build a Retrieval Augmented Generation (RAG) App Vector stores and retrievers Build a Question/Answering system over SQL data Summarize Text How-to guides How-to guides How to use tools in a chain How to use a vectorstore as a retriever How to add memory to chatbots How to use example selectors How to map values to a graph database How to add a semantic layer over graph database How to invoke runnables in parallel How to stream chat model responses How to add default invocation args to a Runnable How to add retrieval to chatbots How to use few shot examples in chat models How to do tool/function calling How to best prompt for Graph-RAG How to install LangChain packages How to add examples to the prompt for query analysis How to use few shot examples How to run custom functions How to use output parsers to parse an LLM response into structured format How to handle cases where no queries are generated How to route between sub-chains How to return structured data from a model How to use toolkits How to add ad-hoc tool calling capability to LLMs and Chat Models Build an Agent with AgentExecutor (Legacy) How to construct knowledge graphs How to partially format prompt templates How to handle multiple queries when doing query analysis How to use built-in tools and toolkits How to pass through arguments from one step to the next How to compose prompts together How to handle multiple retrievers when doing query analysis How to add values to a chain's state How to construct filters for query analysis How to configure runtime chain internals How deal with high cardinality categoricals when doing query analysis Custom Document Loader How to split by HTML header How to split by HTML sections How to use the MultiQueryRetriever How to add scores to retriever results Caching How to use callbacks in async environments How to attach callbacks to a runnable How to propagate callbacks  constructor How to dispatch custom callback events How to pass callbacks in at runtime How to split by character How to cache chat model responses How to init any model in one line How to track token usage in ChatModels How to add tools to chatbots How to split code How to do retrieval with contextual compression How to convert Runnables as Tools How to create custom callback handlers How to create a custom chat model class How to create a custom LLM class Custom Retriever How to create tools How to debug your LLM apps How to load CSVs How to load documents from a directory How to load HTML How to load JSON How to load Markdown How to load Microsoft Office files How to load PDFs How to create a dynamic (self-constructing) chain Text embedding models How to combine results from multiple retrievers How to select examples by length How to select examples by maximal marginal relevance (MMR) How to select examples by n-gram overlap How to select examples by similarity How to use reference examples when doing extraction How to handle long text when doing extraction How to use prompting alone (no tool calling) to do extraction How to add fallbacks to a runnable How to filter messages Hybrid Search How to use the LangChain indexing API How to inspect runnables LangChain Expression Language Cheatsheet How to cache LLM responses How to track token usage for LLMs Run LLMs locally How to get log probabilities How to reorder retrieved results to mitigate the \"lost in the middle\" effect How to split Markdown by Headers How to merge consecutive messages of the same type How to add message history How to migrate from legacy LangChain agents to LangGraph How to migrate chains to LCEL How to retrieve using multiple vectors per document How to pass multimodal data directly to models How to use multimodal prompts How to create a custom Output Parser How to use the output-fixing parser How to parse JSON output How to retry when a parsing error occurs How to parse XML output How to parse YAML output How to use the Parent Document Retriever How to use LangChain with different Pydantic versions How to add chat history How to get a RAG application to add citations How to do per-user retrieval How to get your RAG application to return sources How to stream results from your RAG application How to split JSON data How to recursively split text by characters Response metadata How to do \"self-querying\" retrieval How to split text based on semantic similarity How to chain runnables How to save and load LangChain objects How to split text by tokens How to do question answering over CSVs How to deal with large databases when doing SQL question-answering How to better prompt when doing SQL question-answering How to do query validation as part of SQL question-answering How to stream runnables How to stream responses from an LLM How to use a time-weighted vector store retriever How to return artifacts from a tool How to use chat models to call tools How to disable parallel tool calling How to force models to call a tool How to access the RunnableConfig from a tool How to pass tool outputs to chat models How to pass run time values to tools How to stream events from a tool How to stream tool calls How to convert tools to OpenAI Functions How to handle tool errors How to use few-shot prompting with tool calling How to add a human-in-the-loop for tools How to bind model-specific tools How to trim messages How to create and query vector stores Conceptual guide Ecosystem 🦜🛠️ LangSmith 🦜🕸️ LangGraph Versions Overview Release Policy Packages v0.2 LangChain v0.2 astream_events v2 Changes Security Introduction On this page Introduction LangChain is a framework for developing applications powered by large language models (LLMs). LangChain simplifies every stage of the LLM application lifecycle: Development : Build your applications using LangChain's open-source building blocks , components , and third-party integrations .\n",
      "Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support. Productionization : Use LangSmith to inspect, monitor and evaluate your chains, so that you can continuously optimize and deploy with confidence. Deployment : Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Cloud . Concretely, the framework consists of the following open-source libraries: langchain-core : Base abstractions and LangChain Expression Language. langchain-community : Third party integrations. Partner packages (e.g. langchain-openai , langchain-anthropic , etc.): Some integrations have been further split into their own lightweight packages that only depend on langchain-core . langchain : Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangGraph : Build robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. Integrates smoothly with LangChain, but can be used without it. LangServe : Deploy LangChain chains as REST APIs. LangSmith : A developer platform that lets you debug, test, evaluate, and monitor LLM applications. note These docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library. Tutorials ​ If you're looking to build something specific or are more of a hands-on learner, check out our tutorials section .\n",
      "This is the best place to get started. These are the best ones to get started with: Build a Simple LLM Application Build a Chatbot Build an Agent Introduction to LangGraph Explore the full list of LangChain tutorials here , and check out other LangGraph tutorials here . How-to guides ​ Here you’ll find short answers to “How do I….?” types of questions.\n",
      "These how-to guides don’t cover topics in depth – you’ll find that material in the Tutorials and the API Reference .\n",
      "However, these guides will help you quickly accomplish common tasks. Check out LangGraph-specific how-tos here . Conceptual guide ​ Introductions to all the key parts of LangChain you’ll need to know! Here you'll find high level explanations of all LangChain concepts. For a deeper dive into LangGraph concepts, check out this page . API reference ​ Head to the reference section for full documentation of all classes and methods in the LangChain Python packages. Ecosystem ​ 🦜🛠️ LangSmith ​ Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. 🦜🕸️ LangGraph ​ Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. Additional resources ​ Security ​ Read up on our Security best practices to make sure you're developing safely with LangChain. Integrations ​ LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of integrations . Contributing ​ Check out the developer's guide for guidelines on contributing and help getting your dev environment set up. Edit this page Was this page helpful? You can also leave detailed feedback on GitHub . Next Tutorials Tutorials How-to guides Conceptual guide API reference Ecosystem 🦜🛠️ LangSmith 🦜🕸️ LangGraph Additional resources Security Integrations Contributing Community Twitter GitHub Organization Python JS/TS More Homepage Blog YouTube Copyright © 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-️-5e751622edb7'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mIntroducing LangChain: a beginner’s guide 🦜️🔗 | by Ellen Hoeven | Medium Open in app Sign up Sign in Write Sign up Sign in Introducing LangChain: a beginner’s guide 🦜️🔗 Build applications with LLMs using LangChain Ellen Hoeven · Follow 6 min read · Sep 22, 2023 -- 1 Listen Share Have you heard the term LangChain but not sure what exactly it is about? Then this is your chance to catch up: this article provides an overview of the most important concepts in 5 minutes, explaining everything you need to know to continue your journey with LangChain. Why LangChain? Along with the recent developments in large language models (LLMs), many tools and libraries have risen around them to ease the development of LLM applications. LangChain is an open-source development framework for building LLM applications. It bundles common functionalities that are needed for the development of more complex LLM projects. “Building applications with LLMs through composability.” It does so by providing modular components that can be combined into common use cases to build end-to-end LLM applications and making it easier to get started with these use cases. You can think of it as the “glue code” that is needed to combine all these common functionalities around LLMs. In this article I will illustrate the most important concepts behind LangChain and explore some hands-on examples to show how you can leverage LangChain to create an application to answer questions about your own documents. Unleashing the power of LLMs How can you leverage LLMs to create truly powerful apps? This, as opposed to using LLMs stand-alone, is what LangChain addresses. Although LLMs by themselves can already achieve many amazing things, further steps are often required to effectively use LLMs within applications. Such steps consist of prompt engineering, chaining multiple operations together, using agents to make decisions, and others. LangChain provides common interfaces and functionalities to accomplish this: think of it like a toolbox, where you can take the tools and materials you need to build your specific LLM application. The key here is the library’s composability design, allowing you to plug together the different components as required and thus making the implementation of complex applications more modular, making it easier to debug, maintain and improve them. What can you do with it? Some example applications you can develop using LangChain include the following: Build your own chatbot — use LangChain’s LLM interfaces, prompt templates and memory options to build a chatbot with conversation history. Question-answering of specific documents — by creating an index over your own documents, you can sift through the documents and use them to augment your prompts, retrieving domain-specific answers. Summarize texts, documents, or sites — use document loaders and transformers before sending the text to be summarized to your LLM of choice, then parse the output as needed for further use downstream. … and many more: you can find an overview of possible use cases with Python guides in the LangChain documentation. Next, let’s dive into the components that enable you to create such use cases. LangChain Structure LangChain offers several modules , each of which allows you to manage a specific aspect of the LLM interaction. At the time of writing (v.0.0.209), these include the following modules: Overview of LangChain — Image by author LLMs, Prompts & Parsers : Interactions with LLMs are the core component of LangChain. The LLM module provides common interfaces to make calls to LLMs and provides integrations to both open-source and proprietary LLM models. Next, the key to achieve consistent and good results with LLMs are prompts: hence, the prompts class provides options to create and re-use prompt templates. Finally, parsing the model output is streamlined by the output parsers module in order to effectively handle the model output for further use downstream (e.g., by bringing the output into a required format). Data connection: You can think of these as the building blocks to load, transform, query and store your documents in vector stores. LangChain offers several handy built-in data loaders (e.g., Wikipedia, Arxiv, Youtube Transcripts) and pre-processing utilities such as text splitters and text embedding models. Chains: More complex applications require the chaining of multiple components. For instance, you may create a chain that takes user input, formats it with a PromptTemplate, passes it to the LLM, and summarizes the results. LangChain defines the Chain as “ a sequence of calls to components, which can include other chains ”. Memory: The memory module persists a user’s interaction between calls of a model, allowing selected previous parts of a conversation to be fed into the LLM as conversational flow. Chains and Agents are stateless per default — meaning that they treat each query independently if not given instructions to behave otherwise. The memory class provides helper utilities for managing and integrating previous chat history. Agents: Some applications require a flexible chain of calls to LLMs. LangChain provides two types of agents that help to achieve that: action agents make decisions, take actions and make observations on the results of that actions, repeating this cycle until a given task has been completed. The agent has access to a suite of tools, and determines which one to use next. Plan-and-execute agents decide on the full sequence of actions up front and then execute them all without updating the plan. Callbacks : The callbacks in LangChain allow you to hook into various stages of your LLM application. You can use this for instance for logging, monitoring, streaming and other tasks. Other handy features offered by LangChain include indexes, integrations , evaluation and more. Using LangChain for question-answering over documents Let’s dive into some of the functionalities that LangChain has to offer with a hands-on example! In this case, I will use LangChain to build an application for retrieval augmented generation. With this application, you will be able to answer questions over your own documents by indexing them and sending relevant content as part of the prompt to the LLM. Since the LLM has not been trained on these documents, this will help to answer questions specific to these documents. Installing dependencies Create an environment and install the dependencies you need. In addition to LangChain, we will be needing chroma-db as embedding database and tiktoken as tokenizer with OpenAI’s models. pip install langchain pip install chromadb pip install tiktoken Setting up environment variables This step will depend on the the LLM API you wish to use. In this case, I will be using the OpenAI API but you can also use other LLMs and APIs. pip install openai export OPENAI_API_KEY=\"...\" Disclaimer: please keep in mind that using the OpenAI API is not free. LangChain offers many handy utilities such as document loaders, text splitters, embeddings and vector stores like Chroma. from langchain.document_loaders import TextLoader from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain.embeddings import OpenAIEmbeddings from langchain.vectorstores import Chroma from langchain.embeddings import OpenAIEmbeddings from langchain.llms import OpenAI from langchain.chains import RetrievalQA Load documents Load your documents you want to do question answering over. LangChain provides different types of loaders, e.g. for PDFs or text files. In this case, I will be using the State of the Union text document, which you can find here . # Load documents loader = TextLoader('state_of_the_union.txt') documents = loader.load() Split documents LangChain offers different types of text splitters to split your documents into chunks. This ensure that only the most relevant parts of the document will be sent as part of the prompt to the LLM. I use the Recursive Character Text Splitter, which is the recommended splitter for generic text. # Split documents text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0) texts = text_splitter.split_documents(documents) Create embeddings and initialize vector store # Create embeddings embeddings = OpenAIEmbeddings() docsearch = Chroma.from_documents(texts, embeddings) Create chain # Create chain qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.as_retriever()) Ask questions # Run query query = \"What did the president say about Ketanji Brown Jackson\" qa.run(query) Outlook With LLMs emerging as a transformative technology, LangChain comes in exactly at the right time — While this article focuses on the Python implementation, there is also a very popular JavaScript implementation of the LangChain library. The LangChain library already contains numerous functionalities today and continues to expand. With the many functionalities and modules provided, it can be hard to wrap your head around everything LangChain has to offer — but luckily, there are many great articles and tutorials out there, guiding you from your very first steps with LangChain to advanced projects. Useful links and further reading Get started with the LangChain official Quickstart Guide, Concepts and Tutorials here . DeepLearning.ai LangChain Course: https://learn.deeplearning.ai/langchain Awesome LangChain resources: https://github.com/kyrolabs/awesome-langchain LangChain Tutorials and Cookbooks: https://github.com/gkamradt/langchain-tutorials Chat your data Tutorial: https://github.com/hwchase17/chat-your-data Retrieval QA: https://python.langchain.com/docs/modules/chains/popular/vector_db_qa There are many super cool ideas, tutorials and articles about LangChain out there with a steadily growing content base. The documentation around LangChain is currently evolving fast, so it might be that some links change after the time of publishing this article. Enjoyed this article? Follow me\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://www.freecodecamp.org/news/beginners-guide-to-langchain/'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mHow to Use LangChain to Build With LLMs – A Beginner's Guide Search Submit your search query Forum Donate April 11, 2024 / #AI How to Use LangChain to Build With LLMs – A Beginner's Guide Jacob Lee Large language models (LLMs) are incredibly powerful general reasoning tools that are useful in a wide range of situations. But working with LLMs presents challenges that are different from building traditional software: Calls tend to be long-running, and stream generated output as it becomes available. Instead of structured input (something like JSON) with fixed parameters, they take unstructured and arbitrary natural language as input. They are capable of “understanding” subtleties of that language. They are non-deterministic. You may get different outputs even with the same input. LangChain is a popular framework for creating LLM-powered apps. It was built with these and other factors in mind, and provides a wide range of integrations with closed-source model providers (like OpenAI , Anthropic , and Google ), open source models, and other third-party components like vectorstores. This article will walk through the fundamentals of building with LLMs and LangChain’s Python library . The only requirement is basic familiarity with Python, – no machine learning experience needed! You’ll learn about: Basic project setup Using Chat Models and other fundamental LangChain components Using LangChain Expression Language to create chains Streaming output as soon as it is generated Passing context to steer the model’s output (basic RAG concepts) Debugging and tracing the internals of your chains Let’s dive in! Project Setup We recommend using a Jupyter notebook to run the code in this tutorial since it provides a clean, interactive environment. See this page for instructions on setting it up locally, or check out this Google Colab notebook for an in-browser experience. The first thing you'll need to do is choose which Chat Model you want to use. If you've ever used an interface like ChatGPT before, the basic idea of a Chat Model will be familiar to you – the model takes messages as input, and returns messages as output. The difference is that we'll be doing it in code. This guide defaults to Anthropic and their Claude 3 Chat Models, but LangChain also has a wide range of other integrations to choose from, including OpenAI models like GPT-4. pip install langchain_core langchain_anthropic If you’re working in a Jupyter notebook, you’ll need to prefix pip with a % symbol like this: %pip install langchain_core langchain_anthropic . You’ll also need an Anthropic API key, which you can obtain here from their console. Once you have it, set as an environment variable named ANTHROPIC_API_KEY : export ANTHROPIC_API_KEY=\"...\" You can also pass a key directly into the model if you prefer. First steps You can initialize your model like this: from langchain_anthropic import ChatAnthropic\n",
      "\n",
      "chat_model = ChatAnthropic(\n",
      "    model=\"claude-3-sonnet-20240229\",\n",
      "    temperature=0\n",
      ")\n",
      "\n",
      "# If you prefer to pass your key explicitly\n",
      "# chat_model = ChatAnthropic(\n",
      "#   model=\"claude-3-sonnet-20240229\",\n",
      "#   temperature=0,\n",
      "#   api_key=\"YOUR_ANTHROPIC_API_KEY\"\n",
      "# ) The model parameter is a string that matches one of Anthropic’s supported models . At the time of writing, Claude 3 Sonnet strikes a good balance between speed, cost, and reasoning capability. temperature is a measure of the amount of randomness the model uses to generate responses. For consistency, in this tutorial, we set it to 0 but you can experiment with higher values for creative use cases. Now, let’s try running it: chat_model.invoke(\"Tell me a joke about bears!\") Here’s the output: AIMessage(content=\"Here's a bear joke for you:\\\\n\\\\nWhy did the bear dissolve in water?\\\\nBecause it was a polar bear!\") You can see that the output is something called an AIMessage . This is because Chat Models use Chat Messages as input and output. Note: You were able to pass a simple string as input in the previous example because LangChain accepts a few forms of convenience shorthand that it automatically converts to the proper format. In this case, a single string is turned into an array with a single HumanMessage . LangChain also contains abstractions for pure text-completion LLMs, which are string input and string output. But at the time of writing, the chat-tuned variants have overtaken LLMs in popularity. For example, GPT-4 and Claude 3 are both Chat Models. To illustrate what’s going on, you can call the above with a more explicit list of messages: from langchain_core.messages import HumanMessage\n",
      "\n",
      "chat_model.invoke([\n",
      "    HumanMessage(\"Tell me a joke about bears!\")\n",
      "]) And you get a similar output: AIMessage(content=\"Here's a bear joke for you:\\\\n\\\\nWhy did the bear bring a briefcase to work?\\\\nHe was a business bear!\") Prompt Templates Models are useful on their own, but it’s often convenient to parameterize inputs so that you don’t repeat boilerplate. LangChain provides Prompt Templates for this purpose. Prompt templates in LangChain A simple example would be something like this: from langchain_core.prompts import ChatPromptTemplate\n",
      "\n",
      "joke_prompt = ChatPromptTemplate.from_messages([\n",
      "    (\"system\", \"You are a world class comedian.\"),\n",
      "    (\"human\", \"Tell me a joke about {topic}\")\n",
      "]) You can apply the templating using the same .invoke() method as with Chat Models: joke_prompt.invoke({\"topic\": \"beets\"}) Here’s the result: ChatPromptValue(messages=[\n",
      "    SystemMessage(content='You are a world class comedian.'),\n",
      "    HumanMessage(content='Tell me a joke about beets')\n",
      "]) Let’s go over each step: You construct a prompt template consisting of templates for a SystemMessage and a HumanMessage using from_messages . You can think of SystemMessages as meta-instructions that are not part of the current conversation, but purely guide input. The prompt template contains {topic} in curly braces. This denotes a required parameter named \"topic\" . You invoke the prompt template with a dict with a key named \"topic\" and a value \"beets\" . The result contains the formatted messages. Next, you'll learn how to use this prompt template with your Chat Model. Chaining You may have noticed that both the Prompt Template and Chat Model implement the .invoke() method. In LangChain terms, they are both instances of Runnables . You can compose Runnables into “chains” using the pipe ( | ) operator where you .invoke() the next step with the output of the previous one. Here’s an example: chain = joke_prompt | chat_model The resulting chain is itself a Runnable and automatically implements .invoke() (as well as several other methods, as we’ll see later). This is the foundation of LangChain Expression Language (LCEL) . Let’s invoke this new chain: chain.invoke({\"topic\": \"beets\"}) The chain returns a joke whose topic is beets: AIMessage(content=\"Here's a beet joke for you:\\\\n\\\\nWhy did the beet blush? Because it saw the salad dressing!\") Now, let’s say you want to work with just the raw string output of the message. LangChain has a component called an Output Parser , which, as the name implies, is responsible for parsing the output of a model into a more accessible format. Since composed chains are also Runnable, you can again use the pipe operator: from langchain_core.output_parsers import StrOutputParser\n",
      "\n",
      "str_chain = chain | StrOutputParser()\n",
      "\n",
      "# Equivalent to:\n",
      "# str_chain = joke_prompt | chat_model | StrOutputParser() Cool! Now let’s invoke it: str_chain.invoke({\"topic\": \"beets\"}) And the result is now a string as we’d hoped: \"Here's a beet joke for you:\\\\n\\\\nWhy did the beet blush? Because it saw the salad dressing!\" You still pass {\"topic\": \"beets\"} as input to the new str_chain because the first Runnable in the sequence is still the Prompt Template you declared before. Prompt model and output parser Streaming One of the biggest advantages to composing chains with LCEL is the streaming experience. All Runnables implement the .stream() method (and .astream() if you’re working in async environments), including chains. This method returns a generator that will yield output as soon as it’s available, which allows us to get output as quickly as possible. While every Runnable implements .stream() , not all of them support multiple chunks. For example, if you call .stream() on a Prompt Template, it will just yield a single chunk with the same output as .invoke() . You can iterate over the output using for ... in syntax. Try it with the str_chain you just declared: for chunk in str_chain.stream({\"topic\": \"beets\"}):\n",
      "    print(chunk, end=\"|\") And you get multiple strings as output (chunks are separated by a | character in the print function): Here|'s| a| b|eet| joke| for| you|:|\n",
      "\n",
      "Why| did| the| b|eet| bl|ush|?| Because| it| saw| the| sal|ad| d|ressing|!| Chains composed like str_chain will start streaming as early as possible, which in this case is the Chat Model in the chain. Some Output Parsers (like the StrOutputParser used here) and many LCEL Primitives are able to process streamed chunks from previous steps as they are generated – essentially acting as transform streams or passthroughs – and do not disrupt streaming. How to Guide Generation with Context LLMs are trained on large quantities of data and have some innate “knowledge” of various topics. Still, it’s common to pass the model private or more specific data as context when answering to glean useful information or insights. If you've heard the term \"RAG\", or \"retrieval-augmented generation\" before, this is the core principle behind it. One of the simplest examples of this is telling the LLM what the current date is. Because LLMs are snapshots of when they are trained, they can’t natively determine the current time. Here’s an example: chat_model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")\n",
      "\n",
      "chat_model.invoke(\"What is the current date?\") The response: AIMessage(content=\"Unfortunately, I don't actually have a concept of the current date and time. As an AI assistant without an integrated \u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3mUltimate Guide to Getting Started with LangChain | by Zilliz | Medium Open in app Sign up Sign in Write Sign up Sign in Ultimate Guide to Getting Started with LangChain Zilliz · Follow 6 min read · Nov 17, 2023 -- Listen Share Have you seen the parrot + chain emoji popping up around AI lately? Those are LangChain’s signature emojis. LangChain is an AI Agent tool that adds functionality to large language models (LLMs) like GPT. In addition, it includes functionality such as token management and context management. For this getting started tutorial, we look at two primary LangChain examples with real-world use cases. First, how to query GPT. Second, how to query a document with a Colab notebook available here . In this tutorial we cover: What is LangChain? How Can You Run LangChain Queries? Query GPT Query a Document Introduction to LangChain Summary What is LangChain? LangChain is a framework for building applications that leverage LLMs. It allows you to quickly build with the CVP Framework . The two core LangChain functionalities for LLMs are 1) to be data-aware and 2) to be agentic. Data-awareness is the ability to incorporate outside data sources into an LLM application. Agency is the ability to use other tools. As with many LLM tools, LangChain’s default LLM is OpenAI’s GPT and you need an API key from OpenAI to use it. In addition, LangChain works with both Python and JavaScript. In this tutorial, you will learn how it works using Python examples. You can install the Python library through pip by running pip install langchain . How does LangChain work? LangChain’s question-answering flow consists of building blocks that can be easily swapped to create a custom template according to individual needs. These blocks include the question, embedding, documents used to train the model, the constructed prompt, and a response. Therefore, if a company desires a chat experience trained by specific documents, LangChain can swap in and out the various components to achieve that goal. How to use LangChain? One of the primary LangChain use cases is to query text data. You can use it to query documents, vector stores, or to smooth your interactions with GPT, much like LlamaIndex . In this tutorial, we cover a simple example of how to interact with GPT using LangChain and query a document for semantic meaning using LangChain with a vector store. Query GPT Most people’s familiarity with GPT comes from chatting with ChatGPT. ChatGPT is OpenAI’s flagship interface for interacting with GPT. However, if you want to interact with GPT programmatically, you need a query interface like LangChain. LangChain provides a range of query interfaces for GPT, from simple one-question prompts to few shot learning via context. In this example, we’ll look at how to use LangChain to chain together questions using a prompt template. There are a few Python libraries you need to install first. We can install them with # pip install langchain openai python-dotenv tiktoken . I use python-dotenv because I manage my environment variables in a .env file, but you can use whatever method you want to get your OpenAI API key loaded. With our OpenAI API key ready, we must load up our LangChain tools. We need the PromptTemplate and LLMChain imports from langchain and the OpenAI import from langchain.llms . We use OpenAI’s text model, text-davinci-003 for this example. Next, we create a template to query GPT with. The template that we create below tells GPT to answer the given questions one at a time. First, we create a string representing input variables within brackets, similar to how f-strings work. import os from dotenv import load_dotenv import openai load_dotenv() openai.api_key = os.getenv(\"OPENAI_API_KEY\") from langchain import PromptTemplate, LLMChain from langchain.llms import OpenAI davinci = OpenAI(model_name=\"text-davinci-003\") multi_template = \"\"\"Answer the following questions one at a time. Questions: {questions} Answers: \"\"\" Next, we use the PromptTemplate object to create a template from the string with specified input variables. With our prompt template ready, we can create an LLM “chain” by passing in the prompt and the chosen LLM. Now it’s time to create the questions. Once we have the questions we want to ask, we run the LLM chain with the questions passed in to get our answers. long_prompt = PromptTemplate(template=multi_template, input_variables=[\"questions\"]) llm_chain = LLMChain( prompt=long_prompt, llm=davinci ) qs_str = ( \"Which NFL team won the Super Bowl in the 2010 season?\\n\" + \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" + \"Who was the 12th person on the moon?\" + \"How many eyes does a blade of grass have?\" ) print(llm_chain.run(qs_str)) The image below shows the expected results from our example questions. Query a document One of the areas for improvement of GPT and LLMs at large is that they are only trained on data available at their time of training. This means that over time, they lose context and accuracy. Much like the CVP framework, LangChain provides a way to remediate this problem with vector databases. Many vector databases are available; for this example, we use Milvus because of our familiarity with it. To demonstrate LangChain’s ability to inject up-to-date knowledge into your LLM application and the ability to do a semantic search , we cover how to query a document. We use a transcript from the State of the Union address for this example. You can download the transcript here and find the Colab notebook here . To get the libraries you need for this part of the tutorial, run pip install langchain openai milvus pymilvus python-dotenv tiktoken . As with the example of chaining questions together, we start by loading our OpenAI API key and the LLM. Then, we spin up a vector database using Milvus Lite , which allows us to run Milvus directly in our notebook. import os from dotenv import load_dotenv import openai load_dotenv() openai.api_key = os.getenv(\"OPENAI_API_KEY\") from langchain.llms import OpenAI davinci = OpenAI(model_name=\"text-davinci-003\") from milvus import default_server default_server.start() Now we are ready to get into the specifics of querying a document. There are a lot of imports from LangChain this time. We need the Open AI Embeddings, the character text splitter, the Milvus integration, the text loader, and the retrieval Q/A chain. The first thing we do is set up a loader and load the text file. In this case, I have it stored in the same folder as this notebook under state_of_the_union.txt. Next, we split up the text and store it as a set of LangChain docs. Then, we can set up our vector database. In this case, we create a Milvus collection from the documents we just ingested via the TextLoader and CharacterTextSplitter . We also pass in the OpenAI embeddings as the set of text vector embeddings. With our vector database loaded, we can use the RetrievalQA object to query the documents via a vector database. We use the chain type stuff \" and pass in OpenAI as our LLM and the Milvus vector database as a retriever. Then, we can create a query, such as “What did the president say about Ketanji Brown Jackson?” and run` the query. Finally, we should shut down our vector database for a clean close. from langchain.embeddings.openai import OpenAIEmbeddings from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import Milvus from langchain.document_loaders import TextLoader from langchain.chains import RetrievalQA loader = TextLoader('./state_of_the_union.txt') documents = loader.load() text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0) docs = text_splitter.split_documents(documents) embeddings = OpenAIEmbeddings() vector_db = Milvus.from_documents( docs, embeddings, connection_args={\"host\": \"127.0.0.1\", \"port\": default_server.listen_port}, ) qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=vector_db.as_retriever()) query = \"What did the president say about Ketanji Brown Jackson?\" qa.run(query) default_server.stop() The image below shows what an expected response could look like. We should get a response like “The president said that Ketanji Brown Jackson is one of the nation’s top legal minds, a former top litigator in private practice, a former federal public defender, …” LangChain alternative There are several chat-based tools that could be considered alternatives to LangChain, and people often debate which ones are the best. A few that come up frequently include: AgentGPT TensorFlow Auto-GPT BabyAGI Semantic UI LlamaIndex Summary of an introduction to LangChain In this article, we covered the basics of how to use LangChain. We learned that LangChain is a framework for building LLM applications that relies on two key factors. The first factor is using outside data, such as a text document. The second factor is using other tools, such as a vector database . We covered two examples. First, we looked at one of the classic LangChain examples — how to chain together multiple questions. Then, we looked at a practical way to use LangChain to inject domain knowledge by combining it with a vector database like Milvus to query documents. Product -- -- Follow Written by Zilliz 190 Followers Building the #VectorDatabase for enterprise-grade AI. Follow Help Status About Careers Press Blog Privacy Terms Text to speech Teams\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHere are some excellent resources to learn about the LangChain framework:\n",
      "\n",
      "1. **[Top 5 Resources to Learn LangChain](https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702)** by Ankit Yadav on Medium:\n",
      "   - This article provides a curated list of valuable resources, including short courses by DeepLearning.ai, articles, YouTube playlists, and the official LangChain tutorials page.\n",
      "\n",
      "2. **[LangChain Official Documentation](https://python.langchain.com/v0.2/docs/introduction/)**:\n",
      "   - The official documentation is a comprehensive resource that covers everything from basic concepts to advanced tutorials. It includes guides on building various applications, how-to guides, and an API reference.\n",
      "\n",
      "3. **[Introducing LangChain: A Beginner’s Guide](https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-️-5e751622edb7)** by Ellen Hoeven on Medium:\n",
      "   - This article provides an overview of the most important concepts in LangChain and includes hands-on examples to help you get started with building applications using LangChain.\n",
      "\n",
      "4. **[Beginner's Guide to LangChain](https://www.freecodecamp.org/news/beginners-guide-to-langchain/)** by Jacob Lee on FreeCodeCamp:\n",
      "   - This guide walks through the fundamentals of building with LangChain’s Python library, including project setup, using chat models, creating chains, and streaming output.\n",
      "\n",
      "5. **[Ultimate Guide to Getting Started with LangChain](https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8)** by Zilliz on Medium:\n",
      "   - This tutorial covers the basics of LangChain, including how to query GPT and documents, and provides practical examples using Python.\n",
      "\n",
      "These resources should provide a solid foundation for learning and building applications with the LangChain framework.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | ToolsAgentOutputParser()\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "input1 = \"What are good resources on learning about the langchain framework?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:09:57.699319Z",
     "iopub.status.busy": "2024-07-18T12:09:57.699086Z",
     "iopub.status.idle": "2024-07-18T12:09:57.703279Z",
     "shell.execute_reply": "2024-07-18T12:09:57.702792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are good resources on learning about the langchain framework?',\n",
       " 'chat_history': [HumanMessage(content='What are good resources on learning about the langchain framework?'),\n",
       "  AIMessage(content=\"Here are some excellent resources to learn about the LangChain framework:\\n\\n1. **[Top 5 Resources to Learn LangChain](https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702)** by Ankit Yadav on Medium:\\n   - This article provides a curated list of valuable resources, including short courses by DeepLearning.ai, articles, YouTube playlists, and the official LangChain tutorials page.\\n\\n2. **[LangChain Official Documentation](https://python.langchain.com/v0.2/docs/introduction/)**:\\n   - The official documentation is a comprehensive resource that covers everything from basic concepts to advanced tutorials. It includes guides on building various applications, how-to guides, and an API reference.\\n\\n3. **[Introducing LangChain: A Beginner’s Guide](https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-️-5e751622edb7)** by Ellen Hoeven on Medium:\\n   - This article provides an overview of the most important concepts in LangChain and includes hands-on examples to help you get started with building applications using LangChain.\\n\\n4. **[Beginner's Guide to LangChain](https://www.freecodecamp.org/news/beginners-guide-to-langchain/)** by Jacob Lee on FreeCodeCamp:\\n   - This guide walks through the fundamentals of building with LangChain’s Python library, including project setup, using chat models, creating chains, and streaming output.\\n\\n5. **[Ultimate Guide to Getting Started with LangChain](https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8)** by Zilliz on Medium:\\n   - This tutorial covers the basics of LangChain, including how to query GPT and documents, and provides practical examples using Python.\\n\\nThese resources should provide a solid foundation for learning and building applications with the LangChain framework.\")],\n",
       " 'output': \"Here are some excellent resources to learn about the LangChain framework:\\n\\n1. **[Top 5 Resources to Learn LangChain](https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702)** by Ankit Yadav on Medium:\\n   - This article provides a curated list of valuable resources, including short courses by DeepLearning.ai, articles, YouTube playlists, and the official LangChain tutorials page.\\n\\n2. **[LangChain Official Documentation](https://python.langchain.com/v0.2/docs/introduction/)**:\\n   - The official documentation is a comprehensive resource that covers everything from basic concepts to advanced tutorials. It includes guides on building various applications, how-to guides, and an API reference.\\n\\n3. **[Introducing LangChain: A Beginner’s Guide](https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-️-5e751622edb7)** by Ellen Hoeven on Medium:\\n   - This article provides an overview of the most important concepts in LangChain and includes hands-on examples to help you get started with building applications using LangChain.\\n\\n4. **[Beginner's Guide to LangChain](https://www.freecodecamp.org/news/beginners-guide-to-langchain/)** by Jacob Lee on FreeCodeCamp:\\n   - This guide walks through the fundamentals of building with LangChain’s Python library, including project setup, using chat models, creating chains, and streaming output.\\n\\n5. **[Ultimate Guide to Getting Started with LangChain](https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8)** by Zilliz on Medium:\\n   - This tutorial covers the basics of LangChain, including how to query GPT and documents, and provides practical examples using Python.\\n\\nThese resources should provide a solid foundation for learning and building applications with the LangChain framework.\"}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
