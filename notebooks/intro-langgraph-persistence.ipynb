{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangGraph Persistence\n",
    "\n",
    "**Duration:** 60-90 minutes  \n",
    "**Level:** Beginner to Intermediate\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Understand the mental model**: Thread (conversation) → Checkpoints (snapshots) → Replay/Update (time travel/edits) → Memory Store (cross-thread facts)\n",
    "2. **Run a graph with persistence** using checkpointers\n",
    "3. **Inspect state and history** to see saved checkpoints\n",
    "4. **Time-travel** to replay from previous checkpoints\n",
    "5. **Edit state** using update_state with reducers\n",
    "6. **Store user memories** across multiple threads using Store\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Setup: Install Dependencies\n\nFirst, let's install the required packages:\n\n**Note**: Since LangGraph v0.2, the SqliteSaver requires a separate package installation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Uncomment and run if needed\n# !pip install langgraph langgraph-checkpoint-sqlite langchain-core langchain-openai"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set your OpenAI API key\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Mental Model — The Git Analogy (10 min)\n",
    "\n",
    "Understanding LangGraph persistence is easiest through a **Git analogy**:\n",
    "\n",
    "| LangGraph Concept | Git Equivalent | Description |\n",
    "|------------------|----------------|-------------|\n",
    "| **Thread** | Branch | A unique conversation or execution path |\n",
    "| **Checkpoint** | Commit | A snapshot of state at a specific point in time |\n",
    "| **Replay** | Checkout + re-run | Go back to a checkpoint and continue from there |\n",
    "| **Update state** | Commit amend | Modify the state at a checkpoint (with reducers) |\n",
    "| **Memory Store** | Shared repo | Cross-thread persistent storage (not tied to one thread) |\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Threads** identify unique conversation flows (like Git branches)\n",
    "2. **Checkpoints** save state after each \"super-step\" (like Git commits)\n",
    "3. **Time-travel** lets you replay from any checkpoint\n",
    "4. **Reducers** control how state updates merge or overwrite\n",
    "5. **Store** provides cross-thread memory for facts that transcend individual conversations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Minimal Working Example (15 min)\n",
    "\n",
    "Let's build the smallest possible graph with persistence to understand the fundamentals.\n",
    "\n",
    "### Step 1: Define a Simple State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"Simple state with a counter and a list of messages.\"\"\"\n",
    "    count: int\n",
    "    messages: list[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Simple Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_node(state: State) -> State:\n",
    "    \"\"\"Increment the counter by 1.\"\"\"\n",
    "    return {\"count\": state[\"count\"] + 1, \"messages\": state[\"messages\"] + [f\"Count is now {state['count'] + 1}\"]}\n",
    "\n",
    "def double_node(state: State) -> State:\n",
    "    \"\"\"Double the counter.\"\"\"\n",
    "    new_count = state[\"count\"] * 2\n",
    "    return {\"count\": new_count, \"messages\": state[\"messages\"] + [f\"Doubled to {new_count}\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Graph with SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sqlite3\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.sqlite import SqliteSaver\n\n# Create a checkpointer (persists to SQLite in-memory database)\nconn = sqlite3.connect(\":memory:\", check_same_thread=False)\ncheckpointer = SqliteSaver(conn)\n\n# Build the graph\nworkflow = StateGraph(State)\nworkflow.add_node(\"increment\", increment_node)\nworkflow.add_node(\"double\", double_node)\n\n# Define edges\nworkflow.set_entry_point(\"increment\")\nworkflow.add_edge(\"increment\", \"double\")\nworkflow.add_edge(\"double\", END)\n\n# Compile with checkpointer\ngraph = workflow.compile(checkpointer=checkpointer)\n\nprint(\"Graph compiled successfully with persistence!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Graph with a Thread ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread ID identifies this conversation\n",
    "config = {\"configurable\": {\"thread_id\": \"thread_1\"}}\n",
    "\n",
    "# Initial state\n",
    "initial_state = {\"count\": 5, \"messages\": [\"Starting\"]}\n",
    "\n",
    "# Run the graph\n",
    "result = graph.invoke(initial_state, config)\n",
    "print(\"\\nFinal State:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Inspect Current State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current state\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "print(\"\\nCurrent State Info:\")\n",
    "print(f\"Values: {current_state.values}\")\n",
    "print(f\"Next nodes: {current_state.next}\")\n",
    "print(f\"Checkpoint ID: {current_state.config['configurable']['checkpoint_id']}\")\n",
    "print(f\"Step: {current_state.metadata.get('step', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: View State History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all checkpoints in history\n",
    "history = list(graph.get_state_history(config))\n",
    "\n",
    "print(f\"\\nTotal checkpoints: {len(history)}\\n\")\n",
    "\n",
    "for i, checkpoint in enumerate(history):\n",
    "    print(f\"Checkpoint {i}:\")\n",
    "    print(f\"  ID: {checkpoint.config['configurable']['checkpoint_id']}\")\n",
    "    print(f\"  Step: {checkpoint.metadata.get('step', 'N/A')}\")\n",
    "    print(f\"  Values: {checkpoint.values}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- **`values`**: The actual state at this checkpoint\n",
    "- **`next`**: Which nodes will execute next (empty list means done)\n",
    "- **`checkpoint_id`**: Unique identifier for this snapshot\n",
    "- **`step`**: The step number in the execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Time-Travel & Forking (10 min)\n",
    "\n",
    "One of the most powerful features is the ability to **replay** from any checkpoint.\n",
    "\n",
    "### Understanding Replay Semantics\n",
    "\n",
    "- **Before the checkpoint**: Steps are replayed without side effects (read from history)\n",
    "- **After the checkpoint**: Execution continues normally (creates new checkpoints)\n",
    "\n",
    "### Step 1: Pick a Checkpoint to Replay From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick the second checkpoint (index 1)\n",
    "checkpoint_to_replay = history[2]\n",
    "\n",
    "print(f\"Replaying from checkpoint: {checkpoint_to_replay.config['configurable']['checkpoint_id']}\")\n",
    "print(f\"State at this checkpoint: {checkpoint_to_replay.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a New Config with checkpoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config with both thread_id and checkpoint_id\n",
    "replay_config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"thread_1\",\n",
    "        \"checkpoint_id\": checkpoint_to_replay.config[\"configurable\"][\"checkpoint_id\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get state at this checkpoint\n",
    "state_at_checkpoint = graph.get_state(replay_config)\n",
    "print(f\"\\nState at checkpoint: {state_at_checkpoint.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Continue Execution (Creating a Fork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume from this checkpoint - this creates a new branch!\n",
    "# Pass None as input to continue from where we left off\n",
    "forked_result = graph.invoke(None, replay_config)\n",
    "\n",
    "print(\"\\nForked execution result:\")\n",
    "print(forked_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compare Original vs Forked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original thread history\n",
    "original_history = list(graph.get_state_history(config))\n",
    "print(f\"Original thread has {len(original_history)} checkpoints\")\n",
    "\n",
    "# The forked execution created new checkpoints from the replay point\n",
    "print(f\"\\nForked result: {forked_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Update State with Reducers (10 min)\n",
    "\n",
    "Sometimes you need to **modify state** at a checkpoint without re-running nodes. This is where `update_state()` comes in.\n",
    "\n",
    "### Understanding Reducers\n",
    "\n",
    "- **Without reducer**: Values are **overwritten**\n",
    "- **With reducer**: Values are **merged** according to the reducer function\n",
    "\n",
    "### Step 1: Define State with Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from operator import add\n",
    "\n",
    "class StateWithReducer(TypedDict):\n",
    "    \"\"\"State with a reducer on the messages list.\"\"\"\n",
    "    count: int  # No reducer - overwrites\n",
    "    messages: Annotated[list[str], add]  # Reducer - appends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a New Graph with Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def increment_with_reducer(state: StateWithReducer) -> StateWithReducer:\n    return {\"count\": state[\"count\"] + 1, \"messages\": [f\"Incremented to {state['count'] + 1}\"]}\n\ndef double_with_reducer(state: StateWithReducer) -> StateWithReducer:\n    new_count = state[\"count\"] * 2\n    return {\"count\": new_count, \"messages\": [f\"Doubled to {new_count}\"]}\n\n# Build new graph with reducer state\nworkflow_reducer = StateGraph(StateWithReducer)\nworkflow_reducer.add_node(\"increment\", increment_with_reducer)\nworkflow_reducer.add_node(\"double\", double_with_reducer)\nworkflow_reducer.set_entry_point(\"increment\")\nworkflow_reducer.add_edge(\"increment\", \"double\")\nworkflow_reducer.add_edge(\"double\", END)\n\n# Create checkpointer for reducer graph\nconn_reducer = sqlite3.connect(\":memory:\", check_same_thread=False)\ngraph_reducer = workflow_reducer.compile(checkpointer=SqliteSaver(conn_reducer))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run and Update State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_reducer = {\"configurable\": {\"thread_id\": \"thread_reducer\"}}\n",
    "\n",
    "# Run the graph\n",
    "result_reducer = graph_reducer.invoke({\"count\": 3, \"messages\": [\"Start\"]}, config_reducer)\n",
    "print(\"Initial result:\")\n",
    "print(result_reducer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Update State with update_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the state\n",
    "# - count will be OVERWRITTEN (no reducer)\n",
    "# - messages will be APPENDED (has reducer)\n",
    "graph_reducer.update_state(\n",
    "    config_reducer,\n",
    "    {\"count\": 100, \"messages\": [\"Manual update\"]}\n",
    ")\n",
    "\n",
    "# Check updated state\n",
    "updated_state = graph_reducer.get_state(config_reducer)\n",
    "print(\"\\nUpdated state:\")\n",
    "print(updated_state.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- **`count`** was overwritten to 100 (no reducer)\n",
    "- **`messages`** had \"Manual update\" appended to the existing list (has reducer)\n",
    "\n",
    "### Exercise: Remove the Reducer\n",
    "\n",
    "**Question**: How would you make `messages` overwrite instead of append?\n",
    "\n",
    "**Answer**: Remove the `Annotated` and reducer:\n",
    "\n",
    "```python\n",
    "class StateWithReducer(TypedDict):\n",
    "    count: int\n",
    "    messages: list[str]  # No Annotated - will overwrite\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Memory Across Threads — The Store (10 min)\n",
    "\n",
    "**Checkpoints** are per-thread. But what if you need to store facts that span multiple conversations?\n",
    "\n",
    "That's where **Store** comes in!\n",
    "\n",
    "### Store vs Checkpoints\n",
    "\n",
    "| Feature | Checkpoints | Store |\n",
    "|---------|------------|-------|\n",
    "| Scope | Single thread | Cross-thread |\n",
    "| Use case | Conversation history | User preferences, facts |\n",
    "| Analogy | Git commits | Shared database |\n",
    "\n",
    "### Step 1: Create an InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "print(\"InMemoryStore created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Store User Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store memories with namespacing: (user_id, \"memories\")\n",
    "user_id = \"user_123\"\n",
    "namespace = (user_id, \"memories\")\n",
    "\n",
    "# Store some memories\n",
    "store.put(namespace, \"memory_1\", {\"text\": \"User likes pizza\", \"timestamp\": \"2025-01-01\"})\n",
    "store.put(namespace, \"memory_2\", {\"text\": \"User is a software engineer\", \"timestamp\": \"2025-01-02\"})\n",
    "store.put(namespace, \"memory_3\", {\"text\": \"User lives in San Francisco\", \"timestamp\": \"2025-01-03\"})\n",
    "\n",
    "print(f\"Stored 3 memories for {user_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Search Memories (Cross-Thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all memories\n",
    "memories = store.search(namespace)\n",
    "\n",
    "print(f\"\\nAll memories for {user_id}:\")\n",
    "for item in memories:\n",
    "    print(f\"  - Key: {item.key}\")\n",
    "    print(f\"    Value: {item.value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use Store in a Different Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This simulates a new conversation (different thread)\n",
    "# but we can still access the same memories!\n",
    "\n",
    "def simulate_new_thread():\n",
    "    \"\"\"Simulate accessing memories in a completely different thread.\"\"\"\n",
    "    user_memories = store.search((user_id, \"memories\"))\n",
    "    \n",
    "    print(\"Accessing memories in NEW thread (different conversation):\")\n",
    "    for item in user_memories:\n",
    "        print(f\"  - {item.value['text']}\")\n",
    "\n",
    "simulate_new_thread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Integrate Store with Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langgraph.store.base import BaseStore\n\nclass StateWithStore(TypedDict):\n    messages: list[str]\n    user_id: str\n\ndef node_with_store_access(state: StateWithStore, *, store: BaseStore) -> StateWithStore:\n    \"\"\"Node that can access the store via the store parameter.\"\"\"\n    # Access user memories from store\n    user_id = state[\"user_id\"]\n    memories = list(store.search((user_id, \"memories\")))\n    \n    memory_texts = [m.value[\"text\"] for m in memories]\n    \n    return {\n        \"messages\": state[\"messages\"] + [f\"Found {len(memories)} memories\"] + memory_texts,\n        \"user_id\": user_id\n    }\n\n# Build graph with store\nworkflow_with_store = StateGraph(StateWithStore)\nworkflow_with_store.add_node(\"fetch_memories\", node_with_store_access)\nworkflow_with_store.set_entry_point(\"fetch_memories\")\nworkflow_with_store.add_edge(\"fetch_memories\", END)\n\n# Compile with both checkpointer AND store\nconn_store = sqlite3.connect(\":memory:\", check_same_thread=False)\ngraph_with_store = workflow_with_store.compile(\n    checkpointer=SqliteSaver(conn_store),\n    store=store\n)\n\n# Run the graph\nresult_with_store = graph_with_store.invoke(\n    {\"messages\": [\"Starting\"], \"user_id\": user_id},\n    {\"configurable\": {\"thread_id\": \"thread_with_store\"}}\n)\n\nprint(\"\\nResult with store access:\")\nfor msg in result_with_store[\"messages\"]:\n    print(f\"  {msg}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- **Store is cross-thread**: Accessible from any thread\n",
    "- **Namespacing**: Organize data with tuples like `(user_id, \"memories\")`\n",
    "- **Integration**: Pass `store=store` when compiling the graph\n",
    "- **Access in nodes**: Use `store` parameter in node functions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Human-in-the-Loop & Fault Tolerance (5 min)\n",
    "\n",
    "Persistence enables two critical capabilities:\n",
    "\n",
    "### 1. Human-in-the-Loop (HITL)\n",
    "\n",
    "- **Inspect** state before continuing\n",
    "- **Approve/reject** actions\n",
    "- **Edit** state if needed\n",
    "- **Resume** from where you left off\n",
    "\n",
    "Example workflow:\n",
    "```python\n",
    "# Pause before a critical action\n",
    "state = graph.get_state(config)\n",
    "if state.next == [\"dangerous_action\"]:\n",
    "    user_approval = input(\"Approve? (y/n): \")\n",
    "    if user_approval == \"y\":\n",
    "        graph.invoke(None, config)  # Resume\n",
    "```\n",
    "\n",
    "### 2. Fault Tolerance\n",
    "\n",
    "- **Automatic checkpointing** preserves state\n",
    "- **Restart from failure**: If a node crashes, restart from the last checkpoint\n",
    "- **Pending writes preserved**: Uncommitted state changes are saved\n",
    "\n",
    "Example:\n",
    "```python\n",
    "try:\n",
    "    result = graph.invoke(input, config)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    # State is preserved! Resume later:\n",
    "    result = graph.invoke(None, config)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Lab (15-20 min)\n",
    "\n",
    "Now it's your turn! Complete these exercises:\n",
    "\n",
    "### Exercise 1: Run Graph and View State\n",
    "\n",
    "Create a new graph, run it, and inspect the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a graph, run it with a thread_id, and view the state\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: View History and Identify Checkpoints\n",
    "\n",
    "Get the state history and print details about each checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get state history and identify at least 4 checkpoints\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Time-Travel (Replay from Checkpoint)\n",
    "\n",
    "Pick checkpoint 2 and replay from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replay from checkpoint 2 and observe the branch\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Update State\n",
    "\n",
    "Use `update_state()` to fix a value and observe the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update state to fix a value, then re-run one step\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Cross-Thread Memory\n",
    "\n",
    "Add a user memory, then read it in a completely different thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a memory for a user, then access it in a new thread\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls (5 min)\n",
    "\n",
    "### 1. Forgetting `thread_id` → Nothing Persists\n",
    "\n",
    "```python\n",
    "# ❌ Wrong - no thread_id\n",
    "graph.invoke(input)  # Nothing is saved!\n",
    "\n",
    "# ✅ Correct\n",
    "graph.invoke(input, {\"configurable\": {\"thread_id\": \"my_thread\"}})\n",
    "```\n",
    "\n",
    "### 2. Expecting Overwrite Where a Reducer Merges\n",
    "\n",
    "```python\n",
    "# If messages has a reducer:\n",
    "messages: Annotated[list[str], add]\n",
    "\n",
    "# update_state will APPEND, not replace!\n",
    "graph.update_state(config, {\"messages\": [\"new\"]})\n",
    "```\n",
    "\n",
    "### 3. Confusing Checkpoints (Per-Thread) with Store (Cross-Thread)\n",
    "\n",
    "- **Checkpoints**: Thread-specific conversation history\n",
    "- **Store**: Shared facts across all threads\n",
    "\n",
    "### 4. Assuming Replay Re-Calls External APIs\n",
    "\n",
    "- Replay **reads from history** for steps before the checkpoint\n",
    "- It does **NOT** re-execute those steps or call APIs again\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cheat Sheet\n\n### Run with Persistence\n\n```python\nimport sqlite3\nfrom langgraph.checkpoint.sqlite import SqliteSaver\n\n# Create checkpointer\nconn = sqlite3.connect(\":memory:\", check_same_thread=False)\ncheckpointer = SqliteSaver(conn)\n\n# Or for a file-based database:\n# conn = sqlite3.connect(\"checkpoints.db\", check_same_thread=False)\n# checkpointer = SqliteSaver(conn)\n\ngraph = workflow.compile(checkpointer=checkpointer)\n\nconfig = {\"configurable\": {\"thread_id\": \"thread_1\"}}\nresult = graph.invoke(input, config)\n```\n\n### Inspect State\n\n```python\n# Get current state\ncurrent = graph.get_state(config)\n\n# Get all history\nhistory = list(graph.get_state_history(config))\n```\n\n### Time-Travel\n\n```python\nconfig_with_checkpoint = {\n    \"configurable\": {\n        \"thread_id\": \"thread_1\",\n        \"checkpoint_id\": \"checkpoint_id_here\"\n    }\n}\ngraph.invoke(None, config_with_checkpoint)\n```\n\n### Update State\n\n```python\ngraph.update_state(\n    config,\n    {\"key\": \"value\"},\n    as_node=\"node_name\"  # Optional\n)\n```\n\n### Cross-Thread Memory (Store)\n\n```python\nfrom langgraph.store.memory import InMemoryStore\n\nstore = InMemoryStore()\nstore.put((user_id, \"memories\"), \"key\", {\"data\": \"value\"})\nresults = store.search((user_id, \"memories\"))\n\n# Compile with store\ngraph = workflow.compile(checkpointer=checkpointer, store=store)\n```\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment Questions\n",
    "\n",
    "### Q1: When do you need a Store vs. Checkpoints?\n",
    "\n",
    "**Answer**: \n",
    "- Use **checkpoints** for thread-specific conversation history and state\n",
    "- Use **Store** for cross-thread facts (user preferences, memories) that need to be accessed from any conversation\n",
    "\n",
    "### Q2: What happens to steps BEFORE the checkpoint_id during replay?\n",
    "\n",
    "**Answer**: \n",
    "- Steps before the checkpoint are **replayed from history** without re-executing\n",
    "- No side effects occur (APIs are not called again)\n",
    "- Only steps **after** the checkpoint execute normally\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Optional Stretch Exercises\n\n### 1. Swap In-Memory → File-Based SqliteSaver\n\nTry changing from in-memory persistence to a real SQLite file:\n\n```python\nimport sqlite3\nfrom langgraph.checkpoint.sqlite import SqliteSaver\n\nconn = sqlite3.connect(\"./my_checkpoints.db\", check_same_thread=False)\ncheckpointer = SqliteSaver(conn)\n```\n\nThis will persist checkpoints to disk so they survive between program runs!\n\n### 2. Using Context Manager Approach\n\nAlternatively, you can use the context manager approach:\n\n```python\nfrom langgraph.checkpoint.sqlite import SqliteSaver\n\nwith SqliteSaver.from_conn_string(\"./checkpoints.db\") as checkpointer:\n    graph = workflow.compile(checkpointer=checkpointer)\n    result = graph.invoke(input, config)\n```\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "✅ The **Git analogy** for persistence (threads, checkpoints, replay, store)  \n",
    "✅ How to **run graphs with persistence** using checkpointers  \n",
    "✅ How to **inspect state and history**  \n",
    "✅ How to **time-travel** and create forks  \n",
    "✅ How **reducers** control state updates (merge vs overwrite)  \n",
    "✅ How to use **Store** for cross-thread memory  \n",
    "✅ Common pitfalls to avoid  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore **human-in-the-loop** patterns\n",
    "- Try **production checkpointers** (PostgreSQL, Redis)\n",
    "- Build **multi-agent systems** with shared memory\n",
    "- Implement **semantic search** in your Store\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [LangGraph Persistence Docs](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "- [LangGraph Memory Docs](https://langchain-ai.github.io/langgraph/concepts/memory/)\n",
    "- [State and Reducers](https://langchain-ai.github.io/langgraph/concepts/low_level/)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Building! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}