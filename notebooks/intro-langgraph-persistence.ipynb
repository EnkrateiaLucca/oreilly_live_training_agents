{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangGraph Persistence\n",
    "\n",
    "**Duration:** 60-90 minutes  \n",
    "**Level:** Beginner to Intermediate\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Understand the mental model**: Thread (conversation) ‚Üí Checkpoints (snapshots) ‚Üí Replay/Update (time travel/edits) ‚Üí Memory Store (cross-thread facts)\n",
    "2. **Run a graph with persistence** using checkpointers\n",
    "3. **Inspect state and history** to see saved checkpoints\n",
    "4. **Time-travel** to replay from previous checkpoints\n",
    "5. **Edit state** using update_state with reducers\n",
    "6. **Store user memories** across multiple threads using Store\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies\n",
    "\n",
    "First, let's install the required packages:\n",
    "\n",
    "**Note**: Since LangGraph v0.2, the SqliteSaver requires a separate package installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if needed\n",
    "# !pip install langgraph langgraph-checkpoint-sqlite langchain-core langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Mental Model ‚Äî The Git Analogy (10 min)\n",
    "\n",
    "Understanding LangGraph persistence is easiest through a **Git analogy**:\n",
    "\n",
    "| LangGraph Concept | Git Equivalent | Description |\n",
    "|------------------|----------------|-------------|\n",
    "| **Thread** | Branch | A unique conversation or execution path |\n",
    "| **Checkpoint** | Commit | A snapshot of state at a specific point in time |\n",
    "| **Replay** | Checkout + re-run | Go back to a checkpoint and continue from there |\n",
    "| **Update state** | Commit amend | Modify the state at a checkpoint (with reducers) |\n",
    "| **Memory Store** | Shared repo | Cross-thread persistent storage (not tied to one thread) |\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Threads** identify unique conversation flows (like Git branches)\n",
    "2. **Checkpoints** save state after each \"super-step\" (like Git commits)\n",
    "3. **Time-travel** lets you replay from any checkpoint\n",
    "4. **Reducers** control how state updates merge or overwrite\n",
    "5. **Store** provides cross-thread memory for facts that transcend individual conversations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Minimal Working Example (15 min)\n",
    "\n",
    "Let's build the smallest possible graph with persistence to understand the fundamentals.\n",
    "\n",
    "### Step 1: Define a Simple State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"Simple state with a counter and a list of messages.\"\"\"\n",
    "    count: int\n",
    "    messages: list[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Simple Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_node(state: State) -> State:\n",
    "    \"\"\"Increment the counter by 1.\"\"\"\n",
    "    return {\"count\": state[\"count\"] + 1, \"messages\": state[\"messages\"] + [f\"Count is now {state['count'] + 1}\"]}\n",
    "\n",
    "def double_node(state: State) -> State:\n",
    "    \"\"\"Double the counter.\"\"\"\n",
    "    new_count = state[\"count\"] * 2\n",
    "    return {\"count\": new_count, \"messages\": state[\"messages\"] + [f\"Doubled to {new_count}\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Graph with SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled successfully with persistence!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Create a checkpointer (persists to SQLite in-memory database)\n",
    "conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"increment\", increment_node)\n",
    "workflow.add_node(\"double\", double_node)\n",
    "\n",
    "# Define edges\n",
    "workflow.set_entry_point(\"increment\")\n",
    "workflow.add_edge(\"increment\", \"double\")\n",
    "workflow.add_edge(\"double\", END)\n",
    "\n",
    "# Compile with checkpointer\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"Graph compiled successfully with persistence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Graph with a Thread ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final State:\n",
      "{'count': 12, 'messages': ['Starting', 'Count is now 6', 'Doubled to 12']}\n"
     ]
    }
   ],
   "source": [
    "# Thread ID identifies this conversation\n",
    "config = {\"configurable\": {\"thread_id\": \"thread_1\"}}\n",
    "\n",
    "# Initial state\n",
    "initial_state = {\"count\": 5, \"messages\": [\"Starting\"]}\n",
    "\n",
    "# Run the graph\n",
    "result = graph.invoke(initial_state, config)\n",
    "print(\"\\nFinal State:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Inspect Current State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current State Info:\n",
      "Values: {'count': 12, 'messages': ['Starting', 'Count is now 6', 'Doubled to 12']}\n",
      "Next nodes: ()\n",
      "Checkpoint ID: 1f106819-fefc-6809-8002-0b036108a8d7\n",
      "Step: 2\n"
     ]
    }
   ],
   "source": [
    "# Get the current state\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "print(\"\\nCurrent State Info:\")\n",
    "print(f\"Values: {current_state.values}\")\n",
    "print(f\"Next nodes: {current_state.next}\")\n",
    "print(f\"Checkpoint ID: {current_state.config['configurable']['checkpoint_id']}\")\n",
    "print(f\"Step: {current_state.metadata.get('step', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: View State History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total checkpoints: 4\n",
      "\n",
      "Checkpoint 0:\n",
      "  ID: 1f106819-fefc-6809-8002-0b036108a8d7\n",
      "  Step: 2\n",
      "  Values: {'count': 12, 'messages': ['Starting', 'Count is now 6', 'Doubled to 12']}\n",
      "\n",
      "Checkpoint 1:\n",
      "  ID: 1f106819-fefa-6918-8001-905f95b8de6e\n",
      "  Step: 1\n",
      "  Values: {'count': 6, 'messages': ['Starting', 'Count is now 6']}\n",
      "\n",
      "Checkpoint 2:\n",
      "  ID: 1f106819-fef8-6191-8000-793fc420b9a1\n",
      "  Step: 0\n",
      "  Values: {'count': 5, 'messages': ['Starting']}\n",
      "\n",
      "Checkpoint 3:\n",
      "  ID: 1f106819-fef5-62b6-bfff-b5db35212794\n",
      "  Step: -1\n",
      "  Values: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all checkpoints in history\n",
    "history = list(graph.get_state_history(config))\n",
    "\n",
    "print(f\"\\nTotal checkpoints: {len(history)}\\n\")\n",
    "\n",
    "for i, checkpoint in enumerate(history):\n",
    "    print(f\"Checkpoint {i}:\")\n",
    "    print(f\"  ID: {checkpoint.config['configurable']['checkpoint_id']}\")\n",
    "    print(f\"  Step: {checkpoint.metadata.get('step', 'N/A')}\")\n",
    "    print(f\"  Values: {checkpoint.values}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- **`values`**: The actual state at this checkpoint\n",
    "- **`next`**: Which nodes will execute next (empty list means done)\n",
    "- **`checkpoint_id`**: Unique identifier for this snapshot\n",
    "- **`step`**: The step number in the execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Time-Travel & Forking (10 min)\n",
    "\n",
    "One of the most powerful features is the ability to **replay** from any checkpoint.\n",
    "\n",
    "### Understanding Replay Semantics\n",
    "\n",
    "- **Before the checkpoint**: Steps are replayed without side effects (read from history)\n",
    "- **After the checkpoint**: Execution continues normally (creates new checkpoints)\n",
    "\n",
    "### Step 1: Pick a Checkpoint to Replay From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaying from checkpoint: 1f106819-fef8-6191-8000-793fc420b9a1\n",
      "State at this checkpoint: {'count': 5, 'messages': ['Starting']}\n"
     ]
    }
   ],
   "source": [
    "# Let's pick the second checkpoint (index 1)\n",
    "checkpoint_to_replay = history[2]\n",
    "\n",
    "print(f\"Replaying from checkpoint: {checkpoint_to_replay.config['configurable']['checkpoint_id']}\")\n",
    "print(f\"State at this checkpoint: {checkpoint_to_replay.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a New Config with checkpoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State at checkpoint: {'count': 5, 'messages': ['Starting']}\n"
     ]
    }
   ],
   "source": [
    "# Config with both thread_id and checkpoint_id\n",
    "replay_config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"thread_1\",\n",
    "        \"checkpoint_id\": checkpoint_to_replay.config[\"configurable\"][\"checkpoint_id\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get state at this checkpoint\n",
    "state_at_checkpoint = graph.get_state(replay_config)\n",
    "print(f\"\\nState at checkpoint: {state_at_checkpoint.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Continue Execution (Creating a Fork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forked execution result:\n",
      "{'count': 12, 'messages': ['Starting', 'Count is now 6', 'Doubled to 12']}\n"
     ]
    }
   ],
   "source": [
    "# Resume from this checkpoint - this creates a new branch!\n",
    "# Pass None as input to continue from where we left off\n",
    "forked_result = graph.invoke(None, replay_config)\n",
    "\n",
    "print(\"\\nForked execution result:\")\n",
    "print(forked_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compare Original vs Forked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original thread has 6 checkpoints\n",
      "\n",
      "Forked result: {'count': 12, 'messages': ['Starting', 'Count is now 6', 'Doubled to 12']}\n"
     ]
    }
   ],
   "source": [
    "# Original thread history\n",
    "original_history = list(graph.get_state_history(config))\n",
    "print(f\"Original thread has {len(original_history)} checkpoints\")\n",
    "\n",
    "# The forked execution created new checkpoints from the replay point\n",
    "print(f\"\\nForked result: {forked_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Update State with Reducers (10 min)\n",
    "\n",
    "Sometimes you need to **modify state** at a checkpoint without re-running nodes. This is where `update_state()` comes in.\n",
    "\n",
    "### Understanding Reducers\n",
    "\n",
    "- **Without reducer**: Values are **overwritten**\n",
    "- **With reducer**: Values are **merged** according to the reducer function\n",
    "\n",
    "### Step 1: Define State with Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from operator import add\n",
    "\n",
    "class StateWithReducer(TypedDict):\n",
    "    \"\"\"State with a reducer on the messages list.\"\"\"\n",
    "    count: int  # No reducer - overwrites\n",
    "    messages: Annotated[list[str], add]  # Reducer - appends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a New Graph with Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_with_reducer(state: StateWithReducer) -> StateWithReducer:\n",
    "    return {\"count\": state[\"count\"] + 1, \"messages\": [f\"Incremented to {state['count'] + 1}\"]}\n",
    "\n",
    "def double_with_reducer(state: StateWithReducer) -> StateWithReducer:\n",
    "    new_count = state[\"count\"] * 2\n",
    "    return {\"count\": new_count, \"messages\": [f\"Doubled to {new_count}\"]}\n",
    "\n",
    "# Build new graph with reducer state\n",
    "workflow_reducer = StateGraph(StateWithReducer)\n",
    "workflow_reducer.add_node(\"increment\", increment_with_reducer)\n",
    "workflow_reducer.add_node(\"double\", double_with_reducer)\n",
    "workflow_reducer.set_entry_point(\"increment\")\n",
    "workflow_reducer.add_edge(\"increment\", \"double\")\n",
    "workflow_reducer.add_edge(\"double\", END)\n",
    "\n",
    "# Create checkpointer for reducer graph\n",
    "conn_reducer = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "graph_reducer = workflow_reducer.compile(checkpointer=SqliteSaver(conn_reducer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run and Update State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial result:\n",
      "{'count': 8, 'messages': ['Start', 'Incremented to 4', 'Doubled to 8']}\n"
     ]
    }
   ],
   "source": [
    "config_reducer = {\"configurable\": {\"thread_id\": \"thread_reducer\"}}\n",
    "\n",
    "# Run the graph\n",
    "result_reducer = graph_reducer.invoke({\"count\": 3, \"messages\": [\"Start\"]}, config_reducer)\n",
    "print(\"Initial result:\")\n",
    "print(result_reducer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Update State with update_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated state:\n",
      "{'count': 100, 'messages': ['Start', 'Incremented to 4', 'Doubled to 8', 'Manual update']}\n"
     ]
    }
   ],
   "source": [
    "# Update the state\n",
    "# - count will be OVERWRITTEN (no reducer)\n",
    "# - messages will be APPENDED (has reducer)\n",
    "graph_reducer.update_state(\n",
    "    config_reducer,\n",
    "    {\"count\": 100, \"messages\": [\"Manual update\"]}\n",
    ")\n",
    "\n",
    "# Check updated state\n",
    "updated_state = graph_reducer.get_state(config_reducer)\n",
    "print(\"\\nUpdated state:\")\n",
    "print(updated_state.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- **`count`** was overwritten to 100 (no reducer)\n",
    "- **`messages`** had \"Manual update\" appended to the existing list (has reducer)\n",
    "\n",
    "### Exercise: Remove the Reducer\n",
    "\n",
    "**Question**: How would you make `messages` overwrite instead of append?\n",
    "\n",
    "**Answer**: Remove the `Annotated` and reducer:\n",
    "\n",
    "```python\n",
    "class StateWithReducer(TypedDict):\n",
    "    count: int\n",
    "    messages: list[str]  # No Annotated - will overwrite\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Memory Across Threads ‚Äî The Store (10 min)\n",
    "\n",
    "**Checkpoints** are per-thread. But what if you need to store facts that span multiple conversations?\n",
    "\n",
    "That's where **Store** comes in!\n",
    "\n",
    "### Store vs Checkpoints\n",
    "\n",
    "| Feature | Checkpoints | Store |\n",
    "|---------|------------|-------|\n",
    "| Scope | Single thread | Cross-thread |\n",
    "| Use case | Conversation history | User preferences, facts |\n",
    "| Analogy | Git commits | Shared database |\n",
    "\n",
    "### Step 1: Create an InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InMemoryStore created!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "print(\"InMemoryStore created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Store User Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 3 memories for user_123\n"
     ]
    }
   ],
   "source": [
    "# Store memories with namespacing: (user_id, \"memories\")\n",
    "user_id = \"user_123\"\n",
    "namespace = (user_id, \"memories\")\n",
    "\n",
    "# Store some memories\n",
    "store.put(namespace, \"memory_1\", {\"text\": \"User likes pizza\", \"timestamp\": \"2025-01-01\"})\n",
    "store.put(namespace, \"memory_2\", {\"text\": \"User is a software engineer\", \"timestamp\": \"2025-01-02\"})\n",
    "store.put(namespace, \"memory_3\", {\"text\": \"User lives in San Francisco\", \"timestamp\": \"2025-01-03\"})\n",
    "\n",
    "print(f\"Stored 3 memories for {user_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Search Memories (Cross-Thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All memories for user_123:\n",
      "  - Key: memory_1\n",
      "    Value: {'text': 'User likes pizza', 'timestamp': '2025-01-01'}\n",
      "\n",
      "  - Key: memory_2\n",
      "    Value: {'text': 'User is a software engineer', 'timestamp': '2025-01-02'}\n",
      "\n",
      "  - Key: memory_3\n",
      "    Value: {'text': 'User lives in San Francisco', 'timestamp': '2025-01-03'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for all memories\n",
    "memories = store.search(namespace)\n",
    "\n",
    "print(f\"\\nAll memories for {user_id}:\")\n",
    "for item in memories:\n",
    "    print(f\"  - Key: {item.key}\")\n",
    "    print(f\"    Value: {item.value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use Store in a Different Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing memories in NEW thread (different conversation):\n",
      "  - User likes pizza\n",
      "  - User is a software engineer\n",
      "  - User lives in San Francisco\n"
     ]
    }
   ],
   "source": [
    "# This simulates a new conversation (different thread)\n",
    "# but we can still access the same memories!\n",
    "\n",
    "def simulate_new_thread():\n",
    "    \"\"\"Simulate accessing memories in a completely different thread.\"\"\"\n",
    "    user_memories = store.search((user_id, \"memories\"))\n",
    "    \n",
    "    print(\"Accessing memories in NEW thread (different conversation):\")\n",
    "    for item in user_memories:\n",
    "        print(f\"  - {item.value['text']}\")\n",
    "\n",
    "simulate_new_thread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Integrate Store with Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result with store access:\n",
      "  Starting\n",
      "  Found 3 memories\n",
      "  User likes pizza\n",
      "  User is a software engineer\n",
      "  User lives in San Francisco\n"
     ]
    }
   ],
   "source": [
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "class StateWithStore(TypedDict):\n",
    "    messages: list[str]\n",
    "    user_id: str\n",
    "\n",
    "def node_with_store_access(state: StateWithStore, *, store: BaseStore) -> StateWithStore:\n",
    "    \"\"\"Node that can access the store via the store parameter.\"\"\"\n",
    "    # Access user memories from store\n",
    "    user_id = state[\"user_id\"]\n",
    "    memories = list(store.search((user_id, \"memories\")))\n",
    "    \n",
    "    memory_texts = [m.value[\"text\"] for m in memories]\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [f\"Found {len(memories)} memories\"] + memory_texts,\n",
    "        \"user_id\": user_id\n",
    "    }\n",
    "\n",
    "# Build graph with store\n",
    "workflow_with_store = StateGraph(StateWithStore)\n",
    "workflow_with_store.add_node(\"fetch_memories\", node_with_store_access)\n",
    "workflow_with_store.set_entry_point(\"fetch_memories\")\n",
    "workflow_with_store.add_edge(\"fetch_memories\", END)\n",
    "\n",
    "# Compile with both checkpointer AND store\n",
    "conn_store = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "graph_with_store = workflow_with_store.compile(\n",
    "    checkpointer=SqliteSaver(conn_store),\n",
    "    store=store\n",
    ")\n",
    "\n",
    "# Run the graph\n",
    "result_with_store = graph_with_store.invoke(\n",
    "    {\"messages\": [\"Starting\"], \"user_id\": user_id},\n",
    "    {\"configurable\": {\"thread_id\": \"thread_with_store\"}}\n",
    ")\n",
    "\n",
    "print(\"\\nResult with store access:\")\n",
    "for msg in result_with_store[\"messages\"]:\n",
    "    print(f\"  {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- **Store is cross-thread**: Accessible from any thread\n",
    "- **Namespacing**: Organize data with tuples like `(user_id, \"memories\")`\n",
    "- **Integration**: Pass `store=store` when compiling the graph\n",
    "- **Access in nodes**: Use `store` parameter in node functions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Human-in-the-Loop & Fault Tolerance (5 min)\n",
    "\n",
    "Persistence enables two critical capabilities:\n",
    "\n",
    "### 1. Human-in-the-Loop (HITL)\n",
    "\n",
    "- **Inspect** state before continuing\n",
    "- **Approve/reject** actions\n",
    "- **Edit** state if needed\n",
    "- **Resume** from where you left off\n",
    "\n",
    "Example workflow:\n",
    "```python\n",
    "# Pause before a critical action\n",
    "state = graph.get_state(config)\n",
    "if state.next == [\"dangerous_action\"]:\n",
    "    user_approval = input(\"Approve? (y/n): \")\n",
    "    if user_approval == \"y\":\n",
    "        graph.invoke(None, config)  # Resume\n",
    "```\n",
    "\n",
    "### 2. Fault Tolerance\n",
    "\n",
    "- **Automatic checkpointing** preserves state\n",
    "- **Restart from failure**: If a node crashes, restart from the last checkpoint\n",
    "- **Pending writes preserved**: Uncommitted state changes are saved\n",
    "\n",
    "Example:\n",
    "```python\n",
    "try:\n",
    "    result = graph.invoke(input, config)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    # State is preserved! Resume later:\n",
    "    result = graph.invoke(None, config)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Lab (15-20 min)\n",
    "\n",
    "Now it's your turn! Complete these exercises:\n",
    "\n",
    "### Exercise 1: Run Graph and View State\n",
    "\n",
    "Create a new graph, run it, and inspect the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a graph, run it with a thread_id, and view the state\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: View History and Identify Checkpoints\n",
    "\n",
    "Get the state history and print details about each checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get state history and identify at least 4 checkpoints\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Time-Travel (Replay from Checkpoint)\n",
    "\n",
    "Pick checkpoint 2 and replay from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replay from checkpoint 2 and observe the branch\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Update State\n",
    "\n",
    "Use `update_state()` to fix a value and observe the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update state to fix a value, then re-run one step\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Cross-Thread Memory\n",
    "\n",
    "Add a user memory, then read it in a completely different thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a memory for a user, then access it in a new thread\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls (5 min)\n",
    "\n",
    "### 1. Forgetting `thread_id` ‚Üí Nothing Persists\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - no thread_id\n",
    "graph.invoke(input)  # Nothing is saved!\n",
    "\n",
    "# ‚úÖ Correct\n",
    "graph.invoke(input, {\"configurable\": {\"thread_id\": \"my_thread\"}})\n",
    "```\n",
    "\n",
    "### 2. Expecting Overwrite Where a Reducer Merges\n",
    "\n",
    "```python\n",
    "# If messages has a reducer:\n",
    "messages: Annotated[list[str], add]\n",
    "\n",
    "# update_state will APPEND, not replace!\n",
    "graph.update_state(config, {\"messages\": [\"new\"]})\n",
    "```\n",
    "\n",
    "### 3. Confusing Checkpoints (Per-Thread) with Store (Cross-Thread)\n",
    "\n",
    "- **Checkpoints**: Thread-specific conversation history\n",
    "- **Store**: Shared facts across all threads\n",
    "\n",
    "### 4. Assuming Replay Re-Calls External APIs\n",
    "\n",
    "- Replay **reads from history** for steps before the checkpoint\n",
    "- It does **NOT** re-execute those steps or call APIs again\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cheat Sheet\n",
    "\n",
    "### Run with Persistence\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Create checkpointer\n",
    "conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "\n",
    "# Or for a file-based database:\n",
    "# conn = sqlite3.connect(\"checkpoints.db\", check_same_thread=False)\n",
    "# checkpointer = SqliteSaver(conn)\n",
    "\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"thread_1\"}}\n",
    "result = graph.invoke(input, config)\n",
    "```\n",
    "\n",
    "### Inspect State\n",
    "\n",
    "```python\n",
    "# Get current state\n",
    "current = graph.get_state(config)\n",
    "\n",
    "# Get all history\n",
    "history = list(graph.get_state_history(config))\n",
    "```\n",
    "\n",
    "### Time-Travel\n",
    "\n",
    "```python\n",
    "config_with_checkpoint = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"thread_1\",\n",
    "        \"checkpoint_id\": \"checkpoint_id_here\"\n",
    "    }\n",
    "}\n",
    "graph.invoke(None, config_with_checkpoint)\n",
    "```\n",
    "\n",
    "### Update State\n",
    "\n",
    "```python\n",
    "graph.update_state(\n",
    "    config,\n",
    "    {\"key\": \"value\"},\n",
    "    as_node=\"node_name\"  # Optional\n",
    ")\n",
    "```\n",
    "\n",
    "### Cross-Thread Memory (Store)\n",
    "\n",
    "```python\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "store = InMemoryStore()\n",
    "store.put((user_id, \"memories\"), \"key\", {\"data\": \"value\"})\n",
    "results = store.search((user_id, \"memories\"))\n",
    "\n",
    "# Compile with store\n",
    "graph = workflow.compile(checkpointer=checkpointer, store=store)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment Questions\n",
    "\n",
    "### Q1: When do you need a Store vs. Checkpoints?\n",
    "\n",
    "**Answer**: \n",
    "- Use **checkpoints** for thread-specific conversation history and state\n",
    "- Use **Store** for cross-thread facts (user preferences, memories) that need to be accessed from any conversation\n",
    "\n",
    "### Q2: What happens to steps BEFORE the checkpoint_id during replay?\n",
    "\n",
    "**Answer**: \n",
    "- Steps before the checkpoint are **replayed from history** without re-executing\n",
    "- No side effects occur (APIs are not called again)\n",
    "- Only steps **after** the checkpoint execute normally\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Stretch Exercises\n",
    "\n",
    "### 1. Swap In-Memory ‚Üí File-Based SqliteSaver\n",
    "\n",
    "Try changing from in-memory persistence to a real SQLite file:\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "conn = sqlite3.connect(\"./my_checkpoints.db\", check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn)\n",
    "```\n",
    "\n",
    "This will persist checkpoints to disk so they survive between program runs!\n",
    "\n",
    "### 2. Using Context Manager Approach\n",
    "\n",
    "Alternatively, you can use the context manager approach:\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "with SqliteSaver.from_conn_string(\"./checkpoints.db\") as checkpointer:\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "    result = graph.invoke(input, config)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "‚úÖ The **Git analogy** for persistence (threads, checkpoints, replay, store)  \n",
    "‚úÖ How to **run graphs with persistence** using checkpointers  \n",
    "‚úÖ How to **inspect state and history**  \n",
    "‚úÖ How to **time-travel** and create forks  \n",
    "‚úÖ How **reducers** control state updates (merge vs overwrite)  \n",
    "‚úÖ How to use **Store** for cross-thread memory  \n",
    "‚úÖ Common pitfalls to avoid  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore **human-in-the-loop** patterns\n",
    "- Try **production checkpointers** (PostgreSQL, Redis)\n",
    "- Build **multi-agent systems** with shared memory\n",
    "- Implement **semantic search** in your Store\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [LangGraph Persistence Docs](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "- [LangGraph Memory Docs](https://langchain-ai.github.io/langgraph/concepts/memory/)\n",
    "- [State and Reducers](https://langchain-ai.github.io/langgraph/concepts/low_level/)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Building! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "O'Reilly Agents (oreilly-agents)",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
