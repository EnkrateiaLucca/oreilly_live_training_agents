{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file\n",
    "# create directory\n",
    "# list files\n",
    "\n",
    "class CreateFile(BaseModel):\n",
    "    file_path: str = Field(description=\"file path to create\")\n",
    "    contents: str = Field(description=\"contents to write to the file\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_structured_response(prompt):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"\"\"\n",
    "                   You are a helpful research and programming assistant,\n",
    "                   you take in requests and you output the structured object \n",
    "                   with the relevant attributes for the request.\n",
    "                   \"\"\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format=CreateFile\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "prompt = \"Create a file with an essay containing 2 paragraphs about why bald guys love pancakes.\"\n",
    "\n",
    "structured_response = get_structured_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "bald_guys_love_pancakes_essay.txt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(structured_response.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Many bald guys are known for their confidence and ability to embrace life’s simple pleasures. One such pleasure is the love for pancakes. The smooth, warm surface of a pancake may remind them of the embrace of a sunny morning or the crisp satisfaction that comes from the perfect, even shape—qualities they can also appreciate about their own perfectly bald heads. Pancakes, like a bald scalp, require care and finesse in preparation, and both symbolize a certain ease and comfort in being oneself.\n",
       "\n",
       "Additionally, pancakes represent the ultimate customizable food: just as each bald man has his own unique style, every pancake breakfast can be tailored to personal taste, whether with syrup, fruit, or a dusting of sugar. This freedom to choose and indulge reflects the liberated spirit of many bald guys, who have shed not only their hair but also society’s unnecessary expectations, allowing them to savor life—and pancakes—with gusto. It’s not just about breakfast; it’s about confidently enjoying what you love, and for many bald men, that love is symbolized by a hearty stack of pancakes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(structured_response.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(file_path: str, contents: str) -> str:\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(contents)\n",
    "    \n",
    "    return \"Created file!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_execute_create_file_action(input_llm_struct: CreateFile) -> str:\n",
    "    try:\n",
    "        create_file(input_llm_struct.file_path, input_llm_struct.contents)\n",
    "    except:\n",
    "        print(\"did not create function!\")\n",
    "    \n",
    "    return \"File created!\"\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"Create a file with an essay containing 2 paragraphs about why bald guys love pancakes.\"\n",
    "\n",
    "structured_response = get_structured_response(prompt)\n",
    "\n",
    "observation_output = agent_execute_create_file_action(structured_response)\n",
    "\n",
    "# pass that along the model or to a different model to generate a response\n",
    "# llm_call(observation_output)....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bald_guys_love_pancakes_essay.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_response.file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "O'Reilly Agents (oreilly-agents)",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
